{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df60876b-cb40-41d2-8c49-21fa99a8a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\caption{Metrics by action and method. ``Value'' denotes DR-value for C-kNN-LSH and DR-kNN, plug-in policy value for kNN and T-Learner, weighted contrast for MSM, and sequential DR value for Seq-DR. MSE is only defined for C-kNN-LSH, DR-kNN, kNN, and T-Learner.}\n",
      "\\label{tab:methods-by-action-full}\n",
      "\\resizebox{\\linewidth}{!}{%\n",
      "\\begin{tabular}{l cc cc cc cc cc cc cc}\n",
      "\\toprule\n",
      "\\multirow{2}{*}{\\textbf{Action}} & \\multicolumn{2}{c}{\\textbf{C-kNN-LSH (ours)}} & \\multicolumn{2}{c}{\\textbf{DR-kNN}} & \\multicolumn{2}{c}{\\textbf{kNN}} & \\multicolumn{2}{c}{\\textbf{T-Learner}} & \\multicolumn{2}{c}{\\textbf{MSM}} & \\multicolumn{2}{c}{\\textbf{Seq-DR}} & \\multicolumn{2}{c}{\\textbf{Visits}} \\\\\n",
      "& \\textbf{MSE} & \\textbf{Value} & \\textbf{MSE} & \\textbf{Value} & \\textbf{MSE} & \\textbf{Value} & \\textbf{MSE} & \\textbf{Value} & \\textbf{MSE} & \\textbf{Value} & \\textbf{MSE} & \\textbf{Value} & \\textbf{Train (avg)} & \\textbf{Test (avg)} \\\\\n",
      "\\midrule\n",
      "A\\_dose1 & 1.0429 \\pm 0.0782 & 0.0571 \\pm 0.0205 &  & 2.5023 \\pm 0.1068 &  & 2.5086 \\pm 0.0949 &  & 2.4629 \\pm 0.0955 &  & 0.0943 \\pm 0.3612 &  & 0.0261 \\pm 0.0700 & 53,270.2 & 13,432.8 \\\\\n",
      "A\\_dose2 & 1.0370 \\pm 0.0786 & 0.0527 \\pm 0.0110 &  & 2.4993 \\pm 0.0914 &  & 2.4951 \\pm 0.0979 &  & 2.4625 \\pm 0.0949 &  & 0.2139 \\pm 0.2218 &  & 0.0468 \\pm 0.1006 & 53,270.2 & 13,432.8 \\\\\n",
      "A\\_dose3 & 1.0415 \\pm 0.0810 & 0.0562 \\pm 0.0183 &  & 2.5311 \\pm 0.1173 &  & 2.5232 \\pm 0.1201 &  & 2.4625 \\pm 0.0955 &  & -0.0407 \\pm 0.0974 &  & -0.1298 \\pm 0.0648 & 53,270.2 & 13,432.8 \\\\\n",
      "A\\_dose4 & 1.0370 \\pm 0.0785 & 0.4001 \\pm 0.1546 &  & 2.4881 \\pm 0.0881 &  & 2.5059 \\pm 0.1042 &  & 2.4634 \\pm 0.0956 &  & -0.0492 \\pm 0.0612 &  & -0.0387 \\pm 0.0313 & 53,270.2 & 13,432.8 \\\\\n",
      "A\\_vax\\_any & 1.0387 \\pm 0.0779 & 0.3302 \\pm 0.1289 &  & 2.5704 \\pm 0.1649 &  & 2.4976 \\pm 0.0962 &  & 2.4628 \\pm 0.0955 &  & -0.0186 \\pm 0.0566 &  & -0.0833 \\pm 0.0467 & 53,270.2 & 13,432.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- helpers ---\n",
    "VAL_PAT = re.compile(r\"\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*[±\\+-\\-~]*\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*\")\n",
    "\n",
    "def fmt(mean, ci):\n",
    "    return f\"{float(mean):.4f} \\\\pm {float(ci):.4f}\"\n",
    "\n",
    "def parse_value_str(s):\n",
    "    if isinstance(s, (int, float)):  # mean only\n",
    "        return float(s), np.nan\n",
    "    if not isinstance(s, str):\n",
    "        return np.nan, np.nan\n",
    "    s = s.replace(\"+-\", \"±\").replace(\"+/-\", \"±\").replace(\"±\", \" ± \")\n",
    "    m = VAL_PAT.match(s.strip())\n",
    "    return (float(m.group(1)), float(m.group(2))) if m else (np.nan, np.nan)\n",
    "\n",
    "def split_method_metric(metric_str):\n",
    "    # Examples in your baseline:\n",
    "    # 'DR-kNN MSE' -> ('DR-kNN','MSE')\n",
    "    # 'DR-kNN DR-value' -> ('DR-kNN','Value')\n",
    "    # 'kNN MSE' -> ('kNN','MSE')\n",
    "    # 'kNN plug-value' -> ('kNN','Value')\n",
    "    # 'MSM weighted contrast' -> ('MSM','Value')\n",
    "    # 'Seq-DR value' -> ('Seq-DR','Value')\n",
    "    s = str(metric_str).strip()\n",
    "    s = s.replace(\"plug-value\", \"Value\").replace(\"DR-value\", \"Value\").replace(\"weighted contrast\",\"Value\")\n",
    "    parts = s.split()\n",
    "    method = \" \".join(parts[:-1]) if len(parts) > 1 else parts[0]\n",
    "    metric = parts[-1].capitalize() if len(parts) > 1 else \"Value\"\n",
    "    if metric not in (\"MSE\",\"Value\"):\n",
    "        metric = \"Value\"\n",
    "    return method, metric\n",
    "\n",
    "# --- normalize ours ---\n",
    "def normalize_ours(df_ours, method_name=\"C-kNN-LSH (ours)\"):\n",
    "    need = {\"action\",\"mse_mean\",\"mse_ci95\",\"dr_value_mean\",\"dr_value_ci95\"}\n",
    "    missing = need - set(df_ours.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"df_ours missing columns: {missing}\")\n",
    "    recs = []\n",
    "    for r in df_ours.itertuples(index=False):\n",
    "        action = r.action\n",
    "        recs.append({\"action\": action, \"method\": method_name, \"metric\": \"MSE\",\n",
    "                     \"mean\": float(r.mse_mean), \"ci95\": float(r.mse_ci95)})\n",
    "        recs.append({\"action\": action, \"method\": method_name, \"metric\": \"Value\",\n",
    "                     \"mean\": float(r.dr_value_mean), \"ci95\": float(r.dr_value_ci95)})\n",
    "    out = pd.DataFrame(recs)\n",
    "    out[\"cell\"] = out.apply(lambda x: fmt(x[\"mean\"], x[\"ci95\"]), axis=1)\n",
    "    return out\n",
    "\n",
    "# --- normalize baselines ---\n",
    "def normalize_baselines(df_base):\n",
    "    need = {\"action\",\"metric\",\"value\"}\n",
    "    missing = need - set(df_base.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"df_base missing columns: {missing}\")\n",
    "    rows = []\n",
    "    for r in df_base.itertuples(index=False):\n",
    "        mth, met = split_method_metric(r.metric)\n",
    "        mean, ci = parse_value_str(r.value)\n",
    "        rows.append({\"action\": r.action, \"method\": mth, \"metric\": met,\n",
    "                     \"mean\": mean, \"ci95\": ci})\n",
    "    out = pd.DataFrame(rows)\n",
    "    out[\"cell\"] = out.apply(lambda x: fmt(x[\"mean\"], x[\"ci95\"]) if pd.notna(x[\"mean\"]) else \"\", axis=1)\n",
    "    return out\n",
    "\n",
    "# --- build paper table ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_paper_table(df_ours, df_base,\n",
    "                      visits_train=53270.2, visits_test=13432.8,\n",
    "                      methods=(\"C-kNN-LSH (ours)\",\"DR-kNN\",\"kNN\",\"T-Learner\",\"MSM\",\"Seq-DR\"),\n",
    "                      action_order=(\"A_dose1\",\"A_dose2\",\"A_dose3\",\"A_dose4\",\"A_vax_any\")):\n",
    "    # ---- normalize_ours / normalize_baselines defined earlier ----\n",
    "    ours = normalize_ours(df_ours)\n",
    "    base = normalize_baselines(df_base)\n",
    "    alln = pd.concat([ours, base], ignore_index=True)\n",
    "\n",
    "    # pivot to (method, metric)\n",
    "    cols_full = pd.MultiIndex.from_product([methods, [\"MSE\",\"Value\"]])\n",
    "    piv = (alln.pivot_table(index=\"action\", columns=[\"method\",\"metric\"], values=\"cell\", aggfunc=\"first\")\n",
    "                .reindex(columns=cols_full))\n",
    "\n",
    "    # visits as strings (avoid floats later)\n",
    "    piv[(\"Visits\",\"Train (avg)\")] = f\"{visits_train:,.1f}\"\n",
    "    piv[(\"Visits\",\"Test (avg)\")]  = f\"{visits_test:,.1f}\"\n",
    "\n",
    "    # order columns\n",
    "    ordered_cols = []\n",
    "    for m in methods:\n",
    "        ordered_cols.extend([(m,\"MSE\"),(m,\"Value\")])\n",
    "    ordered_cols.extend([(\"Visits\",\"Train (avg)\"),(\"Visits\",\"Test (avg)\")])\n",
    "    piv = piv.reindex(columns=pd.MultiIndex.from_tuples(ordered_cols))\n",
    "\n",
    "    # order actions\n",
    "    order = [a for a in action_order if a in piv.index]\n",
    "    order += [a for a in piv.index if a not in order]\n",
    "    piv = piv.loc[order]\n",
    "\n",
    "    # IMPORTANT: clear MultiIndex names properly (list-like for both levels)\n",
    "    if isinstance(piv.columns, pd.MultiIndex) and piv.columns.nlevels == 2:\n",
    "        piv.columns = pd.MultiIndex.from_tuples(piv.columns.tolist(), names=[None, None])\n",
    "    piv.index.name = None\n",
    "    return piv\n",
    "\n",
    "\n",
    "def to_latex_block(piv):\n",
    "    methods = [\"C-kNN-LSH (ours)\",\"DR-kNN\",\"kNN\",\"T-Learner\",\"MSM\",\"Seq-DR\"]\n",
    "\n",
    "    def safe_str(x):\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "            return \"\"\n",
    "        return x if isinstance(x, str) else f\"{x}\"\n",
    "\n",
    "    header = [\n",
    "        r\"\\begin{table}[t]\",\n",
    "        r\"\\centering\",\n",
    "        r\"\\caption{Metrics by action and method. ``Value'' denotes DR-value for C-kNN-LSH and DR-kNN, plug-in policy value for kNN and T-Learner, weighted contrast for MSM, and sequential DR value for Seq-DR. MSE is only defined for C-kNN-LSH, DR-kNN, kNN, and T-Learner.}\",\n",
    "        r\"\\label{tab:methods-by-action-full}\",\n",
    "        r\"\\resizebox{\\linewidth}{!}{%\",\n",
    "        r\"\\begin{tabular}{l \" + \" \".join([\"cc\"]*len(methods)) + \" cc}\",\n",
    "        r\"\\toprule\",\n",
    "        r\"\\multirow{2}{*}{\\textbf{Action}} & \" +\n",
    "        \" & \".join([fr\"\\multicolumn{{2}}{{c}}{{\\textbf{{{m}}}}}\" for m in methods]) +\n",
    "        r\" & \\multicolumn{2}{c}{\\textbf{Visits}} \\\\\",\n",
    "        r\"& \" + \" & \".join([r\"\\textbf{MSE} & \\textbf{Value}\"]*len(methods)) +\n",
    "        r\" & \\textbf{Train (avg)} & \\textbf{Test (avg)} \\\\\",\n",
    "        r\"\\midrule\"\n",
    "    ]\n",
    "\n",
    "    lines = []\n",
    "    for action, row in piv.iterrows():\n",
    "        cells = [action.replace(\"_\", r\"\\_\")]\n",
    "        for m in methods:\n",
    "            # pull safely and stringify\n",
    "            mse  = row.get((m,\"MSE\"),  np.nan)\n",
    "            val  = row.get((m,\"Value\"), np.nan)\n",
    "            cells.append(safe_str(mse))\n",
    "            cells.append(safe_str(val))\n",
    "        cells.append(safe_str(row.get((\"Visits\",\"Train (avg)\"))))\n",
    "        cells.append(safe_str(row.get((\"Visits\",\"Test (avg)\"))))\n",
    "        lines.append(\" & \".join(map(safe_str, cells)) + r\" \\\\\")\n",
    "    footer = [r\"\\bottomrule\", r\"\\end{tabular}%\", r\"}\", r\"\\end{table}\"]\n",
    "    return \"\\n\".join(header + lines + footer)\n",
    "\n",
    "\n",
    "# --------- USE IT ----------\n",
    "df_ours = df\n",
    "df_base = b\n",
    "# Build table and export LaTeX:\n",
    "piv = build_paper_table(df_ours, df_base)\n",
    "tex = to_latex_block(piv)\n",
    "print(tex)\n",
    "with open(\"methods_by_action_full.tex\",\"w\") as f:\n",
    "    f.write(tex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5576c-c7ad-4dce-a86f-0ae00f42a247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dffde8f-6c91-40bf-b0d9-18d7139f7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_dose1</td>\n",
       "      <td>DR-kNN  MSE</td>\n",
       "      <td>2.5023 ± 0.1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_dose1</td>\n",
       "      <td>DR-kNN  DR-value</td>\n",
       "      <td>0.0604 ± 0.0781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_dose1</td>\n",
       "      <td>kNN     MSE</td>\n",
       "      <td>2.5086 ± 0.0949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_dose1</td>\n",
       "      <td>kNN     plug-value</td>\n",
       "      <td>0.0670 ± 0.0776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_dose1</td>\n",
       "      <td>T-Learner MSE</td>\n",
       "      <td>2.4629 ± 0.0955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    action              metric            value\n",
       "0  A_dose1         DR-kNN  MSE  2.5023 ± 0.1068\n",
       "1  A_dose1    DR-kNN  DR-value  0.0604 ± 0.0781\n",
       "2  A_dose1         kNN     MSE  2.5086 ± 0.0949\n",
       "3  A_dose1  kNN     plug-value  0.0670 ± 0.0776\n",
       "4  A_dose1       T-Learner MSE  2.4629 ± 0.0955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.read_csv('all_methods_summary.csv')\n",
    "b.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc44a77-84e7-476a-963b-5988f7347bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_ci95</th>\n",
       "      <th>dr_value_mean</th>\n",
       "      <th>dr_value_ci95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_dose1</td>\n",
       "      <td>1.042907</td>\n",
       "      <td>0.078177</td>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.020515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_dose2</td>\n",
       "      <td>1.037030</td>\n",
       "      <td>0.078574</td>\n",
       "      <td>0.052650</td>\n",
       "      <td>0.011001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_dose3</td>\n",
       "      <td>1.041522</td>\n",
       "      <td>0.081021</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>0.018298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_dose4</td>\n",
       "      <td>1.036988</td>\n",
       "      <td>0.078486</td>\n",
       "      <td>0.400109</td>\n",
       "      <td>0.154616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_vax_any</td>\n",
       "      <td>1.038675</td>\n",
       "      <td>0.077883</td>\n",
       "      <td>0.330241</td>\n",
       "      <td>0.128906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      action  mse_mean  mse_ci95  dr_value_mean  dr_value_ci95\n",
       "0    A_dose1  1.042907  0.078177       0.057056       0.020515\n",
       "1    A_dose2  1.037030  0.078574       0.052650       0.011001\n",
       "2    A_dose3  1.041522  0.081021       0.056194       0.018298\n",
       "3    A_dose4  1.036988  0.078486       0.400109       0.154616\n",
       "4  A_vax_any  1.038675  0.077883       0.330241       0.128906"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cknn_vax_actions_summary_nodupp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ec1eea-131f-4282-93ad-8d14075a3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "# =============== Utilities ===============\n",
    "\n",
    "def add_bias(X):\n",
    "    return np.concatenate([X, np.ones((X.shape[0],1), dtype=X.dtype)], axis=1)\n",
    "\n",
    "def ridge_regression_fit(X, y, l2=1e-2):\n",
    "    XT = X.T\n",
    "    A = XT @ X\n",
    "    I = np.eye(A.shape[0], dtype=X.dtype)\n",
    "    I[-1, -1] = 0.0  # don't regularize bias\n",
    "    w = np.linalg.solve(A + l2*I, XT @ y)\n",
    "    return w\n",
    "\n",
    "def ridge_regression_predict(W, X):\n",
    "    return X @ W\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_regression_fit(X, y, l2=1e-3, lr=0.1, epochs=300, batch=2048, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N, D = X.shape\n",
    "    w = rng.normal(0, 0.01, size=(D,)).astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "    for ep in range(epochs):\n",
    "        perm = rng.permutation(N)\n",
    "        for s in range(0, N, batch):\n",
    "            e = min(N, s+batch)\n",
    "            xb = X[perm[s:e]]; yb = y[perm[s:e]]\n",
    "            p = sigmoid(xb @ w)\n",
    "            # gradient (+ L2 on non-bias)\n",
    "            grad = (xb.T @ (p - yb)) / (e - s)\n",
    "            grad[:-1] += l2 * w[:-1]\n",
    "            w -= lr * grad\n",
    "    return w\n",
    "\n",
    "def logistic_regression_predict_proba(W, X):\n",
    "    return sigmoid(X @ W)\n",
    "\n",
    "def flatten_time(phi, A, Y):\n",
    "    \"\"\"phi: (n,T,d) object -> (N,d), A,Y -> (N,)\"\"\"\n",
    "    n = len(phi)\n",
    "    ds = [p.shape[0] for p in phi]\n",
    "    d = phi[0].shape[1]\n",
    "    Ntot = sum(ds)\n",
    "    out_phi = np.zeros((Ntot, d), dtype=np.float32)\n",
    "    out_A = np.zeros((Ntot,), dtype=np.int64)\n",
    "    out_Y = np.zeros((Ntot,), dtype=np.float32)\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        T = phi[i].shape[0]\n",
    "        out_phi[idx:idx+T] = phi[i]\n",
    "        out_A[idx:idx+T] = A[i]\n",
    "        out_Y[idx:idx+T] = Y[i]\n",
    "        idx += T\n",
    "    return out_phi, out_A, out_Y\n",
    "\n",
    "# =============== History features (no torch) ===============\n",
    "\n",
    "def build_history_features(X_obj, A_obj, Y_obj, d_latent=16, seed=1337, alpha=0.5):\n",
    "    \"\"\"\n",
    "    X_obj[i]: (T_i, d_x) features per visit *before* treatment\n",
    "    Returns Phi[i]: (T_i, d_latent)\n",
    "    Idea: concat [x_t, a_{t-1}, y_{t-1}, EMA(x_{<t}), cum-mean(y_{<t})] -> random projection + tanh\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = len(X_obj)\n",
    "    d_x = X_obj[0].shape[1]\n",
    "\n",
    "    d_raw = d_x + 1 + 1 + d_x + 1\n",
    "    W = rng.normal(0, 1/np.sqrt(d_raw), size=(d_raw, d_latent)).astype(np.float32)\n",
    "    b = rng.normal(0, 0.1, size=(d_latent,)).astype(np.float32)\n",
    "\n",
    "    Phi = []\n",
    "    for i in range(N):\n",
    "        Xi = X_obj[i]; Ai = A_obj[i]; Yi = Y_obj[i]\n",
    "        T = Xi.shape[0]\n",
    "        phi_i = np.zeros((T, d_latent), dtype=np.float32)\n",
    "        x_ema = np.zeros((d_x,), dtype=np.float32)\n",
    "        y_csum = 0.0\n",
    "        for t in range(T):\n",
    "            x_t = Xi[t]\n",
    "            a_prev = Ai[t-1] if t>0 else 0.0\n",
    "            y_prev = Yi[t-1] if t>0 else 0.0\n",
    "            if t>0:\n",
    "                x_ema = alpha * x_ema + (1-alpha) * Xi[t-1]\n",
    "                y_csum += Yi[t-1]\n",
    "                y_cmean = y_csum / t\n",
    "            else:\n",
    "                x_ema = np.zeros_like(x_t)\n",
    "                y_cmean = 0.0\n",
    "            raw = np.concatenate([x_t, [a_prev], [y_prev], x_ema, [y_cmean]]).astype(np.float32)\n",
    "            phi_i[t] = np.tanh(raw @ W + b)\n",
    "        Phi.append(phi_i)\n",
    "    return np.array(Phi, dtype=object)\n",
    "\n",
    "# =============== ANN (HNSW or exact kNN fallback) ===============\n",
    "\n",
    "try:\n",
    "    import hnswlib\n",
    "    class ANNIndex:\n",
    "        def __init__(self, dim, space=\"l2\", ef=100, M=32):\n",
    "            self.index = hnswlib.Index(space=space, dim=dim)\n",
    "            self.ef = ef; self.M = M; self.built = False\n",
    "        def build(self, X, ids=None):\n",
    "            if ids is None: ids = np.arange(X.shape[0])\n",
    "            self.index.init_index(max_elements=X.shape[0], ef_construction=self.ef, M=self.M)\n",
    "            self.index.add_items(X.astype(np.float32), ids.astype(np.int64))\n",
    "            self.index.set_ef(self.ef); self.built = True\n",
    "        def query(self, Q, k=50):\n",
    "            return self.index.knn_query(Q.astype(np.float32), k=k)\n",
    "except Exception:\n",
    "    # exact kNN fallback (no dependency)\n",
    "    class ANNIndex:\n",
    "        def __init__(self, dim, space=\"l2\", **kwargs):\n",
    "            self.X = None\n",
    "        def build(self, X, ids=None):\n",
    "            self.X = X.astype(np.float32)\n",
    "        def query(self, Q, k=50):\n",
    "            # squared l2\n",
    "            d2 = ((Q[:,None,:] - self.X[None,:,:])**2).sum(axis=2)\n",
    "            idx = np.argsort(d2, axis=1)[:, :k]\n",
    "            d  = np.take_along_axis(d2, idx, axis=1)\n",
    "            return idx, d\n",
    "\n",
    "# =============== DR-kNN estimator ===============\n",
    "\n",
    "def dr_knn_mu(phi_tr, A_tr, Y_tr, query_phi, a_query, out_W, prop_W, k=50, temp=1.0):\n",
    "    \"\"\"\n",
    "    Double-robust kNN: neighbors on phi among train rows with A==a_query.\n",
    "    out_W: ridge on [phi, onehot(a)](+bias)\n",
    "    prop_W: logistic on phi(+bias)\n",
    "    \"\"\"\n",
    "    mask_a = (A_tr == a_query)\n",
    "    phi_a = phi_tr[mask_a]\n",
    "    ann = ANNIndex(dim=phi_tr.shape[1])\n",
    "    ann.build(phi_a)\n",
    "\n",
    "    def design_outcome(phi, a_vec):\n",
    "        a0 = (a_vec==0).astype(np.float32).reshape(-1,1)\n",
    "        a1 = (a_vec==1).astype(np.float32).reshape(-1,1)\n",
    "        Z = np.concatenate([phi, a0, a1], axis=1)\n",
    "        return add_bias(Z)\n",
    "\n",
    "    def m_pred(phi, a_scalar):\n",
    "        Z = design_outcome(phi, np.full((phi.shape[0],), a_scalar, dtype=np.int64))\n",
    "        return ridge_regression_predict(out_W, Z)\n",
    "\n",
    "    def e_pred(phi):\n",
    "        return logistic_regression_predict_proba(prop_W, add_bias(phi))\n",
    "\n",
    "    labels, dists = ann.query(query_phi, k=min(k, len(phi_a)))\n",
    "    Wker = np.exp(-dists / max(temp, 1e-6))\n",
    "    Wker /= (Wker.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # train-side predictions once\n",
    "    e_train = e_pred(phi_tr)\n",
    "    e_train = e_train if a_query==1 else (1.0 - e_train)\n",
    "    m_train_a = m_pred(phi_tr, a_query)\n",
    "\n",
    "    mu = np.zeros(query_phi.shape[0], dtype=np.float32)\n",
    "    # indices of global train rows corresponding to A==a_query\n",
    "    idx_map = np.where(mask_a)[0]\n",
    "    for i in range(query_phi.shape[0]):\n",
    "        local = labels[i]\n",
    "        global_idx = idx_map[local]\n",
    "        w = Wker[i]\n",
    "\n",
    "        res = Y_tr[global_idx] - m_train_a[global_idx]\n",
    "        e_neighbors = e_train[global_idx]\n",
    "        iw = 1.0 / np.clip(e_neighbors, 1e-3, 1-1e-3)\n",
    "        w_tilde = w * iw; w_tilde /= (w_tilde.sum() + 1e-8)\n",
    "\n",
    "        m_q = m_pred(query_phi[i:i+1], a_query)[0]\n",
    "        mu[i] = m_q + np.sum(w_tilde * res)\n",
    "    return mu\n",
    "\n",
    "# =============== Runner: pass your lists here ===============\n",
    "\n",
    "def run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=1337, k=50, temp=1.0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(X_list)\n",
    "    idx = np.arange(n); rng.shuffle(idx)\n",
    "    n_te = max(1, int(0.2*n))\n",
    "    te_idx, tr_idx = idx[:n_te], idx[n_te:]\n",
    "\n",
    "    # object arrays (ragged ok)\n",
    "    X_obj = np.array([np.asarray(x, dtype=np.float32) for x in X_list], dtype=object)\n",
    "    A_obj = np.array([np.asarray(a, dtype=np.int64) for a in A_list], dtype=object)\n",
    "    Y_obj = np.array([np.asarray(y, dtype=np.float32) for y in Y_list], dtype=object)\n",
    "\n",
    "    # history embeddings\n",
    "    Phi = build_history_features(X_obj, A_obj, Y_obj, d_latent=d_latent, seed=seed)\n",
    "    Phi_tr = Phi[tr_idx]; A_tr = A_obj[tr_idx]; Y_tr = Y_obj[tr_idx]\n",
    "    Phi_te = Phi[te_idx]; A_te = A_obj[te_idx]; Y_te = Y_obj[te_idx]\n",
    "\n",
    "    # flatten to visit-level\n",
    "    phi_tr_flat, A_tr_flat, Y_tr_flat = flatten_time(Phi_tr, A_tr, Y_tr)\n",
    "    phi_te_flat, A_te_flat, Y_te_flat = flatten_time(Phi_te, A_te, Y_te)\n",
    "\n",
    "    # fit outcome model: y ~ [phi, onehot(a)] + bias\n",
    "    a0 = (A_tr_flat==0).astype(np.float32).reshape(-1,1)\n",
    "    a1 = (A_tr_flat==1).astype(np.float32).reshape(-1,1)\n",
    "    Z_out_tr = np.concatenate([phi_tr_flat, a0, a1], axis=1)\n",
    "    out_W = ridge_regression_fit(add_bias(Z_out_tr), Y_tr_flat, l2=1e-2)\n",
    "\n",
    "    # fit propensity: a ~ phi + bias\n",
    "    prop_W = logistic_regression_fit(add_bias(phi_tr_flat), A_tr_flat.astype(np.float32),\n",
    "                                     l2=1e-3, lr=0.1, epochs=300, batch=2048, seed=seed)\n",
    "\n",
    "    # DR-kNN mu(a|H) on test\n",
    "    mu0 = dr_knn_mu(phi_tr_flat, A_tr_flat, Y_tr_flat, phi_te_flat, a_query=0,\n",
    "                    out_W=out_W, prop_W=prop_W, k=k, temp=temp)\n",
    "    mu1 = dr_knn_mu(phi_tr_flat, A_tr_flat, Y_tr_flat, phi_te_flat, a_query=1,\n",
    "                    out_W=out_W, prop_W=prop_W, k=k, temp=temp)\n",
    "\n",
    "    # evaluation proxy: observed-treatment MSE\n",
    "    y_pred_obs = np.where(A_te_flat==1, mu1, mu0)\n",
    "    mse = float(np.mean((Y_te_flat - y_pred_obs)**2))\n",
    "\n",
    "    # simple policy: treat if mu1 > mu0, DR value estimate\n",
    "    policy = (mu1 > mu0).astype(np.int64)\n",
    "    # propensity for observed A on test\n",
    "    e_te = logistic_regression_predict_proba(prop_W, add_bias(phi_te_flat))\n",
    "    e_te = np.where(A_te_flat==1, e_te, 1.0 - e_te)\n",
    "    # m_obs (outcome regression at observed A)\n",
    "    a0_te = (A_te_flat==0).astype(np.float32).reshape(-1,1)\n",
    "    a1_te = (A_te_flat==1).astype(np.float32).reshape(-1,1)\n",
    "    Z_out_te = np.concatenate([phi_te_flat, a0_te, a1_te], axis=1)\n",
    "    m_obs = ridge_regression_predict(out_W, add_bias(Z_out_te))\n",
    "    dr_value = float(np.mean(((policy==A_te_flat)/np.clip(e_te,1e-3,1-1e-3)) * (Y_te_flat - m_obs)\n",
    "                             + (policy*mu1 + (1-policy)*mu0)))\n",
    "\n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"dr_value\": dr_value,\n",
    "        \"mu0\": mu0, \"mu1\": mu1,\n",
    "        \"A_te\": A_te_flat, \"Y_te\": Y_te_flat\n",
    "    }\n",
    "def knn_mu(phi_tr, A_tr, Y_tr, query_phi, a_query, k=50, temp=1.0):\n",
    "    mask = (A_tr==a_query)\n",
    "    X = phi_tr[mask]; y = Y_tr[mask]\n",
    "    # exact kNN if no hnswlib\n",
    "    d2 = ((query_phi[:,None,:]-X[None,:,:])**2).sum(2)\n",
    "    idx = np.argsort(d2,1)[:, :min(k, len(X))]\n",
    "    d  = np.take_along_axis(d2, idx, axis=1)\n",
    "    W = np.exp(-d/ max(temp,1e-6)); W /= (W.sum(1,keepdims=True)+1e-8)\n",
    "    return (W * y[idx]).sum(1)\n",
    "def tlearner():\n",
    "    # train\n",
    "    Z0, y0 = phi_tr_flat[A_tr_flat==0], Y_tr_flat[A_tr_flat==0]\n",
    "    Z1, y1 = phi_tr_flat[A_tr_flat==1], Y_tr_flat[A_tr_flat==1]\n",
    "    W0 = ridge_regression_fit(add_bias(Z0), y0, l2=1e-2)\n",
    "    W1 = ridge_regression_fit(add_bias(Z1), y1, l2=1e-2)\n",
    "    # predict potential outcomes on test\n",
    "    mu0 = ridge_regression_predict(W0, add_bias(phi_te_flat))\n",
    "    mu1 = ridge_regression_predict(W1, add_bias(phi_te_flat))\n",
    "    # compute MSE & DR value as before\n",
    "def msm():\n",
    "    e = logistic_regression_predict_proba(prop_W, add_bias(phi_te_flat))\n",
    "    e_obs = np.where(A_te_flat==1, e, 1-e)\n",
    "    # simple (non-sequential) stabilized weight per visit\n",
    "    pA = A_te_flat.mean()  # crude marginal; or per-time-bin marginal\n",
    "    num = np.where(A_te_flat==1, pA, 1-pA)\n",
    "    w = num / np.clip(e_obs,1e-3,1-1e-3)\n",
    "    # weighted outcome difference\n",
    "    tau_msm = np.average(Y_te_flat, weights=w*(A_te_flat==1)) - np.average(Y_te_flat, weights=w*(A_te_flat==0))\n",
    "# ================== Example call ==================\n",
    "# results = run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=1337, k=50, temp=1.0)\n",
    "# print(\"Observed-treatment MSE:\", results[\"mse\"])\n",
    "# print(\"DR value (treat if mu1>mu0):\", results[\"dr_value\"])\n",
    "# seeds = [1,2,3,4,5,6,7,8,9,10]\n",
    "# rows = []\n",
    "# for s in seeds:\n",
    "#     res = run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=s, k=50, temp=1.0)\n",
    "#     rows.append((s, res[\"mse\"], res[\"dr_value\"]))\n",
    "#     arr = np.array([[r[1], r[2]] for r in rows], dtype=float)\n",
    "#     m_mse, m_dr = arr.mean(0)\n",
    "#     s_mse, s_dr = arr.std(0, ddof=1)\n",
    "#     print(f\"MSE: {m_mse:.4f} ± {1.96*s_mse/np.sqrt(len(seeds)):.4f}\")\n",
    "#     print(f\"DR value: {m_dr:.4f} ± {1.96*s_dr/np.sqrt(len(seeds)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf0d533-65e8-46fd-a957-82015770fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def asof_per_patient(left_df, right_df, id_col, left_time, right_time, outcome_col,direction=\"forward\", allow_exact_matches=True):\n",
    "    out = []\n",
    "    for pid, L in left_df.groupby(id_col, sort=False):\n",
    "        R = right_df[right_df[id_col] == pid]\n",
    "        if L.empty:\n",
    "            continue\n",
    "        # sort & drop NaT within this patient\n",
    "        L = L.copy(); R = R.copy()\n",
    "        L[left_time] = pd.to_datetime(L[left_time], errors=\"coerce\").dt.tz_localize(None)\n",
    "        R[right_time] = pd.to_datetime(R[right_time], errors=\"coerce\").dt.tz_localize(None)\n",
    "        L = L[L[left_time].notna()].sort_values(left_time)\n",
    "        R = R[R[right_time].notna()].sort_values(right_time)\n",
    "        if R.empty:\n",
    "            # still add rows with _y_next = NaN to keep alignment if you need it later\n",
    "            tmp = L.copy()\n",
    "            tmp[\"_y_next\"] = np.nan\n",
    "            tmp[\"_y_next_date\"] = pd.NaT\n",
    "        else:\n",
    "            tmp = pd.merge_asof(\n",
    "                L,\n",
    "                R[[id_col, right_time, outcome_col]],\n",
    "                left_on=left_time,\n",
    "                right_on=right_time,\n",
    "                direction=direction,\n",
    "                allow_exact_matches=allow_exact_matches,\n",
    "            ).rename(columns={outcome_col: \"_y_next\", right_time: \"_y_next_date\"})\n",
    "        out.append(tmp)\n",
    "    return pd.concat(out, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def _clean_for_asof(df, id_col, time_col):\n",
    "    df = df.copy()\n",
    "    # parse to timezone-naive datetimes\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors='coerce').dt.tz_localize(None)\n",
    "    # drop rows with missing id or time (asof requires non-null)\n",
    "    df = df[df[id_col].notna() & df[time_col].notna()]\n",
    "    # sort by id then time (required for asof with \"by\")\n",
    "    df = df.sort_values([id_col, time_col])\n",
    "    # optional: drop duplicate rows on (id,time) if they exist\n",
    "    df = df.drop_duplicates(subset=[id_col, time_col])\n",
    "    return df\n",
    "def build_triplets_from_XA_and_outcome(\n",
    "    X_visit, outcome_df,\n",
    "    id_col=\"PARTICIPANT_ID\",\n",
    "    visit_col=\"VISIT_START_DATE\",\n",
    "    A_col=\"A_booster\",\n",
    "    outcome_col=\"pasc_score\",\n",
    "    outcome_date_col=\"date\",\n",
    "    outcome_mode=\"next_value\",\n",
    "    max_forward_days=None\n",
    "):\n",
    "    dfX = _clean_for_asof(X_visit, id_col, visit_col)\n",
    "    dfY = _clean_for_asof(outcome_df, id_col, outcome_date_col)\n",
    "\n",
    "    # feature columns (exclude id/date/A and non-numeric)\n",
    "    exclude = {id_col, visit_col, A_col}\n",
    "    non_numeric = set(dfX.select_dtypes(include=[\"object\"]).columns)\n",
    "    X_cols = [c for c in dfX.columns if c not in exclude and c not in non_numeric]\n",
    "\n",
    "    # NEXT outcome after each visit (no leakage)\n",
    "    # out_next = (\n",
    "    #     pd.merge_asof(\n",
    "    #         dfX[[id_col, visit_col]],\n",
    "    #         dfY[[id_col, outcome_date_col, outcome_col]],\n",
    "    #         by=id_col,\n",
    "    #         left_on=visit_col,\n",
    "    #         right_on=outcome_date_col,\n",
    "    #         direction=\"forward\",\n",
    "    #         allow_exact_matches=True,\n",
    "    #     )\n",
    "    #     .rename(columns={outcome_col: \"_y_next\", outcome_date_col: \"_y_next_date\"})\n",
    "    # )\n",
    "    # Use it like:\n",
    "    left  = dfX[[id_col, visit_col]].copy()\n",
    "    right = dfY[[id_col, outcome_date_col, outcome_col]].copy()\n",
    "    out_next = asof_per_patient(\n",
    "        left_df=left, right_df=right,\n",
    "        id_col=id_col, left_time=visit_col, right_time=outcome_date_col,outcome_col=outcome_col,\n",
    "        direction=\"forward\", allow_exact_matches=True\n",
    "    ).rename(columns={outcome_col: \"_y_next\", outcome_date_col: \"_y_next_date\"})\n",
    "    \n",
    "\n",
    "\n",
    "    if max_forward_days is not None:\n",
    "        dt = (out_next[\"_y_next_date\"] - dfX[visit_col]).dt.days\n",
    "        out_next.loc[dt > max_forward_days, \"_y_next\"] = np.nan\n",
    "\n",
    "    if outcome_mode == \"delta_next\":\n",
    "        left  = dfX[[id_col, visit_col]].copy()\n",
    "        right = dfY[[id_col, outcome_date_col, outcome_col]].copy()\n",
    "        # out_prev = asof_per_patient(\n",
    "        #     left_df=left, right_df=right,\n",
    "        #     id_col=id_col, left_time=visit_col, right_time=outcome_date_col,outcome_col=outcome_col,\n",
    "        #     direction=\"backward\", allow_exact_matches=True\n",
    "        # ).rename(columns={outcome_col: \"_y_prev\"})       \n",
    "        # backward (previous outcome)\n",
    "        out_prev = asof_per_patient(\n",
    "            left_df=left, right_df=right,\n",
    "            id_col=id_col, left_time=visit_col, right_time=outcome_date_col, outcome_col=outcome_col,\n",
    "            direction=\"backward\", allow_exact_matches=True\n",
    "        )\n",
    "        # <-- rename the columns that asof_per_patient created\n",
    "        out_prev = out_prev.rename(columns={\"_y_next\": \"_y_prev\", \"_y_next_date\": \"_y_prev_date\"})\n",
    "        \n",
    "        # now this works:\n",
    "        aligned = pd.concat([dfX[[id_col, visit_col]], out_next[\"_y_next\"], out_prev[\"_y_prev\"]], axis=1)\n",
    "        aligned[\"Y_t\"] = aligned[\"_y_next\"] - aligned[\"_y_prev\"]\n",
    "        # out_prev = (\n",
    "        #     pd.merge_asof(\n",
    "        #         dfX[[id_col, visit_col]],\n",
    "        #         dfY[[id_col, outcome_date_col, outcome_col]],\n",
    "        #         by=id_col,\n",
    "        #         left_on=visit_col,\n",
    "        #         right_on=outcome_date_col,\n",
    "        #         direction=\"backward\",\n",
    "        #         allow_exact_matches=True,\n",
    "        #     ).rename(columns={outcome_col: \"_y_prev\"})\n",
    "        # )\n",
    "        # aligned = pd.concat([dfX[[id_col, visit_col]], out_next[\"_y_next\"], out_prev[\"_y_prev\"]], axis=1)\n",
    "        # aligned[\"Y_t\"] = aligned[\"_y_next\"] - aligned[\"_y_prev\"]\n",
    "    elif outcome_mode == \"next_value\":\n",
    "        aligned = pd.concat([dfX[[id_col, visit_col]], out_next[\"_y_next\"]], axis=1)\n",
    "        aligned[\"Y_t\"] = aligned[\"_y_next\"]\n",
    "    else:\n",
    "        raise ValueError(\"outcome_mode must be 'next_value' or 'delta_next'.\")\n",
    "\n",
    "    # Keep visits with a follow-up outcome\n",
    "    keep = ~aligned[\"Y_t\"].isna()\n",
    "    dfX_kept = dfX.loc[keep].copy()\n",
    "    aligned = aligned.loc[keep].copy()\n",
    "\n",
    "    # Collect ragged sequences\n",
    "    X_list, A_list, Y_list = [], [], []\n",
    "    for pid, gX in dfX_kept.groupby(id_col):\n",
    "        gX = gX.sort_values(visit_col)\n",
    "        X_arr = gX[X_cols].to_numpy(dtype=\"float32\")\n",
    "        A_arr = gX[A_col].astype(\"int8\").to_numpy()\n",
    "        Y_arr = aligned.loc[gX.index, \"Y_t\"].astype(\"float32\").to_numpy()\n",
    "        if len(X_arr) == 0: \n",
    "            continue\n",
    "        X_list.append(X_arr); A_list.append(A_arr); Y_list.append(Y_arr)\n",
    "\n",
    "    return np.array(X_list, dtype=object), np.array(A_list, dtype=object), np.array(Y_list, dtype=object), X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcabec47-0818-4f95-8fa7-3d9449cf5ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4ea26-036e-4788-8456-18558106a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_dose1\n",
      "221.857563495636\n",
      "A_dose2\n",
      "221.19806933403015\n",
      "A_dose3\n",
      "223.66928029060364\n",
      "A_dose4\n",
      "222.82362914085388\n",
      "A_vax_any\n",
      "223.52686429023743\n",
      "hello  A_dose1\n",
      "run   237.82792854309082\n",
      "hello  A_dose2\n",
      "run   238.00918054580688\n",
      "hello  A_dose3\n",
      "run   237.05921697616577\n",
      "hello  A_dose4\n",
      "run   237.35303401947021\n",
      "hello  A_vax_any\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import time\n",
    "ACTIONS = [\"A_dose1\",\"A_dose2\",\"A_dose3\",\"A_dose4\",\"A_vax_any\"]\n",
    "SEEDS   = [1,2,3,4,5]#,6,7,8,9,10]   # shrink to e.g. [1,2,3,4,5] for speed\n",
    "ID_COL, VISIT_COL = \"PARTICIPANT_ID\", \"VISIT_START_DATE\"\n",
    "OUTCOME_NAME, OUTCOME_DATE, OUTCOME_MODE, MAX_FORWARD_DAYS = \"pasc_score\",\"date\",\"delta_next\",120\n",
    "\n",
    "def zscore_Y(Y_list):\n",
    "    all_y = np.concatenate([y for y in Y_list]) if len(Y_list) else np.array([0.])\n",
    "    mu, sd = all_y.mean(), all_y.std() or 1.0\n",
    "    return np.array([(y - mu)/sd for y in Y_list], dtype=object)\n",
    "\n",
    "# 1) Precompute (X,A,Y) ONCE per action (this is the big time saver)\n",
    "triplet_cache = {}\n",
    "for A_col in ACTIONS:\n",
    "    start_time = time.time()\n",
    "    print(A_col)\n",
    "    X_list, A_list, Y_list, _ = build_triplets_from_XA_and_outcome(\n",
    "        X_visit=X_visit_with_A, outcome_df=pasc_df,\n",
    "        id_col=ID_COL, visit_col=VISIT_COL,\n",
    "        A_col=A_col, outcome_col=OUTCOME_NAME, outcome_date_col=OUTCOME_DATE,\n",
    "        outcome_mode=OUTCOME_MODE, max_forward_days=MAX_FORWARD_DAYS\n",
    "    )\n",
    "    # optional standardization (consistent across seeds)\n",
    "    Y_list_std = zscore_Y(Y_list)\n",
    "    triplet_cache[A_col] = (X_list, A_list, Y_list_std)\n",
    "    end_time = time.time()\n",
    "    print(end_time - start_time)\n",
    "# 2) Run seeds WITHOUT rebuilding triplets\n",
    "rows = []\n",
    "for A_col in ACTIONS:\n",
    "    print(\"hello \", A_col)\n",
    "    start_time = time.time()\n",
    "    X_list, A_list, Y_list_std = triplet_cache[A_col]\n",
    "    for s in SEEDS:\n",
    "        res = run_cknn_numpy(X_list, A_list, Y_list_std, d_latent=16, seed=s, k=50, temp=1.0)\n",
    "        rows.append({\"action\": A_col, \"seed\": s, \"mse\": res[\"mse\"], \"dr_value\": res[\"dr_value\"]})\n",
    "    end_time = time.time()\n",
    "    print(\"run  \", end_time - start_time)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 3) Summarize mean ± 95% CI\n",
    "def summarize(group, col):\n",
    "    mean = group[col].mean()\n",
    "    sem  = group[col].std(ddof=1) / max(1, np.sqrt(len(group)))\n",
    "    ci95 = 1.96 * sem\n",
    "    return pd.Series({f\"{col}_mean\": mean, f\"{col}_ci95\": ci95})\n",
    "\n",
    "summary = (df.groupby(\"action\")\n",
    "             .apply(lambda g: pd.concat([summarize(g,\"mse\"), summarize(g,\"dr_value\")]))\n",
    "             .reset_index(drop=False)\n",
    "          )\n",
    "\n",
    "print(summary.sort_values(\"action\"))\n",
    "summary.to_csv(\"cknn_vax_actions_summary_nodupp.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c208e68-720c-480c-ba1f-b2d0fc471ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_visit_with_A=pd.read_csv('X_visit_with_A.csv')\n",
    "pasc_df = pd.read_csv('y_pasc_score2024.csv')\n",
    "# pasc_df.head()\n",
    "pasc_df.rename({\"pasc_score_2024\":\"pasc_score\"},axis=\"columns\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96216477-6024-475a-b0cd-f2d212e21fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_actions_methods import compare_actions_methods\n",
    "\n",
    "ACTIONS = [\"A_dose1\",\"A_dose2\",\"A_dose3\",\"A_dose4\",\"A_vax_any\"]  # (you already ran A_booster)\n",
    "\n",
    "df_all, summary_all = compare_actions_methods(\n",
    "    X_visit_df=X_visit_with_A,      # must include PARTICIPANT_ID, VISIT_START_DATE, and all A_* columns + features\n",
    "    outcome_df=pasc_df,             # or depression_df\n",
    "    actions=ACTIONS,\n",
    "    id_col=\"PARTICIPANT_ID\",\n",
    "    visit_col=\"VISIT_START_DATE\",\n",
    "    outcome_col=\"pasc_score\",       # or \"depression_score\"\n",
    "    outcome_date_col=\"date\",\n",
    "    outcome_mode=\"delta_next\",      # or \"next_value\"\n",
    "    max_forward_days=120,\n",
    "    seeds=[1,2,3,4,5,6,7,8,9,10],   # paper-ready mean ± 95% CI\n",
    "    encoder=\"gru\", d_latent=16, hidden=64,\n",
    "    # encoder=\"identity\",\n",
    "    k=50, temp=1.0,\n",
    "    enc_epochs=5, head_epochs=10, batch_size=64, lr=1e-3,\n",
    "    test_frac=0.2, use_cuda=True,\n",
    "    standardize_y=False             # set True to z-score Y within each action experiment\n",
    ")\n",
    "\n",
    "print(summary_all.head())\n",
    "# Optional: persist\n",
    "df_all.to_csv(\"all_methods_per_seed.csv\", index=False)\n",
    "summary_all.to_csv(\"all_methods_summary.csv\", index=False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1a03be-1f2c-4a58-bba0-ef9a7a775859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb0b05-41f7-4ee0-9f31-181be297e5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
