{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbcc544-89f8-4ed4-8012-282b466d4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unsloth\n",
    "# !pip install huggingface\n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d1274c-0a5e-45c0-99e0-7e068858c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.12.9: Fast Qwen3 patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    Tesla V100-SXM2-16GB. Num GPUs = 1. Max memory: 15.766 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd8b0c946c442cca4e754485c76c08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5aabac3ec5462bbb6f8115ebd8eee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe75fd6c129a491386a1fc67a48687c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24887651b29c404c818103f81dafe782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44cf7f1c1294fe98200c1f42ab57687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517171ad846e474e9a4dd4ad8e4f8bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83034ad46ec346be8eb4e78c85deaa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f200f14659b403e867d4c70fd3ed376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd58f2d2c0bf4643bb48ea9e12389fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0fd6887bdd46f79d0bd05a9fd0c5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609bec87b41d466d8c34d902031b52e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60c87d2c7b94616ae214a4c416745f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f007a768ec419d8cd8ff384d52b635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a094c5860444778a333be4332db55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "fourbit_models = [\n",
    "    \"unsloth/Qwen3-1.7B-unsloth-bnb-4bit\", # Qwen 14B 2x faster\n",
    "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-32B-unsloth-bnb-4bit\",\n",
    "\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Phi-4\",\n",
    "    \"unsloth/Llama-3.1-8B\",\n",
    "    \"unsloth/Llama-3.2-3B\",\n",
    "    \"unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit\" # [NEW] We support TTS models!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "model_name = \"unsloth/Qwen3-14B-unsloth-bnb-4bit\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # or torch.float16 if no bf16\n",
    "    llm_int8_enable_fp32_cpu_offload=True,  # key for offloading\n",
    ")\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=8048,          # consider lowering if you still OOM\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",            # let HF shard between GPU/CPU\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2189972-8e78-458a-9028-c49376b9dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "datafold = \"/sbgenomics/project-files/\"\n",
    "file = \"y_pasc_score2024.csv\"\n",
    "# file = \"RECOVERAdult_BiostatsDerived_202412_symptoms_deID.csv\"\n",
    "result = pd.read_csv(datafold + file)\n",
    "result = result.rename(columns={\"PARTICIPANT_ID\":\"id\", \"pasc_score_2024\":\"name\"})\n",
    "result['index'] = \"pasc_score_2024\"\n",
    "result_reordered = result.iloc[:, [0, 3,1,2]]\n",
    "# file = \"all_methods_summary.csv\"\n",
    "file = \"vaccine_2026.csv\"\n",
    "df = pd.read_csv(datafold + file)\n",
    "df=df.iloc[:, [1, 2, 3,4]]\n",
    "combined_df = pd.concat([result_reordered, df], ignore_index=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5555118-20d6-4b02-a7cf-5f09de672462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>pasc_score_2024</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>pasc_score_2024</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>pasc_score_2024</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>pasc_score_2024</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>pasc_score_2024</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            index        date  name\n",
       "0  RA11305  pasc_score_2024  2021-01-01  16.0\n",
       "1  RA11305  pasc_score_2024  2021-04-03  14.0\n",
       "2  RA11305  pasc_score_2024  2021-06-28   8.0\n",
       "3  RA11305  pasc_score_2024  2021-09-28  13.0\n",
       "4  RA11305  pasc_score_2024  2021-12-23  10.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a858ee-6586-42dd-bf16-fae6b0c7e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13451\n",
      "(313, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# B = \"pasc_score_2024\"  # set your target value\n",
    "# out = combined_df.groupby(\"id\").filter(lambda g: (g[\"index\"] == B).sum() > 4)\n",
    "# print(out.shape)#282581, 4)\n",
    "\n",
    "ids = np.unique(out['id'])\n",
    "print(len(ids)) #15158 13451\n",
    "index = 5\n",
    "\n",
    "selected_ids = [id_value for id_value in ids[5:20]] # Make sure ids is just the list of values\n",
    "output_ind_df = combined_df[combined_df['id'].isin(selected_ids)]\n",
    "\n",
    "# output_ind_df = combined_df[combined_df['id']==ids[index]]\n",
    "print(output_ind_df.shape)\n",
    "# df_new = output_ind_df.drop(columns=['id'])\n",
    "output_ind = output_ind_df.to_string(index=True, header=True)\n",
    "# output_string = combined_df.to_string(index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a4b63c-e9c6-4542-8aaa-474e91160bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_ind_df\n",
    "prompt = (\n",
    "\"\"\"You are a clinical, medical, physician, and statistical expert.\n",
    "\n",
    "You will be given a table for several patient with columns:\n",
    "- id: patient id\n",
    "- date: date of record\n",
    "- index: 0=enrollment; 1/2/3/4=vaccine dose number; \"followup\" or \"followup_k\"=follow-up visit, pasc=wellness score (lower is better). Threshold: >=12 = Long COVID (PASC), <12 = No PASC.\n",
    "- name: free-text description (may include vaccine brand like pfizer/moderna/etc, and may contain notes, if it is value, then pasc)\n",
    "- (optional) followup_2: \"no\" means no vaccine between this visit and the previous visit; \"yes\" means a vaccine occurred between visits.\n",
    "\n",
    "Important notes:\n",
    "- Vaccines may occur before enrollment (index=0).\n",
    "- Dates may be out of order in the raw text; sort by date when building a timeline.\n",
    "- If vaccine brand is ambiguous/misspelled (e.g., \"pfzier\"), normalize to the closest common brand and also keep the raw string.\n",
    "\n",
    "TASKS\n",
    "Write a concise summary,sStart a section exactly titled: #Summary\n",
    "   In #Summary include:\n",
    "   - 3–5 sentences describing the patients’ course, key events, and strongest observed associations of the longitudal information\n",
    "\n",
    "INPUT TABLE :\n",
    "\"\"\"\n",
    "+ output_ind +\n",
    "\"\"\"\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cda6b19-4803-430c-aa1f-6b239cfadc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "You are a clinical, medical, physician, and statistical expert.\n",
      "\n",
      "You will be given a table for several patient with columns:\n",
      "- id: patient id\n",
      "- date: date of record\n",
      "- index: 0=enrollment; 1/2/3/4=vaccine dose number; \"followup\" or \"followup_k\"=follow-up visit, pasc_score_2024=wellness score (lower is better). Threshold: >=12 = Long COVID (PASC), <12 = No PASC.\n",
      "- name: free-text description (may include vaccine brand like pfizer/moderna/etc, and may contain notes, if it is value, then pasc_score_2024)\n",
      "- (optional) followup_2: \"no\" means no vaccine between this visit and the previous visit; \"yes\" means a vaccine occurred between visits.\n",
      "\n",
      "Important notes:\n",
      "- Vaccines may occur before enrollment (index=0).\n",
      "- Dates may be out of order in the raw text; sort by date when building a timeline.\n",
      "- If vaccine brand is ambiguous/misspelled (e.g., \"pfzier\"), normalize to the closest common brand and also keep the raw string.\n",
      "\n",
      "TASKS\n",
      "Write a concise summary,sStart a section exactly titled: #Summary\n",
      "   In #Summary include:\n",
      "   - 3–5 sentences describing the patients’ course, key events, and strongest observed associations of the longitudal information\n",
      "\n",
      "INPUT TABLE :\n",
      "              id            index        date        name\n",
      "15556   RA110001  pasc_score_2024  2022-01-01        19.0\n",
      "15557   RA110001  pasc_score_2024  2022-04-03         0.0\n",
      "15558   RA110001  pasc_score_2024  2022-05-27         0.0\n",
      "15559   RA110001  pasc_score_2024  2022-09-17         3.0\n",
      "15560   RA110001  pasc_score_2024  2022-12-23         5.0\n",
      "15561   RA110001  pasc_score_2024  2023-03-19        16.0\n",
      "15562   RA110001  pasc_score_2024  2023-06-11        13.0\n",
      "15563   RA110001  pasc_score_2024  2023-09-18        11.0\n",
      "15564   RA110001  pasc_score_2024  2023-11-26         7.0\n",
      "29216   RA110008  pasc_score_2024  2022-01-01         9.0\n",
      "29217   RA110008  pasc_score_2024  2022-03-04         NaN\n",
      "29218   RA110008  pasc_score_2024  2022-06-02         0.0\n",
      "29219   RA110008  pasc_score_2024  2022-08-31         3.0\n",
      "29220   RA110008  pasc_score_2024  2022-11-19         NaN\n",
      "29221   RA110008  pasc_score_2024  2023-02-24         2.0\n",
      "29222   RA110008  pasc_score_2024  2023-05-30         0.0\n",
      "29223   RA110008  pasc_score_2024  2023-08-29         2.0\n",
      "29224   RA110008  pasc_score_2024  2023-11-24         5.0\n",
      "37186   RA110016  pasc_score_2024  2022-01-01         0.0\n",
      "37187   RA110016  pasc_score_2024  2022-02-21         0.0\n",
      "37188   RA110016  pasc_score_2024  2022-05-28         0.0\n",
      "37189   RA110016  pasc_score_2024  2022-08-01         0.0\n",
      "37190   RA110016  pasc_score_2024  2022-11-07         0.0\n",
      "37191   RA110016  pasc_score_2024  2022-12-25         0.0\n",
      "37192   RA110016  pasc_score_2024  2023-06-15         0.0\n",
      "37193   RA110016  pasc_score_2024  2023-08-13         NaN\n",
      "37194   RA110016  pasc_score_2024  2023-11-23         0.0\n",
      "37195   RA110016  pasc_score_2024  2024-03-30         NaN\n",
      "39835   RA110010  pasc_score_2024  2023-01-01         0.0\n",
      "39836   RA110010  pasc_score_2024  2023-04-01         0.0\n",
      "39837   RA110010  pasc_score_2024  2023-08-19         0.0\n",
      "39838   RA110010  pasc_score_2024  2023-10-13         0.0\n",
      "39839   RA110010  pasc_score_2024  2023-12-23         0.0\n",
      "39840   RA110010  pasc_score_2024  2024-03-17         0.0\n",
      "39841   RA110010  pasc_score_2024  2024-06-16         0.0\n",
      "39842   RA110010  pasc_score_2024  2024-09-19         0.0\n",
      "45865   RA110002  pasc_score_2024  2022-01-01         5.0\n",
      "45866   RA110002  pasc_score_2024  2022-07-17         0.0\n",
      "45867   RA110002  pasc_score_2024  2022-09-01         0.0\n",
      "45868   RA110002  pasc_score_2024  2022-11-30         0.0\n",
      "45869   RA110002  pasc_score_2024  2023-03-01         0.0\n",
      "45870   RA110002  pasc_score_2024  2023-06-21         NaN\n",
      "45871   RA110002  pasc_score_2024  2023-09-05         NaN\n",
      "45872   RA110002  pasc_score_2024  2023-12-03         NaN\n",
      "47267   RA110009  pasc_score_2024  2023-02-13         2.0\n",
      "47268   RA110009  pasc_score_2024  2023-04-13         0.0\n",
      "47269   RA110009  pasc_score_2024  2023-06-25         2.0\n",
      "47270   RA110009  pasc_score_2024  2023-09-25        10.0\n",
      "47271   RA110009  pasc_score_2024  2024-01-04         2.0\n",
      "47272   RA110009  pasc_score_2024  2024-04-06         2.0\n",
      "47273   RA110009  pasc_score_2024  2024-06-30         NaN\n",
      "47274   RA110009  pasc_score_2024         NaN         NaN\n",
      "52277   RA110003  pasc_score_2024  2022-01-01         0.0\n",
      "52278   RA110003  pasc_score_2024  2022-05-15         1.0\n",
      "52279   RA110003  pasc_score_2024  2022-08-01         5.0\n",
      "52280   RA110003  pasc_score_2024  2022-10-29         1.0\n",
      "52281   RA110003  pasc_score_2024  2023-01-31         0.0\n",
      "52282   RA110003  pasc_score_2024  2023-05-07         0.0\n",
      "52283   RA110003  pasc_score_2024  2023-08-20         1.0\n",
      "52284   RA110003  pasc_score_2024  2023-10-24         NaN\n",
      "52285   RA110003  pasc_score_2024  2024-01-20         NaN\n",
      "52286   RA110003  pasc_score_2024  2024-05-12         0.0\n",
      "59091   RA110014  pasc_score_2024  2022-01-01         0.0\n",
      "59092   RA110014  pasc_score_2024  2022-03-26         0.0\n",
      "59093   RA110014  pasc_score_2024  2022-06-24         0.0\n",
      "59094   RA110014  pasc_score_2024  2022-09-22         0.0\n",
      "59095   RA110014  pasc_score_2024  2022-12-22         0.0\n",
      "59096   RA110014  pasc_score_2024  2023-03-19         NaN\n",
      "59097   RA110014  pasc_score_2024  2023-06-17         0.0\n",
      "59098   RA110014  pasc_score_2024  2023-09-15         4.0\n",
      "59099   RA110014  pasc_score_2024  2023-12-16         0.0\n",
      "67878   RA110013  pasc_score_2024  2022-01-02         7.0\n",
      "67879   RA110013  pasc_score_2024  2022-04-01         1.0\n",
      "67880   RA110013  pasc_score_2024  2022-06-18         0.0\n",
      "67881   RA110013  pasc_score_2024  2022-09-16         NaN\n",
      "67882   RA110013  pasc_score_2024  2022-12-01         0.0\n",
      "67883   RA110013  pasc_score_2024  2023-03-16         1.0\n",
      "67884   RA110013  pasc_score_2024  2023-06-22         NaN\n",
      "67885   RA110013  pasc_score_2024  2023-08-25         1.0\n",
      "67886   RA110013  pasc_score_2024  2023-12-10         0.0\n",
      "67887   RA110013  pasc_score_2024  2024-03-07         0.0\n",
      "82230   RA110011  pasc_score_2024  2022-01-01         1.0\n",
      "82231   RA110011  pasc_score_2024  2022-05-23         0.0\n",
      "82232   RA110011  pasc_score_2024  2022-08-22         0.0\n",
      "82233   RA110011  pasc_score_2024  2022-12-02         0.0\n",
      "82234   RA110011  pasc_score_2024  2023-02-04         0.0\n",
      "82235   RA110011  pasc_score_2024  2023-05-25         0.0\n",
      "82236   RA110011  pasc_score_2024  2023-08-18         0.0\n",
      "82237   RA110011  pasc_score_2024  2023-12-10         0.0\n",
      "82238   RA110011  pasc_score_2024  2024-02-11         0.0\n",
      "82239   RA110011  pasc_score_2024  2024-05-11         0.0\n",
      "82240   RA110011  pasc_score_2024  2024-08-12         0.0\n",
      "82542   RA110015  pasc_score_2024  2022-01-01         3.0\n",
      "82543   RA110015  pasc_score_2024  2022-04-20        25.0\n",
      "82544   RA110015  pasc_score_2024  2022-07-17         6.0\n",
      "82545   RA110015  pasc_score_2024  2022-10-25        12.0\n",
      "82546   RA110015  pasc_score_2024  2022-12-31        12.0\n",
      "82547   RA110015  pasc_score_2024  2023-04-22         7.0\n",
      "82548   RA110015  pasc_score_2024  2023-07-11         6.0\n",
      "82549   RA110015  pasc_score_2024  2023-10-14        23.0\n",
      "82550   RA110015  pasc_score_2024  2023-12-31        16.0\n",
      "82551   RA110015  pasc_score_2024  2024-04-03        23.0\n",
      "82552   RA110015  pasc_score_2024  2024-07-03        22.0\n",
      "82950   RA110006  pasc_score_2024  2022-01-01         0.0\n",
      "82951   RA110006  pasc_score_2024  2022-02-22        10.0\n",
      "82952   RA110006  pasc_score_2024  2022-05-16         5.0\n",
      "82953   RA110006  pasc_score_2024  2022-09-04         0.0\n",
      "82954   RA110006  pasc_score_2024  2022-11-09        10.0\n",
      "82955   RA110006  pasc_score_2024  2023-02-22         1.0\n",
      "82956   RA110006  pasc_score_2024  2023-05-30        11.0\n",
      "82957   RA110006  pasc_score_2024  2023-08-29         6.0\n",
      "82958   RA110006  pasc_score_2024  2023-11-14         0.0\n",
      "82959   RA110006  pasc_score_2024  2024-02-17        15.0\n",
      "82960   RA110006  pasc_score_2024  2024-05-11         2.0\n",
      "108176  RA110004  pasc_score_2024  2022-01-01         0.0\n",
      "108177  RA110004  pasc_score_2024  2022-03-25         0.0\n",
      "108178  RA110004  pasc_score_2024  2022-06-17         0.0\n",
      "108179  RA110004  pasc_score_2024  2022-09-16         0.0\n",
      "108180  RA110004  pasc_score_2024  2022-12-19         0.0\n",
      "108181  RA110004  pasc_score_2024  2023-03-20         0.0\n",
      "108182  RA110004  pasc_score_2024  2023-06-12         NaN\n",
      "108183  RA110004  pasc_score_2024  2023-09-23         NaN\n",
      "108184  RA110004  pasc_score_2024  2023-12-10         3.0\n",
      "122086  RA110012  pasc_score_2024  2022-01-01         4.0\n",
      "122087  RA110012  pasc_score_2024  2022-04-12         9.0\n",
      "122088  RA110012  pasc_score_2024  2022-06-25        12.0\n",
      "122089  RA110012  pasc_score_2024  2022-08-13         5.0\n",
      "122090  RA110012  pasc_score_2024  2022-10-11         4.0\n",
      "122091  RA110012  pasc_score_2024  2023-05-13         9.0\n",
      "122092  RA110012  pasc_score_2024  2023-09-19        11.0\n",
      "122093  RA110012  pasc_score_2024  2023-11-16         4.0\n",
      "124348  RA110005  pasc_score_2024  2022-01-01         0.0\n",
      "124349  RA110005  pasc_score_2024  2022-05-05         1.0\n",
      "124350  RA110005  pasc_score_2024  2022-08-03         4.0\n",
      "124351  RA110005  pasc_score_2024  2022-11-30         2.0\n",
      "124352  RA110005  pasc_score_2024  2023-02-02         2.0\n",
      "124353  RA110005  pasc_score_2024  2023-05-04         6.0\n",
      "124354  RA110005  pasc_score_2024  2023-08-02         2.0\n",
      "124355  RA110005  pasc_score_2024  2023-11-22         1.0\n",
      "124356  RA110005  pasc_score_2024  2024-02-01         NaN\n",
      "126809  RA110001                0  2022-01-01  enrollment\n",
      "126810  RA110002                0  2022-01-01  enrollment\n",
      "126811  RA110003                0  2022-01-01  enrollment\n",
      "126812  RA110004                0  2022-01-01  enrollment\n",
      "126813  RA110005                0  2022-01-01  enrollment\n",
      "126814  RA110006                0  2022-01-01  enrollment\n",
      "126816  RA110008                0  2022-01-01  enrollment\n",
      "126817  RA110009                0  2023-02-12  enrollment\n",
      "126819  RA110010                0  2023-01-08  enrollment\n",
      "126820  RA110011                0  2022-01-01  enrollment\n",
      "126821  RA110012                0  2022-01-02  enrollment\n",
      "126822  RA110013                0  2022-01-02  enrollment\n",
      "126823  RA110014                0  2022-01-01  enrollment\n",
      "126824  RA110015                0  2022-01-01  enrollment\n",
      "126825  RA110016                0  2022-01-02  enrollment\n",
      "142279  RA110002                1  2020-07-09      Pfizer\n",
      "142641  RA110011                1  2020-09-28      Pfizer\n",
      "145989  RA110001                1  2019-03-07     Moderna\n",
      "145990  RA110001                1  2019-03-07      Pfizer\n",
      "147633  RA110016                1  2020-04-22      Pfizer\n",
      "148485  RA110001                1  2019-03-08     Moderna\n",
      "148486  RA110001                1  2019-03-08      Pfizer\n",
      "150038  RA110001                1  2022-12-24     Moderna\n",
      "150039  RA110001                1  2022-12-24      Pfizer\n",
      "150370  RA110006                1  2020-11-28      Pfizer\n",
      "150944  RA110006                1  2022-01-09      Pfizer\n",
      "153058  RA110011                1  2023-08-06      Pfizer\n",
      "154202  RA110012                1  2020-04-18     Moderna\n",
      "154788  RA110013                1  2023-04-20      Pfizer\n",
      "155365  RA110001                1  2023-10-02     Moderna\n",
      "155366  RA110001                1  2023-10-02      Pfizer\n",
      "156117  RA110005                1  2020-03-05     Moderna\n",
      "157774  RA110013                1  2020-09-02      Pfizer\n",
      "158697  RA110015                1  2021-09-27      Pfizer\n",
      "160508  RA110011                1  2024-07-18      Pfizer\n",
      "164271  RA110013                1  2022-04-15      Pfizer\n",
      "164945  RA110011                1  2022-07-10      Pfizer\n",
      "165932  RA110004                1  2020-10-26      Pfizer\n",
      "166162  RA110009                1  2021-01-31     Moderna\n",
      "166269  RA110014                1  2020-03-07     Moderna\n",
      "166578  RA110009                1  2023-10-10     Moderna\n",
      "168242  RA110016                1  2020-05-03      Pfizer\n",
      "168310  RA110010                1  2021-08-06      Pfizer\n",
      "170197  RA110011                2  2020-10-19      Pfizer\n",
      "170391  RA110002                2  2020-08-02      Pfizer\n",
      "173715  RA110008                2  2021-01-07     Moderna\n",
      "174277  RA110001                2  2019-09-06     Moderna\n",
      "175747  RA110006                2  2020-12-19      Pfizer\n",
      "176601  RA110012                2  2020-05-16     Moderna\n",
      "177521  RA110005                2  2020-04-02     Moderna\n",
      "177912  RA110013                2  2020-09-23      Pfizer\n",
      "178777  RA110015                2  2021-10-31      Pfizer\n",
      "181827  RA110009                2  2021-02-18     Moderna\n",
      "182015  RA110014                2  2020-03-29     Moderna\n",
      "182085  RA110004                2  2020-11-28      Pfizer\n",
      "182969  RA110010                2  2021-10-16      Pfizer\n",
      "183107  RA110016                2  2020-06-01      Pfizer\n",
      "184250  RA110002                3  2021-04-12      Pfizer\n",
      "184871  RA110011                3  2021-07-03      Pfizer\n",
      "186102  RA110001                3  2020-06-02     Moderna\n",
      "188459  RA110006                3  2021-06-27      Pfizer\n",
      "189889  RA110005                3  2021-01-07     Moderna\n",
      "190192  RA110013                3  2021-05-11      Pfizer\n",
      "193342  RA110014                3  2020-11-27     Moderna\n",
      "193351  RA110009                3  2021-11-26     Moderna\n",
      "194325  RA110016                3  2021-02-25      Pfizer\n",
      "195263  RA110001                4  2020-12-27     Moderna\n",
      "199569  RA110009                4  2022-10-06      Pfizer\n",
      "199582  RA110014                4  2021-12-20     Moderna\n",
      "203245  RA110016       followup_3  2022-07-31          No\n",
      "205759  RA110002       followup_3  2022-12-05          No\n",
      "206075  RA110003       followup_2  2022-08-02          No\n",
      "206187  RA110015       followup_3  2022-10-25          No\n",
      "207399  RA110011       followup_3  2022-12-02          No\n",
      "211188  RA110002       followup_4  2023-04-04          No\n",
      "211447  RA110003       followup_3  2022-11-14          No\n",
      "212152  RA110013       followup_4  2022-12-01          No\n",
      "212920  RA110011       followup_4  2023-02-06          No\n",
      "212940  RA110015       followup_4  2022-12-31          No\n",
      "215598  RA110001       followup_6  2023-06-19          No\n",
      "216293  RA110008       followup_6  2023-08-19          No\n",
      "216551  RA110016       followup_8  2023-12-21          No\n",
      "217186  RA110003       followup_4  2023-02-04          No\n",
      "217895  RA110013       followup_5  2023-03-16          No\n",
      "218697  RA110011       followup_5  2023-05-26          No\n",
      "218720  RA110015       followup_5  2023-05-02          No\n",
      "221293  RA110001       followup_7  2023-09-18          No\n",
      "222813  RA110003       followup_5  2023-05-13          No\n",
      "224468  RA110015       followup_6  2023-07-24          No\n",
      "224500  RA110006       followup_2  2022-05-16          No\n",
      "228531  RA110003       followup_6  2023-08-20          No\n",
      "229974  RA110011       followup_7  2023-12-10          No\n",
      "229992  RA110015       followup_7  2023-10-14          No\n",
      "230023  RA110006       followup_3  2022-09-04          No\n",
      "234262  RA110013       followup_8  2023-12-10          No\n",
      "234926  RA110011       followup_8  2024-02-22          No\n",
      "234950  RA110015       followup_8  2024-01-21          No\n",
      "234986  RA110006       followup_4  2022-11-10          No\n",
      "235515  RA110012       followup_2  2022-06-29          No\n",
      "236260  RA110012       followup_1  2022-04-14          No\n",
      "237259  RA110001       followup_1  2022-04-03          No\n",
      "238096  RA110016       followup_4  2022-11-09          No\n",
      "243066  RA110013       followup_9  2024-03-07          No\n",
      "243549  RA110011       followup_9  2024-05-12          No\n",
      "243576  RA110015       followup_9  2024-05-23          No\n",
      "243605  RA110006       followup_5  2023-02-22          No\n",
      "244631  RA110012       followup_3  2022-08-13          No\n",
      "244842  RA110005       followup_1  2022-05-05          No\n",
      "246900  RA110006       followup_6  2023-05-30          No\n",
      "247826  RA110012       followup_4  2022-10-11          No\n",
      "247959  RA110005       followup_2  2022-08-03          No\n",
      "249375  RA110006       followup_7  2023-08-29          No\n",
      "250157  RA110005       followup_3  2022-11-30          No\n",
      "251402  RA110006       followup_8  2023-11-14          No\n",
      "251644  RA110012       followup_5  2023-05-18          No\n",
      "252085  RA110005       followup_4  2023-02-02          No\n",
      "253231  RA110006       followup_9  2024-02-17          No\n",
      "253597  RA110012       followup_6  2023-09-24          No\n",
      "253631  RA110005       followup_5  2023-05-17          No\n",
      "254834  RA110006      followup_10  2024-05-11          No\n",
      "255044  RA110005       followup_6  2023-08-02          No\n",
      "255110  RA110012       followup_7  2023-11-17          No\n",
      "257191  RA110001       followup_2  2022-05-27          No\n",
      "257814  RA110008       followup_2  2022-06-02          No\n",
      "258018  RA110016       followup_5  2023-01-28          No\n",
      "258341  RA110002       followup_1  2022-07-18          No\n",
      "258749  RA110015       followup_1  2022-04-20          No\n",
      "259238  RA110013       followup_1  2022-03-30          No\n",
      "259843  RA110011       followup_1  2022-05-23          No\n",
      "261894  RA110001       followup_3  2022-09-18          No\n",
      "262631  RA110008       followup_3  2022-09-05          No\n",
      "263153  RA110002       followup_2  2022-10-02          No\n",
      "263434  RA110003       followup_1  2022-05-15          No\n",
      "263549  RA110015       followup_2  2022-07-17          No\n",
      "266791  RA110010       followup_3  2023-11-01          No\n",
      "266916  RA110014       followup_4  2022-12-25          No\n",
      "267265  RA110004       followup_4  2022-12-22          No\n",
      "267551  RA110010       followup_4  2024-01-20          No\n",
      "267579  RA110009       followup_5  2024-04-15          No\n",
      "267984  RA110004       followup_5  2023-04-17          No\n",
      "268292  RA110010       followup_5  2024-04-12          No\n",
      "268398  RA110014       followup_6  2023-06-17          No\n",
      "269027  RA110010       followup_6  2024-06-23          No\n",
      "269122  RA110014       followup_7  2023-09-18          No\n",
      "269665  RA110010       followup_7  2024-10-05          No\n",
      "269748  RA110014       followup_8  2023-12-16          No\n",
      "270014  RA110004       followup_8  2023-12-29          No\n",
      "270790  RA110009       followup_1  2023-04-13          No\n",
      "270870  RA110014       followup_1  2022-03-26          No\n",
      "272611  RA110010       followup_1  2023-04-01          No\n",
      "272669  RA110009       followup_2  2023-07-02          No\n",
      "272767  RA110014       followup_2  2022-06-24          No\n",
      "273437  RA110016       followup_2  2022-06-08          No\n",
      "273463  RA110010       followup_2  2023-08-20          No\n",
      "273521  RA110009       followup_3  2023-09-28          No\n",
      "273613  RA110014       followup_3  2022-09-22          No\n",
      "273992  RA110004       followup_3  2022-10-10          No\n",
      "274341  RA110001       followup_4  2022-12-23         Yes\n",
      "274616  RA110016       followup_6  2023-06-26         Yes\n",
      "275655  RA110001       followup_5  2023-03-19         Yes\n",
      "277516  RA110006       followup_1  2022-02-22         Yes\n",
      "278593  RA110011       followup_6  2023-08-19         Yes\n",
      "279000  RA110001       followup_8  2023-12-03         Yes\n",
      "279132  RA110008       followup_8  2023-11-25         Yes\n",
      "279558  RA110013       followup_7  2023-08-25         Yes\n",
      "282527  RA110011      followup_10  2024-08-15         Yes\n",
      "286223  RA110013       followup_2  2022-06-18         Yes\n",
      "286387  RA110011       followup_2  2022-08-25         Yes\n",
      "286744  RA110009       followup_4  2024-01-10         Yes\n",
      "288036  RA110004       followup_1  2022-04-18         Yes\n",
      "288390  RA110016       followup_1  2022-02-24         Yes\n",
      "288537  RA110004       followup_2  2022-07-10         Yes\n",
      "290757  RA110005       followup_7  2023-11-22  Don't know\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Input IDs of shape torch.Size([1, 11669]) with length 11669 > the model's max sequence length of 8048.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 43.44 MiB is free. Process 59509 has 15.72 GiB memory in use. Of the allocated memory 15.14 GiB is allocated by PyTorch, and 196.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m      9\u001b[0m     messages,\n\u001b[1;32m     10\u001b[0m     tokenize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     add_generation_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Must add for generation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextStreamer\n\u001b[0;32m---> 15\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTextStreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:2019\u001b[0m, in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m   2016\u001b[0m     _get_inference_mode_context_manager(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m   2017\u001b[0m     torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m DEVICE_TYPE_TORCH, dtype \u001b[38;5;241m=\u001b[39m dtype),\n\u001b[1;32m   2018\u001b[0m ):\n\u001b[0;32m-> 2019\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# pass\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m restore_training_mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[0;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2787\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2787\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   2790\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   2791\u001b[0m     outputs,\n\u001b[1;32m   2792\u001b[0m     model_kwargs,\n\u001b[1;32m   2793\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2794\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:1270\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1253\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1270\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1280\u001b[0m             xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:1201\u001b[0m, in \u001b[0;36m_LlamaModel_fast_forward_inference.<locals>.LlamaModel_fast_forward_inference_custom\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1193\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X)  \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m X \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(\n\u001b[1;32m   1195\u001b[0m     decoder_layer\u001b[38;5;241m.\u001b[39minput_layernorm,\n\u001b[1;32m   1196\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     variance \u001b[38;5;241m=\u001b[39m variance,\n\u001b[1;32m   1200\u001b[0m )\n\u001b[0;32m-> 1201\u001b[0m X, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[43mattention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m   1211\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X)  \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/qwen3.py:357\u001b[0m, in \u001b[0;36mQwen3Attention_fast_forward_inference\u001b[0;34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[0m\n\u001b[1;32m    353\u001b[0m     Vnn \u001b[38;5;241m=\u001b[39m Vnn[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mexpand(\n\u001b[1;32m    354\u001b[0m         bsz, n_kv_heads, n_groups, cached_len, head_dim\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m     Knn \u001b[38;5;241m=\u001b[39m Knn\u001b[38;5;241m.\u001b[39mreshape(bsz, n_heads, cached_len, head_dim)\n\u001b[0;32m--> 357\u001b[0m     Vnn \u001b[38;5;241m=\u001b[39m \u001b[43mVnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m#     Knn, Vnn = Knn, Vnn\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# pass\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Attention\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bsz \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 43.44 MiB is free. Process 59509 has 15.72 GiB memory in use. Of the allocated memory 15.14 GiB is allocated by PyTorch, and 196.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# # prompt = \"here is the vaccine record of one patient, can you provide a summary of the useful information \" +output_string + \" and present results in a table to be saved, such as date of vaccine, index of vaccine, name of vaccine\"\n",
    "# prompt = \"here is followup of maybe long covid patient, vaccines may be taken before enrollment. there are 4 columns, id column: is the patient id, date column: is the date of item recorded, index column: 0 means the enrollment, 1,2,3,4 means the first, second, third and fourth vaccine, followup means the followup, pasc_score_2024 means the score of wellness, the lower the score, the better the patient, 12 is usually the threshold, >=12 means long covid, < 12 means no; name column: is the description, such as pfzier is the vaccine name, number with pasc_score_2024 means the score, with index column followup_2, no means there is no vaccine between this visit and previous visit, yes means another vaccine \" +\\\n",
    "# output_ind + \" make analysis of the table, then find some discoveries of such as pasc score and the vaccine, the pattern, the timeline, when peak happens, what are the events before and after, discories that usually in nature/science. Write summary in #Summary\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.7,\n",
    "    max_new_tokens = 3024,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a0a96-4b79-449c-b01c-6e4c901cd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # pip install accelerate\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\", device_map=\"auto\")\n",
    "\n",
    "# input_text = \"Write me a poem about Machine Learning.\"\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# outputs = model.generate(**input_ids)\n",
    "# print(tokenizer.decode(outputs[0]))\n",
    "### **Conclusion**\n",
    "- Vaccines (Pfizer/Moderna) may help reduce long COVID symptoms (PASC scores ≤12), but outcomes vary by individual.  \n",
    "- Peaks in PASC scores often occur 6–12 months post-enrollment, followed by recovery in many cases.  \n",
    "- Long-term followups (≥3 years) show that some patients achieve sustained recovery, even without additional vaccines.  \n",
    "\n",
    "This analysis highlights the complex interplay between vaccination, immune response, and long-term health outcomes in post-acute sequelae of SARS-CoV-2 infection.<|im_end|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900574c4-2c2e-4392-b99f-6dd9e221fae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1195a876-3665-41b7-b1e3-005f8d82e6d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'encoding_dsv32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# encoding/encoding_dsv32.py\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencoding_dsv32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m encode_messages, parse_message_from_completion_text\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mAutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/DeepSeek-V3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\u001b[38;5;66;03m#\"Hello! I am DeepSeek.\", \"reasoning_content\": \"thinking...\"},\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1+1=?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     11\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'encoding_dsv32'"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "# encoding/encoding_dsv32.py\n",
    "from encoding_dsv32 import encode_messages, parse_message_from_completion_text\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-V3.2\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hello\"},\n",
    "    {\"role\": \"assistant\", \"content\": prompt},#\"Hello! I am DeepSeek.\", \"reasoning_content\": \"thinking...\"},\n",
    "    {\"role\": \"user\", \"content\": \"1+1=?\"}\n",
    "]\n",
    "encode_config = dict(thinking_mode=\"thinking\", drop_thinking=True, add_default_bos_token=True)\n",
    "\n",
    "# messages -> string\n",
    "prompt = encode_messages(messages, **encode_config)\n",
    "# Output: \"<｜begin▁of▁sentence｜><｜User｜>hello<｜Assistant｜></think>Hello! I am DeepSeek.<｜end▁of▁sentence｜><｜User｜>1+1=?<｜Assistant｜><think>\"\n",
    "\n",
    "# string -> tokens\n",
    "tokens = tokenizer.encode(prompt)\n",
    "# Output: [0, 128803, 33310, 128804, 128799, 19923, 3, 342, 1030, 22651, 4374, 1465, 16, 1, 128803, 19, 13, 19, 127252, 128804, 128798]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f133c8-1b90-4db1-8d2c-4c4e7701d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "**PASC Score Fluctuations Over Time**:\n",
    "**Possible Biological Insights**:\n",
    "   - **Waning Immunity**: The peak in 2024, 20 months after the last vaccine, may reflect **diminished protection** from prior doses, leading to a resurgence of symptoms.\n",
    "   - **Immune Memory and Long COVID**: The patient’s PASC score fluctuated, suggesting **variable immune response**. The 2024 peak might indicate **reduced immune memory** or **viral reactivation** (e.g., SARS-CoV-2 variants or other pathogens).\n",
    "   - **Seasonal or Environmental Factors**: The spike in 2024 could correlate with **seasonal viral activity** (e.g., winter 2023–2024) or **environmental stressors**.\n",
    "\n",
    "5. **Clinical Implications**:\n",
    "   - **Long-Term Monitoring**: The case highlights the need for **long-term monitoring** of patients post-vaccination, especially those with prior long COVID.\n",
    "   - **Vaccine Efficacy Over Time**: The peak in 2024 suggests that **vaccine protection may not fully prevent long-term symptoms**, especially in vulnerable individuals.\n",
    "   - **Therapeutic Window**: The drop in PASC score to 2.0 in May 2024 suggests **possible recovery** or **intervention** (not documented here), indicating variability in disease progression.\n",
    "\n",
    "\n",
    "                                                           ### **6. Scientific Insights**\n",
    "- **Long COVID is not static**:  \n",
    "  - Patients may experience **remissions and relapses**, even with prior vaccinations.  \n",
    "  - **PASC scores are not predictive of long-term outcomes** without additional biomarkers.  \n",
    "\n",
    "- **Vaccine Efficacy for Long COVID**:  \n",
    "  - While vaccines may reduce acute symptoms, **they do not eliminate Long COVID risk** in all individuals.  \n",
    "\n",
    "- **Need for Longitudinal Studies**:  \n",
    "  - More data on **vaccine timing, booster doses, and comorbidities** are needed to understand Long COVID dynamics.  \n",
    "\n",
    "---\n",
    "\n",
    "### **7. Recommendations for Further Research**\n",
    "- Investigate **seasonal triggers** (e.g., viral infections, pollution) in Long COVID relapses.  \n",
    "- Explore **biomarkers** (e.g., cytokine profiles, autoantibodies) to predict PASC score fluctuations.  \n",
    "- Study **vaccine boosters** in Long COVID patients to assess sustained protection.  \n",
    "- Address **missing data** in follow-up visits to improve outcome prediction models.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "Patient RA16050’s PASC scores demonstrate **significant variability**, with a **sharp initial improvement** post-enrollment, followed by **recurrent Long COVID symptoms**. Pre-vaccination history and the absence of further vaccines suggest that **Long COVID is not fully mitigated by vaccination alone**. The **peak in September 2023** highlights the need for ongoing monitoring and personalized interventions for Long COVID patients.<|im_end|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc7e46c-4ded-4d64-b868-5ffe3e55c3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057507767c17411fb67ebaa025564cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04537b0b8e794c80a8155a61a78708d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d12e5ae17448d4914b1790403ef677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c951b1664ce54a8cbb255d6c344b1c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad43ee1c10a4604b6bebefab0a5c998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7bdcc159814df7bc74715fa12ced11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'nvidia/Nemotron-Cascade-8B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "'''\n",
    "single-turn example\n",
    "'''\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"calculate 1+1?\"}\n",
    "]\n",
    "\n",
    "# thinking mode\n",
    "prompt_thinking = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=True)\n",
    "# prompt_thinking = '<|im_start|>system\\nYou are a helpful and harmless assistant.<|im_end|>\\n<|im_start|>user\\ncalculate 1+1? /think<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "# instruct mode\n",
    "prompt_instruct = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "# prompt_instruct = '<|im_start|>system\\nYou are a helpful and harmless assistant.<|im_end|>\\n<|im_start|>user\\ncalculate 1+1? /no_think<|im_end|>\\n<|im_start|>assistant\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d576bb5-bcab-4bf6-bb95-f3bccbd740be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
