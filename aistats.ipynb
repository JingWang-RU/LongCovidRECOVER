{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2b0cd-1ee1-4e1d-9c39-2fc02433fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee4a73-fa91-4854-85f6-3dace428a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------- 1) pick the actions you want to compare -------------\n",
    "ACTIONS = [\"A_dose1\", \"A_dose2\", \"A_dose3\", \"A_dose4\", \"A_vax_any\"]  # you already did A_booster\n",
    "\n",
    "# ------------- 2) choose your outcome & alignment params -------------\n",
    "OUTCOME_NAME = \"pasc_score\"         # or \"depression_score\"\n",
    "OUTCOME_DATE = \"date\"               # the date col of the outcome file (e.g., pasc_df[\"date\"])\n",
    "OUTCOME_MODE = \"delta_next\"         # or \"next_value\"\n",
    "MAX_FORWARD_DAYS = 120              # None to disable\n",
    "ID_COL = \"PARTICIPANT_ID\"\n",
    "VISIT_COL = \"VISIT_START_DATE\"\n",
    "def zscore_Y(Y_list):\n",
    "            all_y = np.concatenate([y for y in Y_list])\n",
    "            mu, sd = all_y.mean(), all_y.std() or 1.0\n",
    "            return [ (y - mu)/sd for y in Y_list ]\n",
    "        # Then call run_cknn_numpy on the standardized Y_list_std instead of Y_list.\n",
    "def build_A_list_in_same_order(X_visit_df, A_col, id_col=\"PARTICIPANT_ID\", date_col=\"VISIT_START_DATE\"):\n",
    "    # patient order = first appearance order in X_visit_df (stable)\n",
    "    ids = X_visit_df[id_col].drop_duplicates().tolist()\n",
    "    g = X_visit_df[[id_col, date_col, A_col]].copy()\n",
    "    g[date_col] = pd.to_datetime(g[date_col], errors=\"coerce\")\n",
    "    A_list = []\n",
    "    for pid in ids:\n",
    "        sub = g[g[id_col]==pid].sort_values(date_col)\n",
    "        A_list.append(sub[A_col].astype(\"int64\").to_numpy())\n",
    "    return np.array(A_list, dtype=object)\n",
    "\n",
    "# ------------- 3) seeds for mean ± CI -------------\n",
    "SEEDS = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# ------------- 4) helper: (X,A,Y) builder you used earlier -------------\n",
    "# make sure this function is in scope (the cleaned, robust version you ended up with).\n",
    "# def build_triplets_from_XA_and_outcome(...):  # <- from our earlier message\n",
    "\n",
    "# ------------- 5) helper: run_cknn_numpy you already have -------------\n",
    "# def run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=1337, k=50, temp=1.0)\n",
    "\n",
    "# ------------- 6) main evaluation loop -------------\n",
    "rows = []\n",
    "for A_col in ACTIONS:\n",
    "    for s in SEEDS:\n",
    "        # Rebuild triplets for THIS action (robust and alignment-safe)\n",
    "        X_list, A_list, Y_list, X_cols = build_triplets_from_XA_and_outcome(\n",
    "            X_visit=X_visit_with_A,           # your per-visit table that contains all A_* columns & features\n",
    "            outcome_df=pasc_df,               # or depression_df\n",
    "            id_col=ID_COL,\n",
    "            visit_col=VISIT_COL,\n",
    "            A_col=A_col,                      # <-- iterate action here\n",
    "            outcome_col=OUTCOME_NAME,\n",
    "            outcome_date_col=OUTCOME_DATE,\n",
    "            outcome_mode=OUTCOME_MODE,\n",
    "            max_forward_days=MAX_FORWARD_DAYS\n",
    "        )\n",
    "        \n",
    "        res = run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=s, k=50, temp=1.0)\n",
    "        rows.append({\"action\": A_col, \"seed\": s, \"mse\": res[\"mse\"], \"dr_value\": res[\"dr_value\"]})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ------------- 7) summarize with mean ± 95% CI -------------\n",
    "def summarize(group, col):\n",
    "    mean = group[col].mean()\n",
    "    sem  = group[col].std(ddof=1) / np.sqrt(len(group))\n",
    "    ci95 = 1.96 * sem\n",
    "    return pd.Series({f\"{col}_mean\": mean, f\"{col}_ci95\": ci95})\n",
    "\n",
    "summary = (df.groupby(\"action\")\n",
    "             .apply(lambda g: pd.concat([summarize(g, \"mse\"), summarize(g, \"dr_value\")]))\n",
    "             .reset_index())\n",
    "\n",
    "print(summary.sort_values(\"action\"))\n",
    "# Optionally save:\n",
    "summary.to_csv(\"cknn_vax_actions_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a61f57-32ad-47a6-bd47-246da68a1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.5270 ± nan\n",
      "DR value: 0.0441 ± nan\n",
      "MSE: 2.7286 ± 0.1767\n",
      "DR value: 0.0966 ± 0.0461\n",
      "MSE: 2.8893 ± 0.2130\n",
      "DR value: 0.1570 ± 0.0726\n",
      "MSE: 2.9185 ± 0.1776\n",
      "DR value: 0.1746 ± 0.0631\n",
      "MSE: 2.8543 ± 0.1777\n",
      "DR value: 0.1484 ± 0.0656\n",
      "MSE: 2.8340 ± 0.1619\n",
      "DR value: 0.1602 ± 0.0614\n",
      "MSE: 2.7869 ± 0.1667\n",
      "DR value: 0.1831 ± 0.0674\n",
      "MSE: 2.7830 ± 0.1545\n",
      "DR value: 0.1893 ± 0.0634\n",
      "MSE: 2.8206 ± 0.1606\n",
      "DR value: 0.1843 ± 0.0600\n",
      "MSE: 2.8211 ± 0.1514\n",
      "DR value: 0.1837 ± 0.0566\n"
     ]
    }
   ],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "# =============== Utilities ===============\n",
    "\n",
    "def add_bias(X):\n",
    "    return np.concatenate([X, np.ones((X.shape[0],1), dtype=X.dtype)], axis=1)\n",
    "\n",
    "def ridge_regression_fit(X, y, l2=1e-2):\n",
    "    XT = X.T\n",
    "    A = XT @ X\n",
    "    I = np.eye(A.shape[0], dtype=X.dtype)\n",
    "    I[-1, -1] = 0.0  # don't regularize bias\n",
    "    w = np.linalg.solve(A + l2*I, XT @ y)\n",
    "    return w\n",
    "\n",
    "def ridge_regression_predict(W, X):\n",
    "    return X @ W\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_regression_fit(X, y, l2=1e-3, lr=0.1, epochs=300, batch=2048, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N, D = X.shape\n",
    "    w = rng.normal(0, 0.01, size=(D,)).astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "    for ep in range(epochs):\n",
    "        perm = rng.permutation(N)\n",
    "        for s in range(0, N, batch):\n",
    "            e = min(N, s+batch)\n",
    "            xb = X[perm[s:e]]; yb = y[perm[s:e]]\n",
    "            p = sigmoid(xb @ w)\n",
    "            # gradient (+ L2 on non-bias)\n",
    "            grad = (xb.T @ (p - yb)) / (e - s)\n",
    "            grad[:-1] += l2 * w[:-1]\n",
    "            w -= lr * grad\n",
    "    return w\n",
    "\n",
    "def logistic_regression_predict_proba(W, X):\n",
    "    return sigmoid(X @ W)\n",
    "\n",
    "def flatten_time(phi, A, Y):\n",
    "    \"\"\"phi: (n,T,d) object -> (N,d), A,Y -> (N,)\"\"\"\n",
    "    n = len(phi)\n",
    "    ds = [p.shape[0] for p in phi]\n",
    "    d = phi[0].shape[1]\n",
    "    Ntot = sum(ds)\n",
    "    out_phi = np.zeros((Ntot, d), dtype=np.float32)\n",
    "    out_A = np.zeros((Ntot,), dtype=np.int64)\n",
    "    out_Y = np.zeros((Ntot,), dtype=np.float32)\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        T = phi[i].shape[0]\n",
    "        out_phi[idx:idx+T] = phi[i]\n",
    "        out_A[idx:idx+T] = A[i]\n",
    "        out_Y[idx:idx+T] = Y[i]\n",
    "        idx += T\n",
    "    return out_phi, out_A, out_Y\n",
    "\n",
    "# =============== History features (no torch) ===============\n",
    "\n",
    "def build_history_features(X_obj, A_obj, Y_obj, d_latent=16, seed=1337, alpha=0.5):\n",
    "    \"\"\"\n",
    "    X_obj[i]: (T_i, d_x) features per visit *before* treatment\n",
    "    Returns Phi[i]: (T_i, d_latent)\n",
    "    Idea: concat [x_t, a_{t-1}, y_{t-1}, EMA(x_{<t}), cum-mean(y_{<t})] -> random projection + tanh\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = len(X_obj)\n",
    "    d_x = X_obj[0].shape[1]\n",
    "\n",
    "    d_raw = d_x + 1 + 1 + d_x + 1\n",
    "    W = rng.normal(0, 1/np.sqrt(d_raw), size=(d_raw, d_latent)).astype(np.float32)\n",
    "    b = rng.normal(0, 0.1, size=(d_latent,)).astype(np.float32)\n",
    "\n",
    "    Phi = []\n",
    "    for i in range(N):\n",
    "        Xi = X_obj[i]; Ai = A_obj[i]; Yi = Y_obj[i]\n",
    "        T = Xi.shape[0]\n",
    "        phi_i = np.zeros((T, d_latent), dtype=np.float32)\n",
    "        x_ema = np.zeros((d_x,), dtype=np.float32)\n",
    "        y_csum = 0.0\n",
    "        for t in range(T):\n",
    "            x_t = Xi[t]\n",
    "            a_prev = Ai[t-1] if t>0 else 0.0\n",
    "            y_prev = Yi[t-1] if t>0 else 0.0\n",
    "            if t>0:\n",
    "                x_ema = alpha * x_ema + (1-alpha) * Xi[t-1]\n",
    "                y_csum += Yi[t-1]\n",
    "                y_cmean = y_csum / t\n",
    "            else:\n",
    "                x_ema = np.zeros_like(x_t)\n",
    "                y_cmean = 0.0\n",
    "            raw = np.concatenate([x_t, [a_prev], [y_prev], x_ema, [y_cmean]]).astype(np.float32)\n",
    "            phi_i[t] = np.tanh(raw @ W + b)\n",
    "        Phi.append(phi_i)\n",
    "    return np.array(Phi, dtype=object)\n",
    "\n",
    "# =============== ANN (HNSW or exact kNN fallback) ===============\n",
    "\n",
    "try:\n",
    "    import hnswlib\n",
    "    class ANNIndex:\n",
    "        def __init__(self, dim, space=\"l2\", ef=100, M=32):\n",
    "            self.index = hnswlib.Index(space=space, dim=dim)\n",
    "            self.ef = ef; self.M = M; self.built = False\n",
    "        def build(self, X, ids=None):\n",
    "            if ids is None: ids = np.arange(X.shape[0])\n",
    "            self.index.init_index(max_elements=X.shape[0], ef_construction=self.ef, M=self.M)\n",
    "            self.index.add_items(X.astype(np.float32), ids.astype(np.int64))\n",
    "            self.index.set_ef(self.ef); self.built = True\n",
    "        def query(self, Q, k=50):\n",
    "            return self.index.knn_query(Q.astype(np.float32), k=k)\n",
    "except Exception:\n",
    "    # exact kNN fallback (no dependency)\n",
    "    class ANNIndex:\n",
    "        def __init__(self, dim, space=\"l2\", **kwargs):\n",
    "            self.X = None\n",
    "        def build(self, X, ids=None):\n",
    "            self.X = X.astype(np.float32)\n",
    "        def query(self, Q, k=50):\n",
    "            # squared l2\n",
    "            d2 = ((Q[:,None,:] - self.X[None,:,:])**2).sum(axis=2)\n",
    "            idx = np.argsort(d2, axis=1)[:, :k]\n",
    "            d  = np.take_along_axis(d2, idx, axis=1)\n",
    "            return idx, d\n",
    "\n",
    "# =============== DR-kNN estimator ===============\n",
    "\n",
    "def dr_knn_mu(phi_tr, A_tr, Y_tr, query_phi, a_query, out_W, prop_W, k=50, temp=1.0):\n",
    "    \"\"\"\n",
    "    Double-robust kNN: neighbors on phi among train rows with A==a_query.\n",
    "    out_W: ridge on [phi, onehot(a)](+bias)\n",
    "    prop_W: logistic on phi(+bias)\n",
    "    \"\"\"\n",
    "    mask_a = (A_tr == a_query)\n",
    "    phi_a = phi_tr[mask_a]\n",
    "    ann = ANNIndex(dim=phi_tr.shape[1])\n",
    "    ann.build(phi_a)\n",
    "\n",
    "    def design_outcome(phi, a_vec):\n",
    "        a0 = (a_vec==0).astype(np.float32).reshape(-1,1)\n",
    "        a1 = (a_vec==1).astype(np.float32).reshape(-1,1)\n",
    "        Z = np.concatenate([phi, a0, a1], axis=1)\n",
    "        return add_bias(Z)\n",
    "\n",
    "    def m_pred(phi, a_scalar):\n",
    "        Z = design_outcome(phi, np.full((phi.shape[0],), a_scalar, dtype=np.int64))\n",
    "        return ridge_regression_predict(out_W, Z)\n",
    "\n",
    "    def e_pred(phi):\n",
    "        return logistic_regression_predict_proba(prop_W, add_bias(phi))\n",
    "\n",
    "    labels, dists = ann.query(query_phi, k=min(k, len(phi_a)))\n",
    "    Wker = np.exp(-dists / max(temp, 1e-6))\n",
    "    Wker /= (Wker.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # train-side predictions once\n",
    "    e_train = e_pred(phi_tr)\n",
    "    e_train = e_train if a_query==1 else (1.0 - e_train)\n",
    "    m_train_a = m_pred(phi_tr, a_query)\n",
    "\n",
    "    mu = np.zeros(query_phi.shape[0], dtype=np.float32)\n",
    "    # indices of global train rows corresponding to A==a_query\n",
    "    idx_map = np.where(mask_a)[0]\n",
    "    for i in range(query_phi.shape[0]):\n",
    "        local = labels[i]\n",
    "        global_idx = idx_map[local]\n",
    "        w = Wker[i]\n",
    "\n",
    "        res = Y_tr[global_idx] - m_train_a[global_idx]\n",
    "        e_neighbors = e_train[global_idx]\n",
    "        iw = 1.0 / np.clip(e_neighbors, 1e-3, 1-1e-3)\n",
    "        w_tilde = w * iw; w_tilde /= (w_tilde.sum() + 1e-8)\n",
    "\n",
    "        m_q = m_pred(query_phi[i:i+1], a_query)[0]\n",
    "        mu[i] = m_q + np.sum(w_tilde * res)\n",
    "    return mu\n",
    "\n",
    "# =============== Runner: pass your lists here ===============\n",
    "\n",
    "def run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=1337, k=50, temp=1.0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(X_list)\n",
    "    idx = np.arange(n); rng.shuffle(idx)\n",
    "    n_te = max(1, int(0.2*n))\n",
    "    te_idx, tr_idx = idx[:n_te], idx[n_te:]\n",
    "\n",
    "    # object arrays (ragged ok)\n",
    "    X_obj = np.array([np.asarray(x, dtype=np.float32) for x in X_list], dtype=object)\n",
    "    A_obj = np.array([np.asarray(a, dtype=np.int64) for a in A_list], dtype=object)\n",
    "    Y_obj = np.array([np.asarray(y, dtype=np.float32) for y in Y_list], dtype=object)\n",
    "\n",
    "    # history embeddings\n",
    "    Phi = build_history_features(X_obj, A_obj, Y_obj, d_latent=d_latent, seed=seed)\n",
    "    Phi_tr = Phi[tr_idx]; A_tr = A_obj[tr_idx]; Y_tr = Y_obj[tr_idx]\n",
    "    Phi_te = Phi[te_idx]; A_te = A_obj[te_idx]; Y_te = Y_obj[te_idx]\n",
    "\n",
    "    # flatten to visit-level\n",
    "    phi_tr_flat, A_tr_flat, Y_tr_flat = flatten_time(Phi_tr, A_tr, Y_tr)\n",
    "    phi_te_flat, A_te_flat, Y_te_flat = flatten_time(Phi_te, A_te, Y_te)\n",
    "\n",
    "    # fit outcome model: y ~ [phi, onehot(a)] + bias\n",
    "    a0 = (A_tr_flat==0).astype(np.float32).reshape(-1,1)\n",
    "    a1 = (A_tr_flat==1).astype(np.float32).reshape(-1,1)\n",
    "    Z_out_tr = np.concatenate([phi_tr_flat, a0, a1], axis=1)\n",
    "    out_W = ridge_regression_fit(add_bias(Z_out_tr), Y_tr_flat, l2=1e-2)\n",
    "\n",
    "    # fit propensity: a ~ phi + bias\n",
    "    prop_W = logistic_regression_fit(add_bias(phi_tr_flat), A_tr_flat.astype(np.float32),\n",
    "                                     l2=1e-3, lr=0.1, epochs=300, batch=2048, seed=seed)\n",
    "\n",
    "    # DR-kNN mu(a|H) on test\n",
    "    mu0 = dr_knn_mu(phi_tr_flat, A_tr_flat, Y_tr_flat, phi_te_flat, a_query=0,\n",
    "                    out_W=out_W, prop_W=prop_W, k=k, temp=temp)\n",
    "    mu1 = dr_knn_mu(phi_tr_flat, A_tr_flat, Y_tr_flat, phi_te_flat, a_query=1,\n",
    "                    out_W=out_W, prop_W=prop_W, k=k, temp=temp)\n",
    "\n",
    "    # evaluation proxy: observed-treatment MSE\n",
    "    y_pred_obs = np.where(A_te_flat==1, mu1, mu0)\n",
    "    mse = float(np.mean((Y_te_flat - y_pred_obs)**2))\n",
    "\n",
    "    # simple policy: treat if mu1 > mu0, DR value estimate\n",
    "    policy = (mu1 > mu0).astype(np.int64)\n",
    "    # propensity for observed A on test\n",
    "    e_te = logistic_regression_predict_proba(prop_W, add_bias(phi_te_flat))\n",
    "    e_te = np.where(A_te_flat==1, e_te, 1.0 - e_te)\n",
    "    # m_obs (outcome regression at observed A)\n",
    "    a0_te = (A_te_flat==0).astype(np.float32).reshape(-1,1)\n",
    "    a1_te = (A_te_flat==1).astype(np.float32).reshape(-1,1)\n",
    "    Z_out_te = np.concatenate([phi_te_flat, a0_te, a1_te], axis=1)\n",
    "    m_obs = ridge_regression_predict(out_W, add_bias(Z_out_te))\n",
    "    dr_value = float(np.mean(((policy==A_te_flat)/np.clip(e_te,1e-3,1-1e-3)) * (Y_te_flat - m_obs)\n",
    "                             + (policy*mu1 + (1-policy)*mu0)))\n",
    "\n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"dr_value\": dr_value,\n",
    "        \"mu0\": mu0, \"mu1\": mu1,\n",
    "        \"A_te\": A_te_flat, \"Y_te\": Y_te_flat\n",
    "    }\n",
    "def knn_mu(phi_tr, A_tr, Y_tr, query_phi, a_query, k=50, temp=1.0):\n",
    "    mask = (A_tr==a_query)\n",
    "    X = phi_tr[mask]; y = Y_tr[mask]\n",
    "    # exact kNN if no hnswlib\n",
    "    d2 = ((query_phi[:,None,:]-X[None,:,:])**2).sum(2)\n",
    "    idx = np.argsort(d2,1)[:, :min(k, len(X))]\n",
    "    d  = np.take_along_axis(d2, idx, axis=1)\n",
    "    W = np.exp(-d/ max(temp,1e-6)); W /= (W.sum(1,keepdims=True)+1e-8)\n",
    "    return (W * y[idx]).sum(1)\n",
    "def tlearner():\n",
    "    # train\n",
    "    Z0, y0 = phi_tr_flat[A_tr_flat==0], Y_tr_flat[A_tr_flat==0]\n",
    "    Z1, y1 = phi_tr_flat[A_tr_flat==1], Y_tr_flat[A_tr_flat==1]\n",
    "    W0 = ridge_regression_fit(add_bias(Z0), y0, l2=1e-2)\n",
    "    W1 = ridge_regression_fit(add_bias(Z1), y1, l2=1e-2)\n",
    "    # predict potential outcomes on test\n",
    "    mu0 = ridge_regression_predict(W0, add_bias(phi_te_flat))\n",
    "    mu1 = ridge_regression_predict(W1, add_bias(phi_te_flat))\n",
    "    # compute MSE & DR value as before\n",
    "def msm():\n",
    "    e = logistic_regression_predict_proba(prop_W, add_bias(phi_te_flat))\n",
    "    e_obs = np.where(A_te_flat==1, e, 1-e)\n",
    "    # simple (non-sequential) stabilized weight per visit\n",
    "    pA = A_te_flat.mean()  # crude marginal; or per-time-bin marginal\n",
    "    num = np.where(A_te_flat==1, pA, 1-pA)\n",
    "    w = num / np.clip(e_obs,1e-3,1-1e-3)\n",
    "    # weighted outcome difference\n",
    "    tau_msm = np.average(Y_te_flat, weights=w*(A_te_flat==1)) - np.average(Y_te_flat, weights=w*(A_te_flat==0))\n",
    "# ================== Example call ==================\n",
    "# results = run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=1337, k=50, temp=1.0)\n",
    "# print(\"Observed-treatment MSE:\", results[\"mse\"])\n",
    "# print(\"DR value (treat if mu1>mu0):\", results[\"dr_value\"])\n",
    "seeds = [1,2,3,4,5,6,7,8,9,10]\n",
    "rows = []\n",
    "for s in seeds:\n",
    "    res = run_cknn_numpy(X_list, A_list, Y_list, d_latent=16, seed=s, k=50, temp=1.0)\n",
    "    rows.append((s, res[\"mse\"], res[\"dr_value\"]))\n",
    "    arr = np.array([[r[1], r[2]] for r in rows], dtype=float)\n",
    "    m_mse, m_dr = arr.mean(0)\n",
    "    s_mse, s_dr = arr.std(0, ddof=1)\n",
    "    print(f\"MSE: {m_mse:.4f} ± {1.96*s_mse/np.sqrt(len(seeds)):.4f}\")\n",
    "    print(f\"DR value: {m_dr:.4f} ± {1.96*s_dr/np.sqrt(len(seeds)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f6d7be-71e9-47ff-8a70-a7600794f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def _to_dt(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\", utc=False).dt.tz_localize(None)\n",
    "\n",
    "def _same_month(a, b):\n",
    "    a = pd.to_datetime(a, errors=\"coerce\"); b = pd.to_datetime(b, errors=\"coerce\")\n",
    "    return (a.dt.year == b.dt.year) & (a.dt.month == b.dt.month)\n",
    "\n",
    "def add_vax_actions_to_visits(\n",
    "    X_visit: pd.DataFrame,\n",
    "    vax_dates: pd.DataFrame,\n",
    "    id_col=\"PARTICIPANT_ID\",\n",
    "    visit_col=\"VISIT_START_DATE\",\n",
    "    booster_doses=(3,4,5)  # which doses count as \"booster\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    vax_dates: wide table with columns like:\n",
    "      PARTICIPANT_ID, vacc_vaccdt_1_date, vacc_vaccdt_2_date, ... (up to 5)\n",
    "    Returns X_visit with new columns:\n",
    "      A_dose1..A_doseK, A_vax_any, A_booster, months_since_last_vaccine\n",
    "    \"\"\"\n",
    "    X = X_visit.copy()\n",
    "    V = vax_dates.copy()\n",
    "\n",
    "    # parse visit date\n",
    "    X[visit_col] = _to_dt(X[visit_col])\n",
    "\n",
    "    # find dose date columns in vax_dates\n",
    "    dose_cols = []\n",
    "    dose_idx = []\n",
    "    for c in V.columns:\n",
    "        m = re.search(r'(\\d+)', c)\n",
    "        if c.endswith(\"_date\") and m:\n",
    "            dose_cols.append(c)\n",
    "            dose_idx.append(int(m.group(1)))\n",
    "    # sort consistently by dose number\n",
    "    dose_cols = [dc for _, dc in sorted(zip(dose_idx, dose_cols))]\n",
    "    dose_numbers = sorted(dose_idx)\n",
    "\n",
    "    # parse dose dates\n",
    "    for c in dose_cols:\n",
    "        V[c] = _to_dt(V[c])\n",
    "\n",
    "    # merge dose dates onto each visit\n",
    "    M = X.merge(V[[id_col] + dose_cols], on=id_col, how=\"left\")\n",
    "\n",
    "    # per-dose actions A_dosek\n",
    "    for k, c in zip(dose_numbers, dose_cols):\n",
    "        M[f\"A_dose{k}\"] = _same_month(M[c], M[visit_col]).astype(\"int8\")\n",
    "\n",
    "    # composites\n",
    "    a_cols = [f\"A_dose{k}\" for k in dose_numbers]\n",
    "    M[\"A_vax_any\"] = (M[a_cols].sum(axis=1) > 0).astype(\"int8\")\n",
    "\n",
    "    booster_cols = [f\"A_dose{k}\" for k in dose_numbers if k in booster_doses]\n",
    "    if booster_cols:\n",
    "        M[\"A_booster\"] = (M[booster_cols].sum(axis=1) > 0).astype(\"int8\")\n",
    "    else:\n",
    "        M[\"A_booster\"] = np.int8(0)\n",
    "\n",
    "    # months_since_last_vaccine (<= visit date)\n",
    "    def months_since(row):\n",
    "        ref = row[visit_col]\n",
    "        if pd.isna(ref): return np.float32(999.0)\n",
    "        # consider any dose date <= visit date\n",
    "        dates = [row[c] for c in dose_cols if pd.notna(row[c]) and row[c] <= ref]\n",
    "        if not dates: return np.float32(999.0)\n",
    "        last = max(dates)\n",
    "        return np.float32((ref - last).days / 30.0)\n",
    "\n",
    "    M[\"months_since_last_vaccine\"] = M.apply(months_since, axis=1)\n",
    "\n",
    "    return M\n",
    "import pandas as pd\n",
    "X_visit = pd.read_csv('X_visits.csv')\n",
    "vax_dates = pd.read_csv('vax_dates.csv')\n",
    "\n",
    "X_visit_with_A = add_vax_actions_to_visits(X_visit, vax_dates)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ef127-d142-421c-89c8-5e74fd813abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in X_visit_with_A.columns:\n",
    "#     print(x,end=' ')\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8950ebb5-5c5d-4538-ba7b-1ff670cca8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_visit_with_A.shape(158685, 670)\n",
    "X_visit_with_A.to_csv('X_visit_with_A.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "271729b1-3cb8-4fcc-a64d-48170fb53c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTICIPANT_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>pasc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARTICIPANT_ID        date  pasc_score\n",
       "0        RA11305  2021-01-01        16.0\n",
       "1        RA11305  2021-04-03        14.0\n",
       "2        RA11305  2021-06-28         8.0\n",
       "3        RA11305  2021-09-28        13.0\n",
       "4        RA11305  2021-12-23        10.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pasc_df = pd.read_csv('y_pasc_score2024.csv')\n",
    "pasc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee357ea-289f-49eb-b33c-0187c3a37d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pasc_df.rename({\"pasc_score_2024\":\"pasc_score\"},axis=\"columns\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f97ac-1933-4b59-8eff-2e912abbf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, random, time, json\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import hnswlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Synthetic sequential data\n",
    "# ------------------------------\n",
    "\n",
    "def make_synthetic_longitudinal(N=1000, T=5, d_x=6, seed=1337):\n",
    "    \"\"\"\n",
    "    Generate synthetic longitudinal data with confounding.\n",
    "    Each patient i has time-varying covariates X_{i,t}, treatment A_{i,t} in {0,1},\n",
    "    and outcome Y_{i,t}. Treatment depends on history; outcomes depend on both\n",
    "    latent health and treatment.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # latent \"health\" state per patient, evolves\n",
    "    Z = rng.normal(0, 1, size=(N,))  # baseline health\n",
    "    \n",
    "    X = []\n",
    "    A = []\n",
    "    Y = []\n",
    "    # create d_x covariates; first few are confounders linked to Z and past Y\n",
    "    for i in range(N):\n",
    "        Xi = []\n",
    "        Ai = []\n",
    "        Yi = []\n",
    "        z = Z[i]\n",
    "        y_prev = 0.0\n",
    "        for t in range(T):\n",
    "            # covariates: some depend on z and y_prev\n",
    "            x = rng.normal(0,1,size=(d_x,))\n",
    "            x[0] += 0.8*z\n",
    "            x[1] += 0.6*y_prev\n",
    "            x[2] += 0.4*z*y_prev\n",
    "            \n",
    "            # clinician policy: treat if (z + y_prev + x0) high, plus noise\n",
    "            logits = 0.8*z + 0.7*y_prev + 0.5*x[0] + rng.normal(0,0.5)\n",
    "            a = (logits > 0.0).astype(int)\n",
    "            \n",
    "            # outcome model: future health depends on current treatment and covariates\n",
    "            # true treatment effect heterogeneity: beneficial if z is low (sicker)\n",
    "            tau = 0.8 - 0.6*max(z, 0)  # smaller effect for healthier\n",
    "            noise = rng.normal(0, 0.5)\n",
    "            y = (0.6*y_prev + 0.5*x[0] + 0.3*x[1] + tau*a + 0.3*z + noise)\n",
    "            \n",
    "            Xi.append(x.astype(np.float32))\n",
    "            Ai.append(int(a))\n",
    "            Yi.append(float(y))\n",
    "            \n",
    "            y_prev = y\n",
    "        \n",
    "        X.append(np.array(Xi, dtype=np.float32))  # (T, d_x)\n",
    "        A.append(np.array(Ai, dtype=np.int64))    # (T,)\n",
    "        Y.append(np.array(Yi, dtype=np.float32))  # (T,)\n",
    "    return np.array(X, dtype=object), np.array(A, dtype=object), np.array(Y, dtype=object)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Models: GRU encoder, outcome, policy\n",
    "# -----------------------------------------\n",
    "\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, d_x, d_hidden=64, d_latent=16):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=d_x+2, hidden_size=d_hidden, batch_first=True)\n",
    "        self.proj = nn.Linear(d_hidden, d_latent)\n",
    "    def forward(self, X, A, Y):\n",
    "        \"\"\"\n",
    "        X: (B,T,d_x), A: (B,T), Y: (B,T)\n",
    "        Build history embedding for each time step t using prefix 0..t-1.\n",
    "        We do teacher-forcing: shift A,Y by one with zeros at t=0.\n",
    "        Returns embeddings Phi of shape (B,T,d_latent).\n",
    "        \"\"\"\n",
    "        B,T,d_x = X.shape\n",
    "        A_shift = torch.zeros_like(A)\n",
    "        Y_shift = torch.zeros_like(Y)\n",
    "        if T>1:\n",
    "            A_shift[:,1:] = A[:,:-1].float()\n",
    "            Y_shift[:,1:] = Y[:,:-1].float()\n",
    "        inp = torch.cat([X, A_shift.unsqueeze(-1), Y_shift.unsqueeze(-1)], dim=-1)\n",
    "        h, _ = self.gru(inp)  # (B,T,d_hidden)\n",
    "        phi = self.proj(h)    # (B,T,d_latent)\n",
    "        return phi\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in, d_out=1, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, d_out)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def outcome_forward(outcome_net, phi, a):\n",
    "    \"\"\"\n",
    "    phi: (B,T,d_latent), a: (B,T) int {0,1}\n",
    "    returns preds (B,T)\n",
    "    \"\"\"\n",
    "    B,T,d = phi.shape\n",
    "    a_one = F.one_hot(a, num_classes=2).float()  # (B,T,2)\n",
    "    x = torch.cat([phi, a_one], dim=-1).view(B*T, d+2)\n",
    "    y = outcome_net(x).view(B,T)\n",
    "    return y\n",
    "\n",
    "def propensity_forward(prop_net, phi):\n",
    "    \"\"\"\n",
    "    phi: (B,T,d_latent)\n",
    "    returns p(a=1 | phi) in (B,T)\n",
    "    \"\"\"\n",
    "    B,T,d = phi.shape\n",
    "    x = phi.reshape(B*T, d)\n",
    "    logit = prop_net(x).view(B,T)\n",
    "    p1 = torch.sigmoid(logit)\n",
    "    return p1\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Losses: predictive + balance\n",
    "# -------------------------------\n",
    "\n",
    "def mmd_loss(res_treated, res_control, sigma=1.0):\n",
    "    \"\"\"Simple RBF-kernel MMD between 1D residual samples.\"\"\"\n",
    "    # res_*: (n,)\n",
    "    def rbf(x, y):\n",
    "        xx = x.unsqueeze(1)\n",
    "        yy = y.unsqueeze(0)\n",
    "        return torch.exp(-(xx-yy)**2/(2*sigma**2))\n",
    "    Ktt = rbf(res_treated, res_treated).mean()\n",
    "    Kcc = rbf(res_control, res_control).mean()\n",
    "    Ktc = rbf(res_treated, res_control).mean()\n",
    "    return Ktt + Kcc - 2*Ktc\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4) Training with predictive + balancing loss\n",
    "# --------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    d_x: int = 6\n",
    "    T: int = 5\n",
    "    d_hidden: int = 64\n",
    "    d_latent: int = 16\n",
    "    hidden: int = 64\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 10\n",
    "    batch_size: int = 64\n",
    "    lam_mmd: float = 0.1\n",
    "    seed: int = 1337\n",
    "\n",
    "def train_cknn_lsh(X, A, Y, cfg: TrainConfig):\n",
    "    torch.manual_seed(cfg.seed); np.random.seed(cfg.seed); random.seed(cfg.seed)\n",
    "    N = len(X)\n",
    "    idx = np.arange(N)\n",
    "    tr_idx, te_idx = train_test_split(idx, test_size=0.2, random_state=cfg.seed)\n",
    "    \n",
    "    # pack into tensors\n",
    "    def pack(idxs):\n",
    "        # pad to uniform T if variable-length; here T is fixed\n",
    "        Xb = torch.tensor(np.stack([X[i] for i in idxs], axis=0)) # (B,T,d_x)\n",
    "        Ab = torch.tensor(np.stack([A[i] for i in idxs], axis=0)) # (B,T)\n",
    "        Yb = torch.tensor(np.stack([Y[i] for i in idxs], axis=0)) # (B,T)\n",
    "        return Xb, Ab, Yb\n",
    "    Xtr, Atr, Ytr = pack(tr_idx)\n",
    "    Xte, Ate, Yte = pack(te_idx)\n",
    "    \n",
    "    enc = GRUEncoder(cfg.d_x, cfg.d_hidden, cfg.d_latent)\n",
    "    out_net = MLP(cfg.d_latent+2, 1, cfg.hidden)\n",
    "    prop_net = MLP(cfg.d_latent, 1, cfg.hidden)\n",
    "    params = list(enc.parameters()) + list(out_net.parameters()) + list(prop_net.parameters())\n",
    "    opt = optim.Adam(params, lr=cfg.lr)\n",
    "    \n",
    "    B = Xtr.shape[0]\n",
    "    steps_per_epoch = math.ceil(B / cfg.batch_size)\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        perm = torch.randperm(B)\n",
    "        Xtr_sh = Xtr[perm]; Atr_sh = Atr[perm]; Ytr_sh = Ytr[perm]\n",
    "        epoch_loss = 0.0\n",
    "        for step in range(steps_per_epoch):\n",
    "            s = step*cfg.batch_size; e = min((step+1)*cfg.batch_size, B)\n",
    "            x = Xtr_sh[s:e]; a = Atr_sh[s:e]; y = Ytr_sh[s:e]\n",
    "            phi = enc(x,a,y)               # (b,T,d_latent)\n",
    "            yhat = outcome_forward(out_net, phi, a)  # (b,T)\n",
    "            p1 = propensity_forward(prop_net, phi)   # (b,T)\n",
    "            \n",
    "            # Predictive loss (MSE + BCE for observed actions)\n",
    "            loss_pred = F.mse_loss(yhat, y)\n",
    "            # action loglik\n",
    "            logp = a.float()*torch.log(p1+1e-6) + (1-a).float()*torch.log(1-p1+1e-6)\n",
    "            loss_act = -logp.mean()\n",
    "            \n",
    "            # Balancing: MMD of residuals across treatment groups in the minibatch\n",
    "            res = (y - yhat).detach()\n",
    "            # pool across time\n",
    "            a_vec = a.reshape(-1)\n",
    "            res_vec = res.reshape(-1)\n",
    "            if (a_vec==1).sum()>1 and (a_vec==0).sum()>1:\n",
    "                mmd = mmd_loss(res_vec[a_vec==1], res_vec[a_vec==0])\n",
    "            else:\n",
    "                mmd = torch.tensor(0.0)\n",
    "            \n",
    "            loss = loss_pred + 0.1*loss_act + cfg.lam_mmd*mmd\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"[Epoch {epoch+1}/{cfg.epochs}] loss={epoch_loss/steps_per_epoch:.4f}\")\n",
    "    \n",
    "    # Build embeddings for train and test\n",
    "    with torch.no_grad():\n",
    "        phi_tr = enc(Xtr, Atr, Ytr).numpy()   # (n_tr,T,d_latent)\n",
    "        phi_te = enc(Xte, Ate, Yte).numpy()   # (n_te,T,d_latent)\n",
    "        # also store predictions for outcome models\n",
    "        yhat_tr = outcome_forward(out_net, torch.tensor(phi_tr), Atr).numpy()\n",
    "        p1_tr = propensity_forward(prop_net, torch.tensor(phi_tr)).numpy()\n",
    "    \n",
    "    model = {\"enc\": enc, \"out_net\": out_net, \"prop_net\": prop_net}\n",
    "    data = {\"Xtr\": Xtr, \"Atr\": Atr, \"Ytr\": Ytr, \"Xte\": Xte, \"Ate\": Ate, \"Yte\": Yte,\n",
    "            \"phi_tr\": phi_tr, \"phi_te\": phi_te, \"yhat_tr\": yhat_tr, \"p1_tr\": p1_tr,\n",
    "            \"tr_idx\": tr_idx, \"te_idx\": te_idx}\n",
    "    return model, data\n",
    "\n",
    "# ------------------------------------\n",
    "# 5) ANN index and DR-kNN estimator\n",
    "# ------------------------------------\n",
    "\n",
    "class ANNIndex:\n",
    "    def __init__(self, dim, space=\"l2\", ef=100, M=32):\n",
    "        self.index = hnswlib.Index(space=space, dim=dim)\n",
    "        self.ef = ef\n",
    "        self.M = M\n",
    "        self.built = False\n",
    "    \n",
    "    def build(self, X, ids=None):\n",
    "        num = X.shape[0]\n",
    "        if ids is None:\n",
    "            ids = np.arange(num)\n",
    "        self.index.init_index(max_elements=num, ef_construction=self.ef, M=self.M)\n",
    "        self.index.add_items(X.astype(np.float32), ids.astype(np.int64))\n",
    "        self.index.set_ef(self.ef)\n",
    "        self.built = True\n",
    "    \n",
    "    def query(self, q, k=50):\n",
    "        labels, dists = self.index.knn_query(q.astype(np.float32), k=k)\n",
    "        return labels, dists\n",
    "\n",
    "def flatten_time(phi, A, Y):\n",
    "    \"\"\"\n",
    "    Flatten sequences into visit-level rows.\n",
    "    phi: (n,T,d), A,Y: (n,T)\n",
    "    returns arrays of shape (n*T, d), (n*T,), (n*T,)\n",
    "    \"\"\"\n",
    "    n,T,d = phi.shape\n",
    "    return phi.reshape(n*T, d), A.reshape(n*T), Y.reshape(n*T)\n",
    "\n",
    "def dr_knn_mu(enc, out_net, prop_net, phi_tr, A_tr, Y_tr, query_phi, a_query, k=50, temp=1.0):\n",
    "    \"\"\"\n",
    "    Estimate mu(a|H) for each query row using DR-kNN.\n",
    "    - Build separate ANN per treatment value for clarity.\n",
    "    \"\"\"\n",
    "    # Split train by treatment\n",
    "    mask_a = (A_tr == a_query)\n",
    "    phi_a = phi_tr[mask_a]\n",
    "    Y_a = Y_tr[mask_a]\n",
    "    \n",
    "    # ANN on phi_a\n",
    "    dim = phi_tr.shape[1]\n",
    "    ann = ANNIndex(dim=dim)\n",
    "    ann.build(phi_a, np.arange(len(phi_a)))\n",
    "    \n",
    "    # outcome and propensity on train\n",
    "    with torch.no_grad():\n",
    "        # outcome for treatment a on train\n",
    "        phi_tr_t = torch.tensor(phi_tr, dtype=torch.float32)\n",
    "        a_tr = torch.tensor(A_tr, dtype=torch.int64)\n",
    "        yhat_tr = outcome_forward(out_net, phi_tr_t.view(1,-1,dim), a_tr.view(1,-1)).view(-1).numpy()\n",
    "        # propensity on train\n",
    "        p1_tr = propensity_forward(prop_net, phi_tr_t.view(1,-1,dim)).view(-1).numpy()\n",
    "        # choose propensity for a\n",
    "        e_tr = p1_tr if a_query==1 else (1-p1_tr)\n",
    "    \n",
    "    # Precompute yhat for treatment a on train rows\n",
    "    # yhat under a differs; recompute with a vector of a's\n",
    "    with torch.no_grad():\n",
    "        B = phi_tr.shape[0]\n",
    "        # create a vector a* of length n_tr*T\n",
    "        a_star = np.full((phi_tr.shape[0],), a_query, dtype=np.int64)\n",
    "    \n",
    "    # For simplicity at visit-level, we treat query_phi as (Q,d)\n",
    "    labels, dists = ann.query(query_phi, k=min(k, len(phi_a)))\n",
    "    # kernel weights\n",
    "    W = np.exp(-dists / max(temp, 1e-6))\n",
    "    W /= (W.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    mu_hat = np.zeros(query_phi.shape[0], dtype=np.float32)\n",
    "    for i in range(query_phi.shape[0]):\n",
    "        idxs = labels[i]                             # indices within phi_a\n",
    "        # Map back to global indices of train where A=a\n",
    "        global_idxs = np.where(mask_a)[0][idxs]\n",
    "        w = W[i]\n",
    "        # Compute outcome regression for neighbors under a_query\n",
    "        with torch.no_grad():\n",
    "            phi_neighbors = torch.tensor(phi_tr[global_idxs], dtype=torch.float32).view(1,-1,dim)\n",
    "            a_neighbors = torch.full((1,len(global_idxs)), a_query, dtype=torch.int64)\n",
    "            m_neighbors = outcome_forward(out_net, phi_neighbors, a_neighbors).view(-1).numpy()\n",
    "        # residuals for neighbors (observed a == a_query)\n",
    "        res = Y_tr[global_idxs] - m_neighbors\n",
    "        # propensity weights (stabilized)\n",
    "        with torch.no_grad():\n",
    "            p1_neighbors = propensity_forward(prop_net, torch.tensor(phi_tr[global_idxs]).view(1,-1,dim)).view(-1).numpy()\n",
    "        e_neighbors = p1_neighbors if a_query==1 else (1-p1_neighbors)\n",
    "        iw = 1.0 / np.clip(e_neighbors, 1e-3, 1-1e-3)\n",
    "        w_tilde = w * iw\n",
    "        w_tilde = w_tilde / (w_tilde.sum() + 1e-8)\n",
    "        \n",
    "        # outcome regression at query\n",
    "        with torch.no_grad():\n",
    "            q_phi = torch.tensor(query_phi[i]).view(1,1,dim)\n",
    "            q_a = torch.tensor([[a_query]], dtype=torch.int64)\n",
    "            m_q = outcome_forward(out_net, q_phi, q_a).item()\n",
    "        \n",
    "        mu_hat[i] = m_q + np.sum(w_tilde * res)\n",
    "    return mu_hat\n",
    "\n",
    "# ---------------------------------\n",
    "# 6) Main demo: train & evaluate\n",
    "# ---------------------------------\n",
    "\n",
    "def main():\n",
    "    X, A, Y = make_synthetic_longitudinal(N=800, T=5, d_x=6, seed=1337)\n",
    "    cfg = TrainConfig(epochs=8, batch_size=64, d_x=6, T=5, d_latent=16, lam_mmd=0.1)\n",
    "    model, data = train_cknn_lsh(X, A, Y, cfg)\n",
    "    \n",
    "    enc = model[\"enc\"]; out_net = model[\"out_net\"]; prop_net = model[\"prop_net\"]\n",
    "    phi_tr, phi_te = data[\"phi_tr\"], data[\"phi_te\"]\n",
    "    \n",
    "    # Flatten to visit-level\n",
    "    phi_tr_flat, A_tr_flat, Y_tr_flat = flatten_time(phi_tr, data[\"Atr\"].numpy(), data[\"Ytr\"].numpy())\n",
    "    phi_te_flat, A_te_flat, Y_te_flat = flatten_time(phi_te, data[\"Ate\"].numpy(), data[\"Yte\"].numpy())\n",
    "    \n",
    "    # Estimate mu(a|H) on test for a in {0,1}\n",
    "    mu0 = dr_knn_mu(enc, out_net, prop_net, phi_tr_flat, A_tr_flat, Y_tr_flat, phi_te_flat, a_query=0, k=50, temp=1.0)\n",
    "    mu1 = dr_knn_mu(enc, out_net, prop_net, phi_tr_flat, A_tr_flat, Y_tr_flat, phi_te_flat, a_query=1, k=50, temp=1.0)\n",
    "    \n",
    "    # Simple evaluation proxy: If observed A_te==1, compare Y to mu1; else compare to mu0.\n",
    "    y_pred_obs = np.where(A_te_flat==1, mu1, mu0)\n",
    "    mse = mean_squared_error(Y_te_flat, y_pred_obs)\n",
    "    print(f\"Test MSE against observed-treatment counterfactual: {mse:.4f}\")\n",
    "    \n",
    "    # Simple \"policy\": treat if mu1 > mu0\n",
    "    policy = (mu1 > mu0).astype(int)\n",
    "    # Off-policy DR value estimate on test (single-step approximation)\n",
    "    # Here we just use observed one-step outcomes; for multi-step, apply sequential DR.\n",
    "    # Propensity on test:\n",
    "    with torch.no_grad():\n",
    "        dim = phi_te.shape[-1]\n",
    "        p1_te = torch.sigmoid(model[\"prop_net\"](torch.tensor(phi_te).view(-1,dim))).view(-1).numpy()\n",
    "    e_te = np.where(A_te_flat==1, p1_te, 1-p1_te)\n",
    "    with torch.no_grad():\n",
    "        # outcome regression at observed A\n",
    "        B = phi_te_flat.shape[0]\n",
    "        a_obs = torch.tensor(A_te_flat.reshape(1,-1), dtype=torch.int64)\n",
    "        m_obs = outcome_forward(out_net, torch.tensor(phi_te_flat).view(1,-1,dim), a_obs).view(-1).numpy()\n",
    "    dr_value = np.mean( (policy==A_te_flat)/np.clip(e_te,1e-3,1-1e-3) * (Y_te_flat - m_obs) + \n",
    "                        ( (policy)*(mu1) + (1-policy)*(mu0) ) )\n",
    "    print(f\"Off-policy DR value (approx.): {dr_value:.4f}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88046b90-91d9-4b79-a555-0590750dc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_col = \"A_booster\"      # or \"A_vax_any\" or \"A_dose3\" etc.\n",
    "\n",
    "X_list, A_list, Y_list, X_cols = build_triplets_from_XA_and_outcome(\n",
    "    X_visit=X_visit_with_A,\n",
    "    outcome_df=pasc_df,                 # columns: PARTICIPANT_ID, date, pasc_score\n",
    "    id_col=\"PARTICIPANT_ID\",\n",
    "    visit_col=\"VISIT_START_DATE\",\n",
    "    A_col=A_col,                        # e.g., \"A_booster\"\n",
    "    outcome_col=\"pasc_score\",\n",
    "    outcome_date_col=\"date\",\n",
    "    outcome_mode=\"delta_next\",          # or \"next_value\"\n",
    "    max_forward_days=120                # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fda3f07-4172-47a5-a39b-d03629b5a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def asof_per_patient(left_df, right_df, id_col, left_time, right_time, outcome_col,direction=\"forward\", allow_exact_matches=True):\n",
    "    out = []\n",
    "    for pid, L in left_df.groupby(id_col, sort=False):\n",
    "        R = right_df[right_df[id_col] == pid]\n",
    "        if L.empty:\n",
    "            continue\n",
    "        # sort & drop NaT within this patient\n",
    "        L = L.copy(); R = R.copy()\n",
    "        L[left_time] = pd.to_datetime(L[left_time], errors=\"coerce\").dt.tz_localize(None)\n",
    "        R[right_time] = pd.to_datetime(R[right_time], errors=\"coerce\").dt.tz_localize(None)\n",
    "        L = L[L[left_time].notna()].sort_values(left_time)\n",
    "        R = R[R[right_time].notna()].sort_values(right_time)\n",
    "        if R.empty:\n",
    "            # still add rows with _y_next = NaN to keep alignment if you need it later\n",
    "            tmp = L.copy()\n",
    "            tmp[\"_y_next\"] = np.nan\n",
    "            tmp[\"_y_next_date\"] = pd.NaT\n",
    "        else:\n",
    "            tmp = pd.merge_asof(\n",
    "                L,\n",
    "                R[[id_col, right_time, outcome_col]],\n",
    "                left_on=left_time,\n",
    "                right_on=right_time,\n",
    "                direction=direction,\n",
    "                allow_exact_matches=allow_exact_matches,\n",
    "            ).rename(columns={outcome_col: \"_y_next\", right_time: \"_y_next_date\"})\n",
    "        out.append(tmp)\n",
    "    return pd.concat(out, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def _clean_for_asof(df, id_col, time_col):\n",
    "    df = df.copy()\n",
    "    # parse to timezone-naive datetimes\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors='coerce').dt.tz_localize(None)\n",
    "    # drop rows with missing id or time (asof requires non-null)\n",
    "    df = df[df[id_col].notna() & df[time_col].notna()]\n",
    "    # sort by id then time (required for asof with \"by\")\n",
    "    df = df.sort_values([id_col, time_col])\n",
    "    # optional: drop duplicate rows on (id,time) if they exist\n",
    "    df = df.drop_duplicates(subset=[id_col, time_col])\n",
    "    return df\n",
    "def build_triplets_from_XA_and_outcome(\n",
    "    X_visit, outcome_df,\n",
    "    id_col=\"PARTICIPANT_ID\",\n",
    "    visit_col=\"VISIT_START_DATE\",\n",
    "    A_col=\"A_booster\",\n",
    "    outcome_col=\"pasc_score\",\n",
    "    outcome_date_col=\"date\",\n",
    "    outcome_mode=\"next_value\",\n",
    "    max_forward_days=None\n",
    "):\n",
    "    dfX = _clean_for_asof(X_visit, id_col, visit_col)\n",
    "    dfY = _clean_for_asof(outcome_df, id_col, outcome_date_col)\n",
    "\n",
    "    # feature columns (exclude id/date/A and non-numeric)\n",
    "    exclude = {id_col, visit_col, A_col}\n",
    "    non_numeric = set(dfX.select_dtypes(include=[\"object\"]).columns)\n",
    "    X_cols = [c for c in dfX.columns if c not in exclude and c not in non_numeric]\n",
    "\n",
    "    # NEXT outcome after each visit (no leakage)\n",
    "    # out_next = (\n",
    "    #     pd.merge_asof(\n",
    "    #         dfX[[id_col, visit_col]],\n",
    "    #         dfY[[id_col, outcome_date_col, outcome_col]],\n",
    "    #         by=id_col,\n",
    "    #         left_on=visit_col,\n",
    "    #         right_on=outcome_date_col,\n",
    "    #         direction=\"forward\",\n",
    "    #         allow_exact_matches=True,\n",
    "    #     )\n",
    "    #     .rename(columns={outcome_col: \"_y_next\", outcome_date_col: \"_y_next_date\"})\n",
    "    # )\n",
    "    # Use it like:\n",
    "    left  = dfX[[id_col, visit_col]].copy()\n",
    "    right = dfY[[id_col, outcome_date_col, outcome_col]].copy()\n",
    "    out_next = asof_per_patient(\n",
    "        left_df=left, right_df=right,\n",
    "        id_col=id_col, left_time=visit_col, right_time=outcome_date_col,outcome_col=outcome_col,\n",
    "        direction=\"forward\", allow_exact_matches=True\n",
    "    ).rename(columns={outcome_col: \"_y_next\", outcome_date_col: \"_y_next_date\"})\n",
    "    \n",
    "\n",
    "\n",
    "    if max_forward_days is not None:\n",
    "        dt = (out_next[\"_y_next_date\"] - dfX[visit_col]).dt.days\n",
    "        out_next.loc[dt > max_forward_days, \"_y_next\"] = np.nan\n",
    "\n",
    "    if outcome_mode == \"delta_next\":\n",
    "        left  = dfX[[id_col, visit_col]].copy()\n",
    "        right = dfY[[id_col, outcome_date_col, outcome_col]].copy()\n",
    "        # out_prev = asof_per_patient(\n",
    "        #     left_df=left, right_df=right,\n",
    "        #     id_col=id_col, left_time=visit_col, right_time=outcome_date_col,outcome_col=outcome_col,\n",
    "        #     direction=\"backward\", allow_exact_matches=True\n",
    "        # ).rename(columns={outcome_col: \"_y_prev\"})       \n",
    "        # backward (previous outcome)\n",
    "        out_prev = asof_per_patient(\n",
    "            left_df=left, right_df=right,\n",
    "            id_col=id_col, left_time=visit_col, right_time=outcome_date_col, outcome_col=outcome_col,\n",
    "            direction=\"backward\", allow_exact_matches=True\n",
    "        )\n",
    "        # <-- rename the columns that asof_per_patient created\n",
    "        out_prev = out_prev.rename(columns={\"_y_next\": \"_y_prev\", \"_y_next_date\": \"_y_prev_date\"})\n",
    "        \n",
    "        # now this works:\n",
    "        aligned = pd.concat([dfX[[id_col, visit_col]], out_next[\"_y_next\"], out_prev[\"_y_prev\"]], axis=1)\n",
    "        aligned[\"Y_t\"] = aligned[\"_y_next\"] - aligned[\"_y_prev\"]\n",
    "        # out_prev = (\n",
    "        #     pd.merge_asof(\n",
    "        #         dfX[[id_col, visit_col]],\n",
    "        #         dfY[[id_col, outcome_date_col, outcome_col]],\n",
    "        #         by=id_col,\n",
    "        #         left_on=visit_col,\n",
    "        #         right_on=outcome_date_col,\n",
    "        #         direction=\"backward\",\n",
    "        #         allow_exact_matches=True,\n",
    "        #     ).rename(columns={outcome_col: \"_y_prev\"})\n",
    "        # )\n",
    "        # aligned = pd.concat([dfX[[id_col, visit_col]], out_next[\"_y_next\"], out_prev[\"_y_prev\"]], axis=1)\n",
    "        # aligned[\"Y_t\"] = aligned[\"_y_next\"] - aligned[\"_y_prev\"]\n",
    "    elif outcome_mode == \"next_value\":\n",
    "        aligned = pd.concat([dfX[[id_col, visit_col]], out_next[\"_y_next\"]], axis=1)\n",
    "        aligned[\"Y_t\"] = aligned[\"_y_next\"]\n",
    "    else:\n",
    "        raise ValueError(\"outcome_mode must be 'next_value' or 'delta_next'.\")\n",
    "\n",
    "    # Keep visits with a follow-up outcome\n",
    "    keep = ~aligned[\"Y_t\"].isna()\n",
    "    dfX_kept = dfX.loc[keep].copy()\n",
    "    aligned = aligned.loc[keep].copy()\n",
    "\n",
    "    # Collect ragged sequences\n",
    "    X_list, A_list, Y_list = [], [], []\n",
    "    for pid, gX in dfX_kept.groupby(id_col):\n",
    "        gX = gX.sort_values(visit_col)\n",
    "        X_arr = gX[X_cols].to_numpy(dtype=\"float32\")\n",
    "        A_arr = gX[A_col].astype(\"int8\").to_numpy()\n",
    "        Y_arr = aligned.loc[gX.index, \"Y_t\"].astype(\"float32\").to_numpy()\n",
    "        if len(X_arr) == 0: \n",
    "            continue\n",
    "        X_list.append(X_arr); A_list.append(A_arr); Y_list.append(Y_arr)\n",
    "\n",
    "    return np.array(X_list, dtype=object), np.array(A_list, dtype=object), np.array(Y_list, dtype=object), X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4479b3a1-8a3e-4c35-aa6e-344ffc37b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# f=\"/Recover2507/project-files/RECOVERAdult_BiostatsDerived_202412_symptoms_deID.csv\"\n",
    "# a=pd.read_csv(f)\n",
    "import os\n",
    "path = \"/sbgenomics/project-files/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "# 0 RECOVERAdult_BDC_202412_answerdata_deID.tsv\n",
    "# 1 RECOVERAdult_BDC_202412_biospecimens_deID.tsv\n",
    "# 2 RECOVERAdult_BDC_202412_concepts_deID.tsv\n",
    "# 3 RECOVERAdult_BDC_202412_demographics_deID.tsv\n",
    "# 4 RECOVERAdult_BDC_202412_fitbit_deID.tsv\n",
    "# 5 RECOVERAdult_BDC_202412_visits_deID.tsv\n",
    "# 6 RECOVERAdult_BiostatsDerived_202412_core_proc_deID.csv\n",
    "# 7 RECOVERAdult_BiostatsDerived_202412_symptoms_deID.csv\n",
    "# 8 RECOVERAdult_BiostatsDerived_202412_visits_deID.csv\n",
    "# 9 _1_RECOVERAdult_BDC_202412_answerdata_deID.tsv\n",
    "# 10 _1_RECOVERAdult_BDC_202412_fitbit_deID.tsv\n",
    "# 11 _1_RECOVERAdult_BiostatsDerived_202412_symptoms_deID.csv\n",
    "\n",
    "# import time \n",
    "# 0 15173 ANSWER_NUMERIC_VAL 'youth (1, Correct) [Non-infected-27m post-index]' % Gastric Retention After 1 Hour [Infected-09m post-index]\n",
    "# Index(['PARTICIPANT_ID', 'VISIT_ID', 'VISIT_TYPE', 'DATA_ENTRY_DATE',\n",
    "#        'FORM_NAME', 'INSTANCE_NUM', 'FIELD_NAME', 'DATA_FIELD_NAME',\n",
    "#        'FIELD_TYPE', 'ANSWER_LABEL', 'ANSWER_NUMERIC_VAL', 'ANSWER_TEXT_VAL',\n",
    "#        'CONECPT_CD', 'CONCEPT_NAME'],\n",
    "#       dtype='object')\n",
    "# 1 13523 PBMC_CELL_COUNT  SPECIMEN_TYPE PLASMA_TREATMENT_TYPE\n",
    "# 'PARTICIPANT_ID', 'KIT_ID', 'COLLECTION_DATE', 'SPECIMEN_TYPE',\n",
    "#        'SPECIMEN_CONCEPT_CD', 'MONTHS_SINCE_INDEX_DATE', 'SPECIMEN_VOLUME',\n",
    "#        'SPECIMEN_VOLUME_UNITS', 'SPECIMEN_THAW_COUNT',\n",
    "#        'COLLECTION_TO_FREEZE_TIME_HOURS', 'PLASMA_TREATMENT_TYPE',\n",
    "#        'PBMC_CELL_COUNT', 'PBMC_CELL_VIABILITY'],\n",
    "# 2 concept id VISIT_ID\tVISIT_TYPE\tDATA_ENTRY_DATE\tFORM_NAME\tINSTANCE_NUM\tFIELD_NAME\t\n",
    "# ['CONCEPT_CODE', 'FIELD_NAME', 'DATA_FIELD_NAME', 'FORM_NAME',\n",
    "#        'CONCEPT_NAME', 'CONCEPT_PATH_NICE', 'CONCEPT_PATH'],\n",
    "# #3 SEX_AT_BIRTH 15179, 20; ENROLL_ZIP_CODE DECEASED (15071 alive, 108 die) 'Female', 'Intersex', 'Male', 'Unknown'\n",
    "# 'PARTICIPANT_ID', 'ENROLL_PROTOCOL', 'ENROLL_SITE_ID',\n",
    "#        'ENROLL_HUB_SITE_ID', 'ENROLL_SITE_PATH', 'ENROLL_DATE',\n",
    "#        'ENROLL_CATEGORY', 'ENROLL_INDEX_DATE', 'CROSSOVER_FLAG',\n",
    "#        'CROSSOVER_INDEX_DATE', 'ONSTUDY_INFECTION', 'ONSTUDY_INFECTION_CNT',\n",
    "#        'SEX_AT_BIRTH', 'DOB', 'AGE_AT_ENROLLMENT', 'ENROLL_ZIP_CODE',\n",
    "#        'WITHDRAWN', 'WITHDRAW_DATE', 'DECEASED', 'DECEASED_DATE'],\n",
    "# # 10,552 F, 4,086 M ;   \n",
    "# # 5  VISIT_START_DATE  INFECTION_STATUS \n",
    "# ['VISIT_ID', 'PARTICIPANT_ID', 'VISIT_SITE_ID', 'VISIT_TYPE',\n",
    "#        'VISIT_START_DATE', 'INFECTION_STATUS', 'MONTHS_POSTINDEX'],\n",
    "#       dtype='object')\n",
    "# # 6  15159 acute_yn 5558 1, 9600 0, infect_yn 2513 0, 12646 1\n",
    "# record_id,acute_yn,infect_yn,infect_yn_anti_f,index_dt,enroll_dt,race___1,race___2,race___3,race___4,race___5,race___6,race___7,race___15,race____88,race_unique_an,biosex,dob,age_enroll,age_enrl_cat,preg_cohort_yn,cc_anxdep_base,cc_asthma_base,cc_autoimm_base,cc_bipolar_base,cc_cancer_base,cc_cfs_base,cc_clung_base,cc_cns_base,cc_copd_base,cc_cvd_base,cc_dementia_base,cc_diabetes_base,cc_fibromyalgia_base,cc_imm_base,cc_liver_base,cc_move_base,cc_nmusc_base,cc_o2home_base,cc_obesity_base,cc_othermh_base,cc_polyov_base,cc_pots_base,cc_renal_base,cc_seiz_base,cc_sickle_base,cc_stroke_base,cc_cvdspec___1_base,cc_cvdspec___2_base,cc_cvdspec___3_base,cc_cvdspec___4_base,cc_cvdspec___5_base,cc_cvdspec___6_base,cc_cvdspec___7_base,cc_cvdspec___8_base,cc_cvdspec___98_base,cc_cvdspec____88_base,cc_autoimmspec___1_base,cc_autoimmspec___2_base,cc_autoimmspec___3_base,cc_autoimmspec___23_base,cc_autoimmspec___4_base,cc_autoimmspec___5_base,cc_autoimmspec___6_base,cc_autoimmspec___7_base,cc_autoimmspec___8_base,cc_autoimmspec___9_base,cc_autoimmspec___10_base,cc_autoimmspec___11_base,cc_autoimmspec___12_base,cc_autoimmspec___13_base,cc_autoimmspec___14_base,cc_autoimmspec___15_base,cc_autoimmspec___16_base,cc_autoimmspec___17_base,cc_autoimmspec___18_base,cc_autoimmspec___19_base,cc_autoimmspec___20_base,cc_autoimmspec___21_base,cc_autoimmspec___22_base,cc_autoimmspec___98_base,cc_autoimmspec____88_base,cc_cancerspec___1_base,cc_cancerspec___2_base,cc_cancerspec___3_base,cc_cancerspec___4_base,cc_cancerspec___5_base,cc_cancerspec___6_base,cc_cancerspec___7_base,cc_cancerspec___8_base,cc_cancerspec___9_base,cc_cancerspec___10_base,cc_cancerspec___11_base,cc_cancerspec___12_base,cc_cancerspec___13_base,cc_cancerspec___14_base,cc_cancerspec___15_base,cc_cancerspec___16_base,cc_cancerspec___17_base,cc_cancerspec___18_base,cc_cancerspec___19_base,cc_cancerspec___20_base,cc_cancerspec___21_base,cc_cancerspec____88_base,cc_transplant_type___1_base,cc_transplant_type___2_base,cc_transplant_type___3_base,cc_transplant_type___4_base,cc_transplant_type___5_base,cc_transplant_type____88_base,cc_stroke_type___1_base,cc_stroke_type___2_base,cc_stroke_type___3_base,cc_stroke_type___4_base,cc_stroke_type___6_base,cc_stroke_type___98_base,cc_stroke_type____88_base,cc_cns_type___1_base,cc_cns_type___2_base,cc_cns_type___3_base,cc_cns_type___4_base,cc_cns_type___5_base,cc_cns_type___6_base,cc_cns_type____88_base,cc_potsspec___1_base,cc_potsspec___2_base,cc_potsspec___3_base,cc_potsspec___4_base,cc_potsspec___10_base,cc_potsspec___98_base,cc_potsspec____88_base,cc_nmusc_type___1_base,cc_nmusc_type___2_base,cc_nmusc_type___3_base,cc_nmusc_type___4_base,cc_nmusc_type___5_base,cc_nmusc_type___6_base,cc_nmusc_type____88_base,cc_move_type___1_base,cc_move_type___2_base,cc_move_type___3_base,cc_move_type___4_base,cc_move_type___5_base,cc_move_type___6_base,cc_move_type___7_base,cc_move_type___8_base,cc_move_type____88_base,cc_diabetesspec_base,cc_dialyn_base,cc_transplant_base,referral_type,spop___2,spop___3,spop___4,spop___99,education,fvacc_index,vacc_numb,vacc_vacctype_1,vacc_vaccothspec_1,vacc_vaccdt_1,vacc_vaccdt_2,vacc_vaccdt_3,enrl_reinfyn,enrl_reinfdt,rx_totalinf,acute_reinf_ovr,rx_carelevel___0,rx_carelevel___1,rx_carelevel___2,rx_carelevel___3,rx_carelevel___4,rx_carelevel___98,rx_carelevel____88,Spike,Nucleocapsid,OVER_89_FLAG,\n",
    "# # 8 pasc_score_2023 pasc_jama2023 servious ? \n",
    "# 'PARTICIPANT_ID', 'ENROLL_PROTOCOL', 'ENROLL_SITE_ID',\n",
    "#        'ENROLL_HUB_SITE_ID', 'ENROLL_SITE_PATH', 'ENROLL_DATE',\n",
    "#        'ENROLL_CATEGORY', 'ENROLL_INDEX_DATE', 'CROSSOVER_FLAG',\n",
    "#        'CROSSOVER_INDEX_DATE', 'ONSTUDY_INFECTION', 'ONSTUDY_INFECTION_CNT',\n",
    "#        'SEX_AT_BIRTH', 'DOB', 'AGE_AT_ENROLLMENT', 'ENROLL_ZIP_CODE',\n",
    "#        'WITHDRAWN', 'WITHDRAW_DATE', 'DECEASED', 'DECEASED_DATE'],\n",
    "#7 15159 , 11 NQOL_CF_Tscore depression ca_stand5dpb  phq8_total  mmrc_dyspnea (breath system) compass_score, gad7_total\n",
    "#11 record_id,redcap_event_name,ps_colldt,compass_score,gad7_total,phq8_total,hit6_total,mmrc_dyspnea,NQOL_CF_Tscore,phq9_total,promis_sleepdist_sf8a_Tscore,snore,mi_neuro_sum,NQOL_UEF_raw,promis_pf_sf4a_raw,vfq_25_score,saq_sumscore,pain_head___before_index,pain_chest___before_index,pain_abdomen___before_index,pain_pelvis___before_index,pain_joint___before_index,pain_muscle___before_index,pain_back___before_index,pain_skin___before_index,pain_feet___before_index,pain_mouth___before_index,pain_throat___before_index,nerve_tremor___before_index,nerve_abmove___before_index,nerve_numb___before_index,nerve_nomove___before_index,nerve_seizure___before_index,ps_fatigue___before_index,ps_malaise___before_index,ps_soreness___before_index,ps_weak___before_index,ps_fever___before_index,ps_temp___before_index,ps_cold___before_index,ps_sense___before_index,ps_smellsick___before_index,ps_sinus___before_index,ps_headache___before_index,ps_pain___before_index,ps_sob___before_index,ps_wheeze___before_index,ps_cough___before_index,ps_heart___before_index,ps_swelllegs___before_index,ps_gastro___before_index,ps_bladder___before_index,ps_nerve___before_index,ps_mood___before_index,ps_think___before_index,ps_sleep___before_index,ps_goofy___before_index,ps_color___before_index,ps_rash___before_index,ps_itching___before_index,ps_anaphylaxis___before_index,ps_dryeyes___before_index,ps_drymouth___before_index,ps_thirst___before_index,ps_vision___before_index,ps_hearing___before_index,ps_bald___before_index,ps_teeth___before_index,ps_menstrual___before_index,ps_menopause___before_index,ps_fertility___before_index,ps_sex___before_index,pain_other___before_index,nerve_other___before_index,ps_headachec___before_index,pain_head___around_index,pain_chest___around_index,pain_abdomen___around_index,pain_pelvis___around_index,pain_joint___around_index,pain_muscle___around_index,pain_back___around_index,pain_skin___around_index,pain_feet___around_index,pain_mouth___around_index,pain_throat___around_index,nerve_tremor___around_index,nerve_abmove___around_index,nerve_numb___around_index,nerve_nomove___around_index,nerve_seizure___around_index,ps_fatigue___around_index,ps_malaise___around_index,ps_soreness___around_index,ps_weak___around_index,ps_fever___around_index,ps_temp___around_index,ps_cold___around_index,ps_sense___around_index,ps_smellsick___around_index,ps_sinus___around_index,ps_headache___around_index,ps_pain___around_index,ps_sob___around_index,ps_wheeze___around_index,ps_cough___around_index,ps_heart___around_index,ps_swelllegs___around_index,ps_gastro___around_index,ps_bladder___around_index,ps_nerve___around_index,ps_mood___around_index,ps_think___around_index,ps_sleep___around_index,ps_goofy___around_index,ps_color___around_index,ps_rash___around_index,ps_itching___around_index,ps_anaphylaxis___around_index,ps_dryeyes___around_index,ps_drymouth___around_index,ps_thirst___around_index,ps_vision___around_index,ps_hearing___around_index,ps_bald___around_index,ps_teeth___around_index,ps_menstrual___around_index,ps_menopause___around_index,ps_fertility___around_index,ps_sex___around_index,pain_other___around_index,nerve_other___around_index,ps_headachec___around_index,pain_head___now,pain_chest___now,pain_abdomen___now,pain_pelvis___now,pain_joint___now,pain_muscle___now,pain_back___now,pain_skin___now,pain_feet___now,pain_mouth___now,pain_throat___now,nerve_tremor___now,nerve_abmove___now,nerve_numb___now,nerve_nomove___now,nerve_seizure___now,ps_fatigue___now,ps_malaise___now,ps_soreness___now,ps_weak___now,ps_fever___now,ps_temp___now,ps_cold___now,ps_sense___now,ps_smellsick___now,ps_sinus___now,ps_headache___now,ps_pain___now,ps_sob___now,ps_wheeze___now,ps_cough___now,ps_heart___now,ps_swelllegs___now,ps_gastro___now,ps_bladder___now,ps_nerve___now,ps_mood___now,ps_think___now,ps_sleep___now,ps_goofy___now,ps_color___now,ps_rash___now,ps_itching___now,ps_anaphylaxis___now,ps_dryeyes___now,ps_drymouth___now,ps_thirst___now,ps_vision___now,ps_hearing___now,ps_bald___now,ps_teeth___now,ps_menstrual___now,ps_menopause___now,ps_fertility___now,ps_sex___now,pain_other___now,nerve_other___now,ps_headachec___now,pain_head___now_not_b4_f,pain_chest___now_not_b4_f,pain_abdomen___now_not_b4_f,pain_pelvis___now_not_b4_f,pain_joint___now_not_b4_f,pain_muscle___now_not_b4_f,pain_back___now_not_b4_f,pain_skin___now_not_b4_f,pain_feet___now_not_b4_f,pain_mouth___now_not_b4_f,pain_throat___now_not_b4_f,nerve_tremor___now_not_b4_f,nerve_abmove___now_not_b4_f,nerve_numb___now_not_b4_f,nerve_nomove___now_not_b4_f,nerve_seizure___now_not_b4_f,ps_fatigue___now_not_b4_f,ps_malaise___now_not_b4_f,ps_soreness___now_not_b4_f,ps_weak___now_not_b4_f,ps_fever___now_not_b4_f,ps_temp___now_not_b4_f,ps_cold___now_not_b4_f,ps_sense___now_not_b4_f,ps_smellsick___now_not_b4_f,ps_sinus___now_not_b4_f,ps_headache___now_not_b4_f,ps_pain___now_not_b4_f,ps_sob___now_not_b4_f,ps_wheeze___now_not_b4_f,ps_cough___now_not_b4_f,ps_heart___now_not_b4_f,ps_swelllegs___now_not_b4_f,ps_gastro___now_not_b4_f,ps_bladder___now_not_b4_f,ps_nerve___now_not_b4_f,ps_mood___now_not_b4_f,ps_think___now_not_b4_f,ps_sleep___now_not_b4_f,ps_goofy___now_not_b4_f,ps_color___now_not_b4_f,ps_rash___now_not_b4_f,ps_itching___now_not_b4_f,ps_anaphylaxis___now_not_b4_f,ps_dryeyes___now_not_b4_f,ps_drymouth___now_not_b4_f,ps_thirst___now_not_b4_f,ps_vision___now_not_b4_f,ps_hearing___now_not_b4_f,ps_bald___now_not_b4_f,ps_teeth___now_not_b4_f,ps_menstrual___now_not_b4_f,ps_menopause___now_not_b4_f,ps_fertility___now_not_b4_f,ps_sex___now_not_b4_f,pain_other___now_not_b4_f,nerve_other___now_not_b4_f,ps_headachec___now_not_b4_f,pain_head___now_not_b4,pain_chest___now_not_b4,pain_abdomen___now_not_b4,pain_pelvis___now_not_b4,pain_joint___now_not_b4,pain_muscle___now_not_b4,pain_back___now_not_b4,pain_skin___now_not_b4,pain_feet___now_not_b4,pain_mouth___now_not_b4,pain_throat___now_not_b4,nerve_tremor___now_not_b4,nerve_abmove___now_not_b4,nerve_numb___now_not_b4,nerve_nomove___now_not_b4,nerve_seizure___now_not_b4,ps_fatigue___now_not_b4,ps_malaise___now_not_b4,ps_soreness___now_not_b4,ps_weak___now_not_b4,ps_fever___now_not_b4,ps_temp___now_not_b4,ps_cold___now_not_b4,ps_sense___now_not_b4,ps_smellsick___now_not_b4,ps_sinus___now_not_b4,ps_headache___now_not_b4,ps_pain___now_not_b4,ps_sob___now_not_b4,ps_wheeze___now_not_b4,ps_cough___now_not_b4,ps_heart___now_not_b4,ps_swelllegs___now_not_b4,ps_gastro___now_not_b4,ps_bladder___now_not_b4,ps_nerve___now_not_b4,ps_mood___now_not_b4,ps_think___now_not_b4,ps_sleep___now_not_b4,ps_goofy___now_not_b4,ps_color___now_not_b4,ps_rash___now_not_b4,ps_itching___now_not_b4,ps_anaphylaxis___now_not_b4,ps_dryeyes___now_not_b4,ps_drymouth___now_not_b4,ps_thirst___now_not_b4,ps_vision___now_not_b4,ps_hearing___now_not_b4,ps_bald___now_not_b4,ps_teeth___now_not_b4,ps_menstrual___now_not_b4,ps_menopause___now_not_b4,ps_fertility___now_not_b4,ps_sex___now_not_b4,pain_other___now_not_b4,nerve_other___now_not_b4,ps_headachec___now_not_b4,pain_head___any_yes,pain_chest___any_yes,pain_abdomen___any_yes,pain_pelvis___any_yes,pain_joint___any_yes,pain_muscle___any_yes,pain_back___any_yes,pain_skin___any_yes,pain_feet___any_yes,pain_mouth___any_yes,pain_throat___any_yes,nerve_tremor___any_yes,nerve_abmove___any_yes,nerve_numb___any_yes,nerve_nomove___any_yes,nerve_seizure___any_yes,ps_fatigue___any_yes,ps_malaise___any_yes,ps_soreness___any_yes,ps_weak___any_yes,ps_fever___any_yes,ps_temp___any_yes,ps_cold___any_yes,ps_sense___any_yes,ps_smellsick___any_yes,ps_sinus___any_yes,ps_headache___any_yes,ps_pain___any_yes,ps_sob___any_yes,ps_wheeze___any_yes,ps_cough___any_yes,ps_heart___any_yes,ps_swelllegs___any_yes,ps_gastro___any_yes,ps_bladder___any_yes,ps_nerve___any_yes,ps_mood___any_yes,ps_think___any_yes,ps_sleep___any_yes,ps_goofy___any_yes,ps_color___any_yes,ps_rash___any_yes,ps_itching___any_yes,ps_anaphylaxis___any_yes,ps_dryeyes___any_yes,ps_drymouth___any_yes,ps_thirst___any_yes,ps_vision___any_yes,ps_hearing___any_yes,ps_bald___any_yes,ps_teeth___any_yes,ps_menstrual___any_yes,ps_menopause___any_yes,ps_fertility___any_yes,ps_sex___any_yes,pain_other___any_yes,nerve_other___any_yes,ps_headachec___any_yes,pain_head___any_yes_notb4,pain_chest___any_yes_notb4,pain_abdomen___any_yes_notb4,pain_pelvis___any_yes_notb4,pain_joint___any_yes_notb4,pain_muscle___any_yes_notb4,pain_back___any_yes_notb4,pain_skin___any_yes_notb4,pain_feet___any_yes_notb4,pain_mouth___any_yes_notb4,pain_throat___any_yes_notb4,nerve_tremor___any_yes_notb4,nerve_abmove___any_yes_notb4,nerve_numb___any_yes_notb4,nerve_nomove___any_yes_notb4,nerve_seizure___any_yes_notb4,ps_fatigue___any_yes_notb4,ps_malaise___any_yes_notb4,ps_soreness___any_yes_notb4,ps_weak___any_yes_notb4,ps_fever___any_yes_notb4,ps_temp___any_yes_notb4,ps_cold___any_yes_notb4,ps_sense___any_yes_notb4,ps_smellsick___any_yes_notb4,ps_sinus___any_yes_notb4,ps_headache___any_yes_notb4,ps_pain___any_yes_notb4,ps_sob___any_yes_notb4,ps_wheeze___any_yes_notb4,ps_cough___any_yes_notb4,ps_heart___any_yes_notb4,ps_swelllegs___any_yes_notb4,ps_gastro___any_yes_notb4,ps_bladder___any_yes_notb4,ps_nerve___any_yes_notb4,ps_mood___any_yes_notb4,ps_think___any_yes_notb4,ps_sleep___any_yes_notb4,ps_goofy___any_yes_notb4,ps_color___any_yes_notb4,ps_rash___any_yes_notb4,ps_itching___any_yes_notb4,ps_anaphylaxis___any_yes_notb4,ps_dryeyes___any_yes_notb4,ps_drymouth___any_yes_notb4,ps_thirst___any_yes_notb4,ps_vision___any_yes_notb4,ps_hearing___any_yes_notb4,ps_bald___any_yes_notb4,ps_teeth___any_yes_notb4,ps_menstrual___any_yes_notb4,ps_menopause___any_yes_notb4,ps_fertility___any_yes_notb4,ps_sex___any_yes_notb4,pain_other___any_yes_notb4,nerve_other___any_yes_notb4,ps_headachec___any_yes_notb4,pain_head___funl,pain_chest___funl,pain_abdomen___funl,pain_pelvis___funl,pain_joint___funl,pain_muscle___funl,pain_back___funl,pain_skin___funl,pain_feet___funl,pain_mouth___funl,pain_throat___funl,nerve_tremor___funl,nerve_abmove___funl,nerve_numb___funl,nerve_nomove___funl,nerve_seizure___funl,ps_fatigue___funl,ps_malaise___funl,ps_soreness___funl,ps_weak___funl,ps_fever___funl,ps_temp___funl,ps_cold___funl,ps_sense___funl,ps_smellsick___funl,ps_sinus___funl,ps_headache___funl,ps_pain___funl,ps_sob___funl,ps_wheeze___funl,ps_cough___funl,ps_heart___funl,ps_swelllegs___funl,ps_gastro___funl,ps_bladder___funl,ps_nerve___funl,ps_mood___funl,ps_think___funl,ps_sleep___funl,ps_goofy___funl,ps_color___funl,ps_rash___funl,ps_itching___funl,ps_anaphylaxis___funl,ps_dryeyes___funl,ps_drymouth___funl,ps_thirst___funl,ps_vision___funl,ps_hearing___funl,ps_bald___funl,ps_teeth___funl,ps_menstrual___funl,ps_menopause___funl,ps_fertility___funl,ps_sex___funl,pain_other___funl,nerve_other___funl,ps_headachec___funl,pain_head___aft30d,pain_chest___aft30d,pain_abdomen___aft30d,pain_pelvis___aft30d,pain_joint___aft30d,pain_muscle___aft30d,pain_back___aft30d,pain_skin___aft30d,pain_feet___aft30d,pain_mouth___aft30d,pain_throat___aft30d,nerve_tremor___aft30d,nerve_abmove___aft30d,nerve_numb___aft30d,nerve_nomove___aft30d,nerve_seizure___aft30d,ps_fatigue___aft30d,ps_malaise___aft30d,ps_soreness___aft30d,ps_weak___aft30d,ps_fever___aft30d,ps_temp___aft30d,ps_cold___aft30d,ps_sense___aft30d,ps_smellsick___aft30d,ps_sinus___aft30d,ps_headache___aft30d,ps_pain___aft30d,ps_sob___aft30d,ps_wheeze___aft30d,ps_cough___aft30d,ps_heart___aft30d,ps_swelllegs___aft30d,ps_gastro___aft30d,ps_bladder___aft30d,ps_nerve___aft30d,ps_mood___aft30d,ps_think___aft30d,ps_sleep___aft30d,ps_goofy___aft30d,ps_color___aft30d,ps_rash___aft30d,ps_itching___aft30d,ps_anaphylaxis___aft30d,ps_dryeyes___aft30d,ps_drymouth___aft30d,ps_thirst___aft30d,ps_vision___aft30d,ps_hearing___aft30d,ps_bald___aft30d,ps_teeth___aft30d,ps_menstrual___aft30d,ps_menopause___aft30d,ps_fertility___aft30d,ps_sex___aft30d,pain_other___aft30d,nerve_other___aft30d,ps_headachec___aft30d,ps_anxiety___now,ps_depress___now,ps_sleepapnea___now,ps_sleepdist___now,ps_anxiety___before_index,ps_depress___before_index,ps_sleepapnea___before_index,ps_sleepdist___before_index,cp_sum,musc_sum,neuro_sum,high_hr_sus,pots_oh,pots_ot,pots,promis_global01,promis_global02,promis_global03,promis_global04,promis_global05,promis_global09r,promis_global06,promis_global10,promis_global08,promis_global07,ps_compass31_calc,compass31_faintfreq,compass31_faintsev,compass31_fainttraj,compass31_colorloc___1,compass31_colorloc___2,compass31_colortraj,compass31_sweatyn,compass31_dryeyesyn,compass31_drymouthtraj,compass31_fullrate,compass31_bloated,compass31_vomit,compass31_cramp,compass31_diarryn,compass31_diarrfreq,compass31_diarrsev,compass31_diarrtraj,compass31_constyn,compass31_constsev,compass31_consttraj,compass31_controlbladder,compass31_urinepass,compass31_emptybladder,compass31_lightyn,compass31_lightsev,compass31_focusyn,compass31_focussev,compass31_vistraj,gad_1,gad_2,gad_3,gad_4,gad_5,gad_6,gad_7,phq_1,phq_2,phq_3,phq_4,phq_5,phq_6,phq_7,phq_8,phq_9,hit6_severerecode,hit6_activitiesrecode,hit6_liedownrecode,hit6_tootiredrecode,hit6_concentraterecode,hit6_irritatedrecode,nqcog_nqcog64r1,nqcog_nqcog75r1,nqcog_nqcog77r1,nqcog_nqcog80r1,nqcog_nqcog22r1,nqcog_nqcog24r1,nqcog_nqcog25r1,nqcog_nqcog40r1,promis_sleep109,promis_sleep116,promis_sleep20,promis_sleep44,promis_sleep108,promis_sleep72,promis_sleep67,promis_sleep115,neuroqol_pfa40,neuroqol_pfa50,neuroqol_pfb21,neuroqol_pfa43,neuroqol_pfa35,neuroqol_pfa55,neuroqol_pfb26,neuroqol_nquex44,mi_neuro1recode,mi_neuro2recode,mi_neuro3recode,mi_neuro4recode,mi_neuro5recode,mi_neuro6recode,mi_neuro7recode,mi_neuro8recode,mi_neuro9recode,mi_neuro10recode,mi_neuro11recode,mi_neuro12recode,mi_neuro13recode,mi_neuro14recode,mi_neuro15recode,promis_pfa11,promis_pfa21,promis_pfa23,promis_pfa53,vfq_2recode,vfq_4recode,vfq_19recode,vfq_5recode,vfq_6recode,vfq_7recode,vfq_8recode,vfq_9recode,vfq_14recode,vfq_11recode,vfq_13recode,vfq_3recode,vfq_21recode,vfq_22recode,vfq_25recode,vfq_17recode,vfq_18recode,vfq_20recode,vfq_23recode,vfq_24recode,vfq_15c,vfq_16,vfq_16a,vfq_12recode,vfq_10recode,visit_month,visit_month_curr,instance,instance_curr,index_dt_curr,infect_yn_curr,ca_hrsupine1,ca_sbpsupine1,ca_dbpsupine1,ca_stand1sbp,ca_stand1dpb,ca_stand3sbp,ca_stand3dpb,ca_stand5sbp,ca_stand5dpb,ca_stand10sbp,ca_stand10dbp,ca_stand1hr,ca_stand3hr,ca_stand5hr,ca_stand10hr,\n",
    "# start_time = time.time()\n",
    "# df0 = pd.read_csv(path+files[0], sep='\\t', encoding='latin1')\n",
    "# print(df0.columns)\n",
    "# df01 = pd.read_csv(path+files[1], sep='\\t', encoding='latin1')\n",
    "# print(df01.columns)\n",
    "# df02 = pd.read_csv(path+files[2], sep='\\t', encoding='latin1')\n",
    "# print(df02.columns)\n",
    "# df3 = pd.read_csv(path + files[8], sep=',', encoding='latin1')\n",
    "# dfinfe = pd.read_csv(path+files[5], sep='\\t', encoding='latin1')\n",
    "# print(df05.columns)\n",
    "# df06 = pd.read_csv(path+files[6], sep=',', encoding='latin1')\n",
    "# print(df06.columns)\n",
    "# dfm = pd.read_csv(path+files[7], sep=',', encoding='latin1')\n",
    "# df1 = pd.read_csv(path+files[10], sep='\\t', encoding='latin1')\n",
    "# df11 = pd.read_csv(path+files[11], sep=',', encoding='latin1')\n",
    "# print(df11.columns)\n",
    "\n",
    "# print(time.time()-start_time, df1.shape)\n",
    "# df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08b3f419-1911-46cd-bca2-2f6117a46486",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinfe.shape #PARTICIPANT_ID  VISIT_START_DATE  INFECTION_STATUS  MONTHS_POSTINDEX 158685\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_X(dynamic_df: pd.DataFrame,\n",
    "           static_df: pd.DataFrame,\n",
    "           id_col=\"PARTICIPANT_ID\",\n",
    "           date_col=\"VISIT_START_DATE\"):\n",
    "    \"\"\"\n",
    "    Combine dynamic + static into a numeric feature matrix X per visit.\n",
    "\n",
    "    Inputs:\n",
    "      dynamic_df: columns include [PARTICIPANT_ID, VISIT_START_DATE, INFECTION_STATUS, MONTHS_POSTINDEX, ...]\n",
    "      static_df:  columns include [PARTICIPANT_ID, age, race, (optional zip, ...)]\n",
    "\n",
    "    Returns:\n",
    "      X_df   : DataFrame with [id_col, date_col] + numeric X columns\n",
    "      X_cols: list of feature column names in X_df\n",
    "    \"\"\"\n",
    "    df = dynamic_df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df = df.sort_values([id_col, date_col])\n",
    "\n",
    "    # Ensure one row per person in static (pick first if duplicates)\n",
    "    s = static_df.copy()\n",
    "    s = s.sort_values([id_col]).groupby(id_col, as_index=False).first()\n",
    "\n",
    "    # Merge static onto each visit\n",
    "    df = df.merge(s, on=id_col, how=\"left\")\n",
    "\n",
    "    # ---- calendar/seasonality\n",
    "    m = df[date_col].dt.month\n",
    "    df[\"cal_sin_month\"] = np.sin(2*np.pi*m/12.0).astype(\"float32\")\n",
    "    df[\"cal_cos_month\"] = np.cos(2*np.pi*m/12.0).astype(\"float32\")\n",
    "\n",
    "    # ---- age at visit (if available)\n",
    "    if \"AGE_AT_ENROLLMENT\" in df.columns and \"MONTHS_POSTINDEX\" in df.columns:\n",
    "        df[\"age_at_visit\"] = (df[\"AGE_AT_ENROLLMENT\"].astype(float) + df[\"MONTHS_POSTINDEX\"].astype(float)/12.0).astype(\"float32\")\n",
    "\n",
    "    # ---- race one-hot (no sklearn)\n",
    "    if \"race\" in df.columns:\n",
    "        race_oh = pd.get_dummies(df[\"race\"].astype(\"category\"), prefix=\"race\", dtype=\"float32\")\n",
    "        df = pd.concat([df.drop(columns=[\"race\"]), race_oh], axis=1)\n",
    "\n",
    "    # ---- infection status one-hot\n",
    "    if \"INFECTION_STATUS\" in df.columns:\n",
    "        inf_oh = pd.get_dummies(df[\"INFECTION_STATUS\"].astype(\"category\"), prefix=\"inf\", dtype=\"float32\")\n",
    "        df = pd.concat([df, inf_oh], axis=1)\n",
    "\n",
    "    # ---- optional: zip -> 3-digit prefix one-hot (avoid huge cardinality)\n",
    "    if \"ENROLL_ZIP_CODE\" in df.columns:\n",
    "        df[\"zip3\"] = df[\"ENROLL_ZIP_CODE\"].astype(str).str.slice(0, 3)\n",
    "        zip3_oh = pd.get_dummies(df[\"zip3\"].astype(\"category\"), prefix=\"zip3\", dtype=\"float32\")\n",
    "        df = pd.concat([df.drop(columns=[\"ENROLL_ZIP_CODE\", \"zip3\"]), zip3_oh], axis=1)\n",
    "\n",
    "    # Collect numeric feature columns (exclude id/date and remaining non-numeric)\n",
    "    exclude = {id_col, date_col}\n",
    "    non_numeric = set(df.select_dtypes(include=[\"object\"]).columns)\n",
    "    X_cols = [c for c in df.columns if c not in exclude and c not in non_numeric]\n",
    "\n",
    "    # Light missing handling: numeric mean-impute\n",
    "    for c in X_cols:\n",
    "        if df[c].dtype.kind in \"biufc\":\n",
    "            df[c] = df[c].astype(\"float32\")\n",
    "            if df[c].isna().any():\n",
    "                df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    X_df = df[[id_col, date_col] + X_cols].sort_values([id_col, date_col]).reset_index(drop=True)\n",
    "    return X_df, X_cols\n",
    "\n",
    "def to_patient_sequences(X_df: pd.DataFrame,\n",
    "                         X_cols,\n",
    "                         id_col=\"PARTICIPANT_ID\",\n",
    "                         date_col=\"VISIT_START_DATE\"):\n",
    "    \"\"\"\n",
    "    Turn the flat X_df into a list of per-patient numpy arrays (ragged sequences).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    for _, g in X_df.groupby(id_col):\n",
    "        g = g.sort_values(date_col)\n",
    "        X_list.append(g[X_cols].to_numpy(dtype=\"float32\"))\n",
    "    return np.array(X_list, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1d759e72-3e6c-4ff8-8f6d-5ede2531058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PARTICIPANT_ID', 'acute_yn', 'infect_yn', 'race___1', 'race___2',\n",
       "       'race___3', 'race___4', 'race___5', 'race___6', 'race___7', 'race___15',\n",
       "       'race____88', 'race_unique_an', 'dob', 'age_enroll', 'age_enrl_cat',\n",
       "       'preg_cohort_yn', 'referral_type', 'spop___2', 'spop___3', 'spop___4',\n",
       "       'spop___99', 'acute_reinf_ovr', 'rx_carelevel___0', 'rx_carelevel___1',\n",
       "       'rx_carelevel___2', 'rx_carelevel___3', 'rx_carelevel___4',\n",
       "       'rx_carelevel___98', 'rx_carelevel____88', 'ENROLL_DATE',\n",
       "       'SEX_AT_BIRTH', 'AGE_AT_ENROLLMENT', 'ENROLL_ZIP_CODE', 'DECEASED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfassess = pd.read_csv(path+files[7], sep=',', encoding='latin1')\n",
    "df_cleaned.columns#.head()\n",
    "# df_cleaned.rename({'record_id':\"PARTICIPANT_ID\"},axis='columns',inplace=True)\n",
    "# df_cleaned.to_csv('x_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "030604b9-c99c-45a0-850e-cdf18d21cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def suffix_to_int(col):\n",
    "    m = re.search(r'(\\d+)$', col)   # grab trailing digits after any underscores\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def collapse_race_to_code(df, race_cols, multiracial_code=777, unknown_code=999, priority=None):\n",
    "   # 0/1 clean-up\n",
    "    tmp = df[race_cols].apply(pd.to_numeric, errors='coerce').fillna(0).clip(0,1).astype('int8')\n",
    "    counts = tmp.sum(axis=1)\n",
    "\n",
    "    # map col -> numeric code from its suffix\n",
    "    col_to_code = {c: suffix_to_int(c) for c in race_cols}\n",
    "\n",
    "    # default choice = column with max value (ties broken by first occurrence)\n",
    "    choice_col = tmp.idxmax(axis=1)\n",
    "\n",
    "    if priority:\n",
    "        # If you want a specific tie-break order, override choice where multiple selected\n",
    "        multi = counts > 1\n",
    "        if multi.any():\n",
    "            # pick the first column in 'priority' that is 1\n",
    "            prio_arr = np.full(len(df), None, dtype=object)\n",
    "            for c in priority:\n",
    "                take = multi & (tmp[c] == 1) & pd.isna(prio_arr)\n",
    "                prio_arr[take.values] = c\n",
    "            # fall back to previous choice if somehow none matched\n",
    "            choice_col = np.where(multi, prio_arr, choice_col)\n",
    "\n",
    "    # map column names to numeric codes\n",
    "    choice_code = pd.Series(choice_col, index=df.index).map(col_to_code)\n",
    "\n",
    "    # assemble final race_code with special cases\n",
    "    race_code = np.where(counts == 0, unknown_code,     # none selected\n",
    "                np.where(counts > 1,  multiracial_code, # multiple selected\n",
    "                         choice_code))                  # exactly one\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['race'] = pd.Series(race_code, index=df.index).astype('int32')\n",
    "    return df\n",
    "race_cols = ['race___1','race___2','race___3','race___4','race___5','race___6','race___7','race___15','race____88']\n",
    "\n",
    "# Strategy A: mark multi as 777, none as 999\n",
    "df_out = collapse_race_to_code(df_cleaned, race_cols, multiracial_code=777, unknown_code=999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3350f5c0-99dd-4494-9d19-ae0e826aa8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158685, 659)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape#X_df.columns\n",
    "# (158685, 659)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "64669154-bf81-4811-8637-92d5fe59617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfassess.head() record_id, ps_colldt, NQOL_CF_Tscore\n",
    "# dfm = dfassess[['record_id', 'ps_colldt', 'NQOL_CF_Tscore']]\n",
    "# dfm.rename({'record_id':'PARTICIPANT_ID', 'ps_colldt':'date'})\n",
    "X_df, X_cols = make_X(dfinfe, df_out_drop)\n",
    "\n",
    "# Optional: save a flat feature table for inspection\n",
    "X_df.to_csv(\"X_visits.csv\", index=False)\n",
    "\n",
    "# Optional: convert to per-patient sequences (for the cKNN-LSH pipeline later)\n",
    "X_obj = to_patient_sequences(X_df, X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8c44886e-ac07-4b00-8c4f-e0ad8eafa950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15159, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15159, 27)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_df.head()\n",
    "# df_out.shape#()\n",
    "# df_out['race_code']\n",
    "print(df_out.shape)\n",
    "df_out_drop = df_out.drop(race_cols, axis=1)\n",
    "df_out_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df434698-ad1e-44fc-8e21-ddcda9c000a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167/1573233774.py:1: DtypeWarning: Columns (7,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_0 = pd.read_csv(path+files[0], sep='\\t', encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PARTICIPANT_ID', 'VISIT_ID', 'VISIT_TYPE', 'DATA_ENTRY_DATE',\n",
      "       'FORM_NAME', 'INSTANCE_NUM', 'FIELD_NAME', 'DATA_FIELD_NAME',\n",
      "       'FIELD_TYPE', 'ANSWER_LABEL', 'ANSWER_NUMERIC_VAL', 'ANSWER_TEXT_VAL',\n",
      "       'CONECPT_CD', 'CONCEPT_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_0 = pd.read_csv(path+files[0], sep='\\t', encoding='latin1')\n",
    "print(df_0.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e505dd-f8f8-486b-8c00-f366bf3cd6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# forms = np.unique(df_0['FORM_NAME'])\n",
    "# print(len(forms)) \n",
    "\"pasc_symptoms\" in forms\n",
    "\"vaccine_status\" in forms\n",
    "print(\"covid_treatment\" in forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef82265f-d60e-4b76-8a2b-d58d193f31e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10919389, 14)\n",
      "(342179, 14)\n",
      "(194085, 14)\n"
     ]
    }
   ],
   "source": [
    "df_0pasc = df_0[df_0['FORM_NAME']==\"pasc_symptoms\"]\n",
    "print(df_0pasc.shape)\n",
    "df_0vacc = df_0[df_0['FORM_NAME']==\"vaccine_status\"]\n",
    "print(df_0vacc.shape)\n",
    "df_0covidtreat = df_0[df_0['FORM_NAME']==\"covid_treatment\"]\n",
    "print(df_0covidtreat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c1a0f22-fd82-4bb8-823e-00a4cc7e7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0covidtreat[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "262e3a1e-6619-4daf-abbb-c8be4bdcbded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTICIPANT_ID</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>VISIT_TYPE</th>\n",
       "      <th>DATA_ENTRY_DATE</th>\n",
       "      <th>FORM_NAME</th>\n",
       "      <th>INSTANCE_NUM</th>\n",
       "      <th>FIELD_NAME</th>\n",
       "      <th>DATA_FIELD_NAME</th>\n",
       "      <th>FIELD_TYPE</th>\n",
       "      <th>ANSWER_LABEL</th>\n",
       "      <th>ANSWER_NUMERIC_VAL</th>\n",
       "      <th>ANSWER_TEXT_VAL</th>\n",
       "      <th>CONECPT_CD</th>\n",
       "      <th>CONCEPT_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27501692</th>\n",
       "      <td>RA12016</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>enrollment</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>vaccine_status</td>\n",
       "      <td>1</td>\n",
       "      <td>vacc_coord</td>\n",
       "      <td>vacc_coord___1</td>\n",
       "      <td>choice</td>\n",
       "      <td>Coordinator data entry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RC-RA1:vacc_coord___1|Inf|v0</td>\n",
       "      <td>Check this box if the coordinator is entering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27501693</th>\n",
       "      <td>RA112169</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>enrollment</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>vaccine_status</td>\n",
       "      <td>1</td>\n",
       "      <td>vacc_coord</td>\n",
       "      <td>vacc_coord___1</td>\n",
       "      <td>choice</td>\n",
       "      <td>Coordinator data entry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RC-RA1:vacc_coord___1|Inf|v0</td>\n",
       "      <td>Check this box if the coordinator is entering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27501694</th>\n",
       "      <td>RA1264</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>enrollment</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>vaccine_status</td>\n",
       "      <td>1</td>\n",
       "      <td>vacc_coord</td>\n",
       "      <td>vacc_coord___1</td>\n",
       "      <td>choice</td>\n",
       "      <td>Coordinator data entry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RC-RA1:vacc_coord___1|Inf|v0</td>\n",
       "      <td>Check this box if the coordinator is entering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27501695</th>\n",
       "      <td>RA17991</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>enrollment</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>vaccine_status</td>\n",
       "      <td>1</td>\n",
       "      <td>vacc_coord</td>\n",
       "      <td>vacc_coord___1</td>\n",
       "      <td>choice</td>\n",
       "      <td>Coordinator data entry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RC-RA1:vacc_coord___1|Inf|v0</td>\n",
       "      <td>Check this box if the coordinator is entering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27501696</th>\n",
       "      <td>RA18073</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>enrollment</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>vaccine_status</td>\n",
       "      <td>1</td>\n",
       "      <td>vacc_coord</td>\n",
       "      <td>vacc_coord___1</td>\n",
       "      <td>choice</td>\n",
       "      <td>Coordinator data entry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RC-RA1:vacc_coord___1|Inf|v0</td>\n",
       "      <td>Check this box if the coordinator is entering ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PARTICIPANT_ID         VISIT_ID  VISIT_TYPE DATA_ENTRY_DATE  \\\n",
       "27501692        RA12016   baseline_arm_1  enrollment      2022-01-01   \n",
       "27501693       RA112169   baseline_arm_1  enrollment      2022-01-01   \n",
       "27501694         RA1264   baseline_arm_1  enrollment      2022-01-01   \n",
       "27501695        RA17991   baseline_arm_1  enrollment      2022-01-01   \n",
       "27501696        RA18073   baseline_arm_1  enrollment      2022-01-01   \n",
       "\n",
       "               FORM_NAME  INSTANCE_NUM  FIELD_NAME DATA_FIELD_NAME FIELD_TYPE  \\\n",
       "27501692  vaccine_status             1  vacc_coord  vacc_coord___1     choice   \n",
       "27501693  vaccine_status             1  vacc_coord  vacc_coord___1     choice   \n",
       "27501694  vaccine_status             1  vacc_coord  vacc_coord___1     choice   \n",
       "27501695  vaccine_status             1  vacc_coord  vacc_coord___1     choice   \n",
       "27501696  vaccine_status             1  vacc_coord  vacc_coord___1     choice   \n",
       "\n",
       "                    ANSWER_LABEL  ANSWER_NUMERIC_VAL ANSWER_TEXT_VAL  \\\n",
       "27501692  Coordinator data entry                 NaN             NaN   \n",
       "27501693  Coordinator data entry                 NaN             NaN   \n",
       "27501694  Coordinator data entry                 NaN             NaN   \n",
       "27501695  Coordinator data entry                 NaN             NaN   \n",
       "27501696  Coordinator data entry                 NaN             NaN   \n",
       "\n",
       "                            CONECPT_CD  \\\n",
       "27501692  RC-RA1:vacc_coord___1|Inf|v0   \n",
       "27501693  RC-RA1:vacc_coord___1|Inf|v0   \n",
       "27501694  RC-RA1:vacc_coord___1|Inf|v0   \n",
       "27501695  RC-RA1:vacc_coord___1|Inf|v0   \n",
       "27501696  RC-RA1:vacc_coord___1|Inf|v0   \n",
       "\n",
       "                                               CONCEPT_NAME  \n",
       "27501692  Check this box if the coordinator is entering ...  \n",
       "27501693  Check this box if the coordinator is entering ...  \n",
       "27501694  Check this box if the coordinator is entering ...  \n",
       "27501695  Check this box if the coordinator is entering ...  \n",
       "27501696  Check this box if the coordinator is entering ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0vacc.head() #DATA_ENTRY_DATE \tDATA_FIELD_NAME\n",
    "# np.unique(df_0vacc['DATA_FIELD_NAME'])\n",
    "# df_0vacc[df_0vacc['DATA_FIELD_NAME']=='vacc_vaccdt_6'].head() #ANSWER_TEXT_VAL\t (26756, 14), 16,006, 13,239, 6760,2008,95\n",
    "# df_0vacc[df_0vacc['DATA_FIELD_NAME']=='vacc_vacctype_1___1'].head() # ANSWER_LABEL (10132, 14), 16,006, 13,239,6760,2008,95\n",
    "# df_0vacc[df_0vacc['DATA_FIELD_NAME']=='vacc_vaccyn_fu___1'].head() # ANSWER_LABEL No DATA_ENTRY_DATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1cf0ec12-40a5-4374-8cc8-478312838129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "VAX_NAMES = [\"vacc_vaccdt_1\",\"vacc_vaccdt_2\",\"vacc_vaccdt_3\",\"vacc_vaccdt_4\"]\n",
    "\n",
    "def _to_datetime(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s, errors=\"coerce\", utc=False).dt.tz_localize(None)\n",
    "\n",
    "def extract_vaccine_dates(events_df: pd.DataFrame,\n",
    "                          patient_col: str = \"PARTICIPANT_ID\",\n",
    "                          field_col: str = \"DATA_FIELD_NAME\",\n",
    "                          value_col: str = \"ANSWER_TEXT_VAL\",\n",
    "                          keep_first: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    From a long table of events, grab the earliest date per (patient, vccK).\n",
    "    Returns wide table with columns: patient_id, vcc1_date, vcc2_date, vcc3_date, vcc4_date\n",
    "    \"\"\"\n",
    "    df = events_df[[patient_col, field_col, value_col]].copy()\n",
    "    df = df[df[field_col].isin(VAX_NAMES)].copy()\n",
    "    df[\"vax_date\"] = _to_datetime(df[value_col])\n",
    "    df = df[~df[\"vax_date\"].isna()].copy()\n",
    "\n",
    "    agg_fn = \"min\" if keep_first else \"max\"\n",
    "    wide = (\n",
    "        df.groupby([patient_col, field_col])[\"vax_date\"]\n",
    "          .agg(agg_fn)\n",
    "          .reset_index()\n",
    "          .pivot(index=patient_col, columns=field_col, values=\"vax_date\")\n",
    "          .rename(columns={k: f\"{k}_date\" for k in VAX_NAMES if k in df[field_col].unique()})\n",
    "          .reset_index()\n",
    "    )\n",
    "    for k in VAX_NAMES:\n",
    "        col = f\"{k}_date\"\n",
    "        if col not in wide.columns:\n",
    "            wide[col] = pd.NaT\n",
    "    return wide[[patient_col] + [f\"{k}_date\" for k in VAX_NAMES]]\n",
    "\n",
    "def _same_month(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    a = pd.to_datetime(a, errors=\"coerce\")\n",
    "    b = pd.to_datetime(b, errors=\"coerce\")\n",
    "    return (a.dt.year == b.dt.year) & (a.dt.month == b.dt.month)\n",
    "\n",
    "def add_vaccine_actions_to_panel(panel_df: pd.DataFrame,\n",
    "                                 vax_dates: pd.DataFrame,\n",
    "                                 patient_col: str = \"PARTICIPANT_ID\",\n",
    "                                 date_col: str = \"date\",\n",
    "                                 composite_any_name: str = \"A_vax_any\",\n",
    "                                 composite_booster_name: str = \"A_booster\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins per-patient vaccine dates to a monthly panel and creates:\n",
    "      - A_vcc1..A_vcc4: 1 if dose date falls in that month, else 0\n",
    "      - A_vax_any: 1 if *any* of vcc1..vcc4 occurs that month\n",
    "      - A_booster: 1 if vcc3 or vcc4 occurs that month\n",
    "      - months_since_last_vaccine: numeric confounder\n",
    "    \"\"\"\n",
    "    panel = panel_df.copy()\n",
    "    panel[date_col] = _to_datetime(panel[date_col])\n",
    "\n",
    "    merged = panel.merge(vax_dates, on=patient_col, how=\"left\")\n",
    "\n",
    "    for k in VAX_NAMES:\n",
    "        cdate = f\"{k}_date\"\n",
    "        acol = f\"A_{k}\"\n",
    "        if cdate not in merged.columns:\n",
    "            merged[acol] = 0\n",
    "            continue\n",
    "        merged[acol] = _same_month(merged[cdate], merged[date_col]).astype(\"int8\")\n",
    "\n",
    "    merged[composite_any_name] = (merged[[f\"A_{k}\" for k in VAX_NAMES]].sum(axis=1) > 0).astype(\"int8\")\n",
    "    merged[composite_booster_name] = (merged[[\"A_vcc3\", \"A_vcc4\"]].sum(axis=1) > 0).astype(\"int8\")\n",
    "\n",
    "    vax_cols = [f\"{k}_date\" for k in VAX_NAMES if f\"{k}_date\" in merged.columns]\n",
    "    def months_since(row):\n",
    "        ref = row[date_col]\n",
    "        best = pd.NaT\n",
    "        for c in vax_cols:\n",
    "            d = row[c]\n",
    "            if pd.isna(d) or pd.isna(ref) or d > ref:\n",
    "                continue\n",
    "            if pd.isna(best) or d > best:\n",
    "                best = d\n",
    "        if pd.isna(best) or pd.isna(ref):\n",
    "            return np.float32(999.0)\n",
    "        return np.float32((ref - best).days / 30.0)\n",
    "\n",
    "    merged[\"months_since_last_vaccine\"] = merged.apply(months_since, axis=1)\n",
    "\n",
    "    return merged\n",
    "\n",
    "import pandas as pd\n",
    "# from add_vaccine_actions import extract_vaccine_dates, add_vaccine_actions_to_panel\n",
    "\n",
    "# 1) Long-format events table with vaccine records\n",
    "#    Must contain: patient_id, DATA_FIELD_NAME (vcc1..vcc4), ANSWER_TEXT_VAL (date string)\n",
    "# events = pd.read_csv(\"events_long.csv\")\n",
    "\n",
    "# 2) Monthly panel (one row per patient_id × month) with a 'date' column\n",
    "# panel = pd.read_csv(\"panel_monthly.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# 3) Get per-patient vaccine dates from long table\n",
    "vax_dates = extract_vaccine_dates(\n",
    "    events_df=df_0vacc,\n",
    "    field_col=\"DATA_FIELD_NAME\",\n",
    "    value_col=\"ANSWER_TEXT_VAL\",  # parsed to datetime\n",
    ")\n",
    "\n",
    "# 4) Add A_vcc1..A_vcc4, A_vax_any, A_booster, months_since_last_vaccine to your panel\n",
    "# panel_aug = add_vaccine_actions_to_panel(\n",
    "#     panel_df=panel,\n",
    "#     vax_dates=vax_dates,\n",
    "#     patient_col=\"DATA_FIELD_NAME\",\n",
    "#     date_col=\"date\",\n",
    "# )\n",
    "\n",
    "# panel_aug.to_csv(\"panel_with_vaccine_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29b45ea9-9dae-4140-b3bf-febd05093f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_dates.shape#(13074, 5)\n",
    "vax_dates.head()\n",
    "vax_dates.to_csv(\"vax_dates.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b86e391-0b90-4856-be95-c3eefbd447c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167/3360065347.py:3: DtypeWarning: Columns (209,212,213,215,216,217,220,233,234,235,243,267,270,271,273,274,275,278,291,292,293,301,359,383,386,387,389,390,391,394,407,408,409,417,475,499,502,503,505,506,507,510,523,524,525,533) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_x = pd.read_csv(path+files[11], sep=',', encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126805, 704)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_x = pd.read_csv(path+files[11], sep=',', encoding='latin1')\n",
    "# df_x.head()\n",
    "print(df_x.shape) # record_id, ps_colldt is the da\n",
    "\n",
    "\n",
    "# te (126805, 704)\n",
    "# for x in df_x.columns:\n",
    "#     print(x, end=',')\n",
    "# df_x.head() #(126805, 704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523756fe-f62c-44c8-a3b2-1e8c56f58ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vaccine = df_0[df_0['FORM_NAME'=='vaccine_status']]\n",
    "df_vaccine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "516d7ee7-efd1-4f4c-8917-1d5d732b6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PARTICIPANT_ID', 'ENROLL_PROTOCOL', 'ENROLL_SITE_ID',\n",
      "       'ENROLL_HUB_SITE_ID', 'ENROLL_SITE_PATH', 'ENROLL_DATE',\n",
      "       'ENROLL_CATEGORY', 'ENROLL_INDEX_DATE', 'CROSSOVER_FLAG',\n",
      "       'CROSSOVER_INDEX_DATE', 'ONSTUDY_INFECTION', 'ONSTUDY_INFECTION_CNT',\n",
      "       'SEX_AT_BIRTH', 'DOB', 'AGE_AT_ENROLLMENT', 'ENROLL_ZIP_CODE',\n",
      "       'WITHDRAWN', 'WITHDRAW_DATE', 'DECEASED', 'DECEASED_DATE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_baseage = pd.read_csv(path+files[3], sep='\\t', encoding='latin1')\n",
    "print(df_baseage.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3dfc74df-84ce-4a7c-bb36-f7d00e9ec79b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_visit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_baseage.rename({\"PARTICIPANT_ID\":'record_id'}, axis='columns',inplace=True)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mX_visit\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_visit' is not defined"
     ]
    }
   ],
   "source": [
    "# df_baseage.rename({\"PARTICIPANT_ID\":'record_id'}, axis='columns',inplace=True)\n",
    "X_visit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "92958c76-9c0d-4768-a17a-eaa0ca47cd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15179, 20)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_baseage.head() # \n",
    "# base_colums = ['PARTICIPANT_ID', \"SEX_AT_BIRTH\", \"AGE_AT_ENROLLMENT\",\"ENROLL_ZIP_CODE\"]\n",
    "# df_base = df_baseage[base_colums]#enroll_protocal adult\n",
    "# df_base.head()\n",
    "# print(np.unique(df_base['ENROLL_PROTOCOL']))\n",
    "df_baseage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2d3582f8-c058-4e74-a6df-0c41d8a40c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167/769487306.py:3: DtypeWarning: Columns (176) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_base = pd.read_csv(path+files[6], sep=',', encoding='latin1')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15159, 177)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install torch\n",
    "# import torch\n",
    "df_base = pd.read_csv(path+files[6], sep=',', encoding='latin1')\n",
    "df_base.shape #(15159, 177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b8a6a3c9-454b-4890-9756-e5208f4984fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.head()\n",
    "# df = merged_df\n",
    "# df.loc[df['SEX_AT_BIRTH'] == 'Female', 'SEX_AT_BIRTH'] = 0\n",
    "# df.loc[df['SEX_AT_BIRTH'] != 1, 'SEX_AT_BIRTH'] = 1\n",
    "# df.loc[df['DECEASED'] == 'N', 'DECEASED'] = 0\n",
    "# df.loc[df['DECEASED'] != 'N', 'DECEASED'] = 1\n",
    "\n",
    "# df_dropped_multiple = df.drop(['infect_yn_anti_f', 'enroll_dt','index_dt'], axis=1)\n",
    "# print(df_dropped_multiple.shape)\n",
    "# threshold_non_nan = len(df) - 100 \n",
    "\n",
    "# df_cleaned = df_dropped_multiple.dropna(axis=1, thresh=threshold_non_nan)\n",
    "# print(df_cleaned.shape)\n",
    "# df_cleaned.columns\n",
    "# df_cleaned.head()\n",
    "df_out_drop.to_csv(\"x_statics.csv\",index=False)\n",
    "# ['record_id', 'acute_yn', 'infect_yn', 'race___1', 'race___2',\n",
    "#        'race___3', 'race___4', 'race___5', 'race___6', 'race___7', 'race___15',\n",
    "#        'race____88', 'race_unique_an', 'dob', 'age_enroll', 'age_enrl_cat',\n",
    "#        'preg_cohort_yn', 'referral_type', 'spop___2', 'spop___3', 'spop___4',\n",
    "#        'spop___99', 'acute_reinf_ovr', 'rx_carelevel___0', 'rx_carelevel___1',\n",
    "#        'rx_carelevel___2', 'rx_carelevel___3', 'rx_carelevel___4',\n",
    "#        'rx_carelevel___98', 'rx_carelevel____88', 'ENROLL_DATE',\n",
    "#        'SEX_AT_BIRTH', 'AGE_AT_ENROLLMENT', 'ENROLL_ZIP_CODE', 'DECEASED'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "855a7f32-0e51-4e73-b3e7-cc104c73b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.unique(df_base['record_id']))\n",
    "# merged_df = pd.merge(df_base, df_baseage[['record_id', 'ENROLL_DATE','SEX_AT_BIRTH','AGE_AT_ENROLLMENT','ENROLL_ZIP_CODE','DECEASED']], on='record_id', how='left')\n",
    "# merged_df.to_csv(\"x_statics.csv\",index=False)\n",
    "# merged_df.head()\n",
    "# #ENROLL_ZIP_CODE,infect_yn_anti_f, SEX_AT_BIRTH,AGE_AT_ENROLLMENT\n",
    "# merged_df.head()\n",
    "# df.loc[df['TargetColumn'] == 'Yes', 'TargetColumn'] = 1\n",
    "# df.loc[df['TargetColumn'] != 1, 'TargetColumn'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4e87df5-8416-4378-80dc-53e59f050a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>acute_yn</th>\n",
       "      <th>infect_yn</th>\n",
       "      <th>infect_yn_anti_f</th>\n",
       "      <th>index_dt</th>\n",
       "      <th>enroll_dt</th>\n",
       "      <th>race___1</th>\n",
       "      <th>race___2</th>\n",
       "      <th>race___3</th>\n",
       "      <th>race___4</th>\n",
       "      <th>...</th>\n",
       "      <th>rx_carelevel___0</th>\n",
       "      <th>rx_carelevel___1</th>\n",
       "      <th>rx_carelevel___2</th>\n",
       "      <th>rx_carelevel___3</th>\n",
       "      <th>rx_carelevel___4</th>\n",
       "      <th>rx_carelevel___98</th>\n",
       "      <th>rx_carelevel____88</th>\n",
       "      <th>Spike</th>\n",
       "      <th>Nucleocapsid</th>\n",
       "      <th>OVER_89_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Infected</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RA16763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Infected</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RA111690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Infected</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA111095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Infected</td>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RA13123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Infected</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_id  acute_yn  infect_yn infect_yn_anti_f    index_dt   enroll_dt  \\\n",
       "0   RA11305       0.0          1         Infected  2020-01-11  2021-01-01   \n",
       "1   RA16763       0.0          1         Infected  2019-04-08  2021-01-01   \n",
       "2  RA111690       0.0          1         Infected  2020-11-05  2022-01-01   \n",
       "3  RA111095       0.0          1         Infected  2021-04-21  2022-01-01   \n",
       "4   RA13123       0.0          1         Infected  2020-04-05  2022-01-01   \n",
       "\n",
       "   race___1  race___2  race___3  race___4  ...  rx_carelevel___0  \\\n",
       "0       0.0       0.0       0.0       0.0  ...               0.0   \n",
       "1       0.0       0.0       0.0       1.0  ...               0.0   \n",
       "2       0.0       0.0       0.0       1.0  ...               0.0   \n",
       "3       0.0       0.0       0.0       0.0  ...               0.0   \n",
       "4       0.0       0.0       0.0       0.0  ...               0.0   \n",
       "\n",
       "   rx_carelevel___1  rx_carelevel___2  rx_carelevel___3  rx_carelevel___4  \\\n",
       "0               1.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               1.0               1.0   \n",
       "2               0.0               1.0               1.0               0.0   \n",
       "3               0.0               1.0               0.0               0.0   \n",
       "4               0.0               1.0               0.0               0.0   \n",
       "\n",
       "  rx_carelevel___98  rx_carelevel____88  Spike  Nucleocapsid OVER_89_FLAG  \n",
       "0               0.0                 0.0    NaN           NaN          NaN  \n",
       "1               0.0                 0.0    NaN           NaN          NaN  \n",
       "2               0.0                 0.0    NaN           NaN          NaN  \n",
       "3               0.0                 0.0    NaN           NaN          NaN  \n",
       "4               0.0                 0.0    NaN           NaN          NaN  \n",
       "\n",
       "[5 rows x 177 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.head() #index_dt, infect_yn, record_id, acute_yn, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6419cd-dc8f-4a38-93b0-e5cb47e8d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record_id,acute_yn,infect_yn,infect_yn_anti_f,index_dt,enroll_dt,race___1,race___2,race___3,race___4,race___5,race___6,race___7,race___15,race____88,race_unique_an,biosex,dob,age_enroll,age_enrl_cat,preg_cohort_yn,cc_anxdep_base,cc_asthma_base,cc_autoimm_base,cc_bipolar_base,cc_cancer_base,cc_cfs_base,cc_clung_base,cc_cns_base,cc_copd_base,cc_cvd_base,cc_dementia_base,cc_diabetes_base,cc_fibromyalgia_base,cc_imm_base,cc_liver_base,cc_move_base,cc_nmusc_base,cc_o2home_base,cc_obesity_base,cc_othermh_base,cc_polyov_base,cc_pots_base,cc_renal_base,cc_seiz_base,cc_sickle_base,cc_stroke_base,cc_cvdspec___1_base,cc_cvdspec___2_base,cc_cvdspec___3_base,cc_cvdspec___4_base,cc_cvdspec___5_base,cc_cvdspec___6_base,cc_cvdspec___7_base,cc_cvdspec___8_base,cc_cvdspec___98_base,cc_cvdspec____88_base,cc_autoimmspec___1_base,cc_autoimmspec___2_base,cc_autoimmspec___3_base,cc_autoimmspec___23_base,cc_autoimmspec___4_base,cc_autoimmspec___5_base,cc_autoimmspec___6_base,cc_autoimmspec___7_base,cc_autoimmspec___8_base,cc_autoimmspec___9_base,cc_autoimmspec___10_base,cc_autoimmspec___11_base,cc_autoimmspec___12_base,cc_autoimmspec___13_base,cc_autoimmspec___14_base,cc_autoimmspec___15_base,cc_autoimmspec___16_base,cc_autoimmspec___17_base,cc_autoimmspec___18_base,cc_autoimmspec___19_base,cc_autoimmspec___20_base,cc_autoimmspec___21_base,cc_autoimmspec___22_base,cc_autoimmspec___98_base,cc_autoimmspec____88_base,cc_cancerspec___1_base,cc_cancerspec___2_base,cc_cancerspec___3_base,cc_cancerspec___4_base,cc_cancerspec___5_base,cc_cancerspec___6_base,cc_cancerspec___7_base,cc_cancerspec___8_base,cc_cancerspec___9_base,cc_cancerspec___10_base,cc_cancerspec___11_base,cc_cancerspec___12_base,cc_cancerspec___13_base,cc_cancerspec___14_base,cc_cancerspec___15_base,cc_cancerspec___16_base,cc_cancerspec___17_base,cc_cancerspec___18_base,cc_cancerspec___19_base,cc_cancerspec___20_base,cc_cancerspec___21_base,cc_cancerspec____88_base,cc_transplant_type___1_base,cc_transplant_type___2_base,cc_transplant_type___3_base,cc_transplant_type___4_base,cc_transplant_type___5_base,cc_transplant_type____88_base,cc_stroke_type___1_base,cc_stroke_type___2_base,cc_stroke_type___3_base,cc_stroke_type___4_base,cc_stroke_type___6_base,cc_stroke_type___98_base,cc_stroke_type____88_base,cc_cns_type___1_base,cc_cns_type___2_base,cc_cns_type___3_base,cc_cns_type___4_base,cc_cns_type___5_base,cc_cns_type___6_base,cc_cns_type____88_base,cc_potsspec___1_base,cc_potsspec___2_base,cc_potsspec___3_base,cc_potsspec___4_base,cc_potsspec___10_base,cc_potsspec___98_base,cc_potsspec____88_base,cc_nmusc_type___1_base,cc_nmusc_type___2_base,cc_nmusc_type___3_base,cc_nmusc_type___4_base,cc_nmusc_type___5_base,cc_nmusc_type___6_base,cc_nmusc_type____88_base,cc_move_type___1_base,cc_move_type___2_base,cc_move_type___3_base,cc_move_type___4_base,cc_move_type___5_base,cc_move_type___6_base,cc_move_type___7_base,cc_move_type___8_base,cc_move_type____88_base,cc_diabetesspec_base,cc_dialyn_base,cc_transplant_base,referral_type,spop___2,spop___3,spop___4,spop___99,education,fvacc_index,vacc_numb,vacc_vacctype_1,vacc_vaccothspec_1,vacc_vaccdt_1,vacc_vaccdt_2,vacc_vaccdt_3,enrl_reinfyn,enrl_reinfdt,rx_totalinf,acute_reinf_ovr,rx_carelevel___0,rx_carelevel___1,rx_carelevel___2,rx_carelevel___3,rx_carelevel___4,rx_carelevel___98,rx_carelevel____88,Spike,Nucleocapsid,OVER_89_FLAG,"
     ]
    }
   ],
   "source": [
    "for x in df_base.columns:\n",
    "    print(x, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfac31aa-fc2d-4e9d-9a92-fba4d864283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_csv(path+files[8], sep=',', encoding='latin1')\n",
    "df_y.head() #record_id, visit_dt,index_dt_curr, pasc_score_2024#, pasc_cc_2023, pasc_cc_2024\n",
    "dfycolums = ['record_id','visit_dt','pasc_score_2024']\n",
    "df_yse = df_y[dfycolums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e6582e9-6dba-47e3-be55-465d23ba2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yse.shape #(126804, 3)\n",
    "\n",
    "df_yse.to_csv('y.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cf0a85-2ec4-4d3d-99a5-8c899193a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record_id,redcap_event_name,visit_dt,visit_month_curr,visit_month,instance_curr,instance,index_dt_curr,index_dt,infect_yn_curr,newinf_yn,newinf_dt,n_newinf,days_visit_indexcurr,days_visit_index,visit_missed,pasc_score_tf_2023,pasc_score_tf_2024,pasc_score_2023,pasc_score_2024,pasc_cc_2023,pasc_cc_2024,pasc_pg2023,pasc_pg2024,pasc_jama2023,pasc_jama2024,"
     ]
    }
   ],
   "source": [
    "for x in df_y.columns:\n",
    "    print(x, end = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "13b4c2b7-59fe-4afb-9214-26b9ad9f40a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>visit_dt</th>\n",
       "      <th>pasc_score_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RA11305</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_id    visit_dt  pasc_score_2024\n",
       "0   RA11305  2021-01-01             16.0\n",
       "1   RA11305  2021-04-03             14.0\n",
       "2   RA11305  2021-06-28              8.0\n",
       "3   RA11305  2021-09-28             13.0\n",
       "4   RA11305  2021-12-23             10.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63ab0434-ef23-4071-8e39-94dcd0ae3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yse.rename({'record_id':'PARTICIPANT_ID', 'visit_dt':'date'},axis='columns',  inplace=True)\n",
    "# df_yse.head()\n",
    "df_yse.to_csv('y_pasc_score2024.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b47c933f-7aaa-416e-a678-b6396f5dde95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126804, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.shape #(126805, 3)\n",
    "df_yse.shape #(126804, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02c2111e-6838-4dd2-b746-12eebaf02d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167/2575169864.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfm.rename({'record_id':'PARTICIPANT_ID', 'ps_colldt':'date'},axis='columns',  inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dfm.rename({'record_id':'PARTICIPANT_ID', 'ps_colldt':'date'},axis='columns',  inplace=True)\n",
    "dfm.to_csv('y_nqol.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d43c0e-ac95-47f8-b495-3acc6419be91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
